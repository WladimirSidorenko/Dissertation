% FILE: sentiment.tex  Version 0.01
% AUTHOR: Uladzimir Sidarenka

% This is a modified version of the file main.tex developed by the
% University Duisburg-Essen, Duisburg, AG Prof. Dr. Günter Törner
% Verena Gondek, Andy Braune, Henning Kerstan Fachbereich Mathematik
% Lotharstr. 65., 47057 Duisburg entstanden im Rahmen des
% DFG-Projektes DissOnlineTutor in Zusammenarbeit mit der
% Humboldt-Universitaet zu Berlin AG Elektronisches Publizieren Joanna
% Rycko und der DNB - Deutsche Nationalbibliothek

Interpersonal communication is not only a way to share objective
information with other people but also a vibrant channel to convey
one's subjective thoughts, attitudes, and feelings.  It is, in fact,
this latter use which provides a personal touch to our discourses,
making them more grasping, more entertaining, and more living.  And it
is often this use which significantly influences our decisions,
preferences, and choices in everyday life.  Therefore, a high-quality
automatic analysis of the subjective part of information is typically
not less important than the extraction and analysis of objective
facts.

\section{Introduction to Sentiment Analysis}

The field of knowledge which deals with the analysis of people's
opinions, sentiments, evaluations, appraisals, attitudes, and emotions
towards particular entities mentioned in discourse is called
\emph{sentiment analysis} (SA) \citep{Liu:12}.  The definition of this
discipline, however, much like the definition of the term
\emph{sentiment} itself, is neither complete nor universally accepted.
The main reasons for this are
\begin{inparaenum}[\itshape i)\upshape]
  \item a frequently unclear delimitation of the subjective and
    objective components of information and
  \item the heteroginity of the language system to which SA methods
    are applied.
\end{inparaenum}

The former factor, for instance, makes it difficult to delimitate what
kinds of events and expressions should actually belong to the domain
of sentiment analysis, and which ones shall rather be excluded from
it.  A prominent example of such problematic borderline cases are the
so-called subjective facts, such as \emph{terrorist attacks} or
\emph{cancer drugs}, which some people perceive as emotionally laden
terms while others regard them as purely objective statements.

The latter factor complicates a precise definition of SA because
different levels of the language have their own concepts of
subjectivity, which in turn require different approaches and methods
to use.  Depending on the language level being analyzed, researchers
typically distinguish three different subtypes of sentiment analysis:
\begin{itemize}
  \item\emph{subsentential} or \emph{fine-grained} SA whose task is to
    determine and analyze specific subjective opinions and/or
    evaluations within single clauses,
  \item\emph{sentential} analysis which tries to ascribe a single
    polarity class to each sentence in a text, and
  \item\emph{suprasentential} or \emph{document-level} sentiment
    classification which seeks to determine the polarity and
    subjectivity classes of complete discourses.
\end{itemize}

Each of these subtypes has its own characteristic strengths and
weaknesses.  The fine-grained SA, for example, is typically considered
to be the ultimate goal of any opinion mining\footnote{Following
  \citet{Liu:12}, we do not make a distinction between the terms
  \emph{opinion mining} and \emph{sentiment analysis} and use both
  expressions interchangeably in this thesis.}  system as it aims at
the highest possible recall of all subjective expressions occurring in
a text.  At the same time, this task is unfortunately very challenging
even for human beings, as we will show in Section \ref{sec:corpus},
let alone computer programs.  The consequently low results often
intimidate researchers and prevent subsentential SA systems from being
used in industrial applications.

The last two disciplines (sentential and document-level analyses) can
be considered as approximations of the fine-grained SA.  They coarsen
the targeted recall down to the level of sentences or texts
respectively, trying to determine only one (the most prominent)
expression of subjectivity per analyzed unit.  In contrast to the
subsentential SA, these approaches typically yield better results at
the cost of sacrificing important details.

Due to these crucial disparities between different variants of
sentiment analysis, speaking of the difficulty or easiness of this
task for a specific domain in general is in the same way wrong as
making overall judgments about the amenability of this domain to the
whole natural language processing field: one always has to specify the
precise level of sentiment analysis whose difficulty is being analyzed
just as she has to set apart a particular NLP task in order to assess
its complicatedness.

In this chapter, we will primarily concentrate on the most challenging
SA objective -- that of the fine-grained SA.  After a brief summary of
related work done on the opinion mining in general and sentiment
analysis of social media in particular, we will introduce a
comprehensive corpus of German tweets that has been created for the
purpose of this work.  A detailed inter-annotator agreement study of
this dataset will reveal which linguistic and extra-linguistic factors
significantly influence the distribution of sentiments in Twitter, and
which of them cause utter confusion among human experts.  After
obtaining an upper bound on human performance, we will successively
compare with it the results attained by automatic sentiment systems,
starting with the most fundamental task of recognizing subjective
expressions and concluding with the ultimate goal of recognizing
textual spans of sentiments, their objects of evaluation
(\emph{targets}), and authors (\emph{sources}).

\subsection{Prehistory of the Field}

However, before we delve into the odds and ends of contemporary
sentiment analysis, we first would like to make a short digression
into the history of this field in order to understand its modern
trends and theories better.  Like many other subdisciplines of
computational linguistics, opinion mining has emerged from several
other areas of research, including philosophy, psychology, cognitive
sciences, and last but least narratology and linguistics.

In \emph{philosophy}, the questions about the nature of emotions,
their interaction with the human consciousness, and their influence on
people's deeds have occupied the minds of many great scholars,
starting from Plato and Aristotle.  Plato, for instance, argued in his
treatise ``The Republic'' \citep[Book~IV]{Plato:91} that the human
soul presumably consists of three fundamental parts: the rational, the
appetitive, and the passionate.  The last part -- the one by which we
become angry or get into a temper -- determines our notion of justice
by favoring either the rational or the appetitive aspect.  These ideas
were further particularized and partly revised by Plato's most
prominent student -- Aristotle.  In Book~II of ``The Rhetoric''
\citep{Aristotle:54}, Aristotle not only provides a precise taxonomy
and definitions of possible emotions that might constitute the
passionate part of the mind, but also contends that these are both the
reasons for the change of human judgements and the consequences of
those changes \cite[cf.][p. 157]{Leighton:82}.

As noted by \citet{Sousa:14}, the sheer variety of phenomena covered
by the term ``emotion'' and its closest neighbors tended to discourage
tidy philosophical theories and daunted researchers for a long period
of time.  A real renaissance of emotional studies happened, however,
in the late 19-th century in \emph{psychology} with the introduction
of the James-Lange Theory \citep{James:1884}.  In his groundbreaking
work, \citeauthor{James:1884} proclaimed the naturalistic idea that
bodily changes followed directly the perception of the exciting facts,
and that our feelings of the same changes were, in fact, the emotions.
In other words, our biological processes were the primary and the only
reason for us to perceive sentiments:
\begin{quote}
``If we fancy some strong emotion, and then try to abstract from our
  consciousness of it all the feelings of its characteristic bodily
  symptoms, we find we have nothing left behind, no `mind-stuff' out
  of which the emotion can be constituted, and that a cold and neutral
  state of intellectual perception is all that
  remains.''\citep[p. 193]{James:1884}
\end{quote}
Independently of James' work, similar views were proposed by the
Danish physician Carl Lange \citep{Lange:1885} who hypothesized that
emotional phenomena were the consequences of cardiovascular events
\citep[cf.][]{Lang:94}.

In the 1920s, James-Lange's theory was severely criticized by Philip
Bard and Walter B. Cannon \citep{Bard:28,Cannon:31}, who proposed an
alternative interpretation of emotions, refuting their connection to
the viscera and arguing that both bodily reactions and subjective
feelings were generated simultaneously in the talamic region of the
brain.

In psychology:

TODO: Schachter-Singer Theory

That emotions typically have formal objects highlights another
important feature of emotional experience which feeling theories
neglect, and which other psychological theories attempt to
accommodate: emotions involve evaluations. If someone insults me and I
become angry, his impertinence will be the aspect of his behavior that
fits the formal object of anger: I only become angry once I construe
the person's remark as a slight; the specific nature of my emotion's
formal object is a function of my appraisal of the situation. Magna
Arnold introduced the notion of appraisal into psychology,
characterizing it as the process through which the significance of a
situation for an individual is determined. Appraisal gives rise to
attraction or aversion, and emotion is equated with this ``felt
tendency toward anything intuitively appraised as good (beneficial),
or away from anything intuitively appraised as bad (harmful).''
(Arnold 1960, 171). Subsequent appraisal theories accept the broad
features of Arnold's account, and differ mainly in emphasis. Richard
Lazarus (1991) makes the strong claim that appraisals are both
necessary and sufficient for emotion, and sees the identity of
particular emotions as being completely determined by the patterns of
appraisal giving rise to them. Nico Frijda (1986) takes the patterns
of action readiness following appraisals to be what characterize
different emotions, but departs from Arnold in not characterizing
these patterns solely in terms of attraction and aversion. Klaus
Scherer and his Geneva school have elaborated appraisal theories into
sophisticated models that anatomize different emotions in terms of
some eighteen or more dimensions of appraisal. Emotions turn out to be
reliably correlated, if not identified, with patterns of such complex
appraisals. (Scherer et al., 2001). Appraisal theories can be
described as taking a functional approach to emotion, insofar as
appraisals lead to reactions whose function is to deal with specific
situation types having some significance for an individual (Scherer
2006). This approach suggests that the space of emotions can be
conceptualized as multidimensional. In practice, however, so-called
dimensional theories simplify the problem of representation by
reducing these to just two or three (Russell 2003).

In literary studies and linguistics,

TODO: Theory of Narrative Sentences

Some philosophers suggest that the directive power which emotions
exert over perception is partly a function of their essentially
dramatic or narrative structure (Rorty 1988). A particularly subtle
examination of the role of narrative in constituting our emotions over
the long term is to be found in (Goldie 2012).  de Sousa (1987) has
suggested that the stories characteristic of different emotions are
learned by association with ``paradigm scenarios.'' These are drawn
first from our daily life as small children and later reinforced by
the stories, art, and culture to which we are exposed. Later still,
they are supplemented and refined by literature and other art forms
capable of expanding the range of one's imagination of ways to live.

Among the first who applied this theory to the needs and wants of
\emph{computational linguistics} was \citet{Wiebe:90a}.  In her work,
the author proposed an algorithm for identifying characters of
narratives whose point of view was represented by subjective
sentences.  Later on, \citet{Wiebe:94} further enhanced this system
with the possibility to predict subjective sentences in stories
automatically.  This work was allegedly one of the first experiments
on the automatic prediction of sentiments on the level of single
sentences.

The real breakthrough in the sentiment analysis field, however,
happened with the introduction of the first manually annotated
corpora.  Notable contributions in this regard were done by
\cite{Wiebe:03} \cite{Wilson:03}.

Computational Linguistics: Wilensky (1983), Dyer (1983),


\cite{Hatzivassi:97} \cite{Nasukawa:03}, \cite{Yi:03},
\cite{Kanayama:04}

\subsection{Sentiment Analysis of Social Media}

One of the main problems that people working on opinion mining are
typically confronted with in the first place is that of the discourse
domain to be analyzed.  Since sentiment analysis is a highly
domain-dependent task \citep[cf.][]{Aue:05,Blitzer:07,Li:08} -- i.e.,
systems trained for specific topics and on specific text genres do not
neatly generalize to other subjects and other linguistic styles -- a
natural question that arises in this context is which of the domains
should be addressed first in that case.

While earlier sentiment works were primarily concerned with narratives
\citep{Wiebe:90a,Wiebe:94} or newspaper articles
\citep{Wiebe:03,Wiebe:05,Bautin:08}, it soon became clear that social
media provides a much more fertile ground for mining people's
opinions.  The reason for this is the virtual absence of any
moderation on many modern CMC services.  This lack of censorship
allows users to be upfront about their feelings.  Combined with the
great popularity of social networks, such freedom of expressing one's
thoughts makes social media the arguably most prolific channel for
sharing (and mining) personal emotions.

It is therefore not surprising that the rapid emergence of numerous SM
websites was accompanied by an increasing interest in their content
from many NLP practitioners.  One of the first who attempted to
extract users' evaluations automatically from CMC services were
\citet{Das:01}.  The authors investigated the correlation between
users' attitudes on economic chat boards and stock prices for about
eight stocks.  For this purpose, they trained a collection of five
classifiers on a training set of 500 messages that were manually
labeled with three classes: \emph{buy} (positive evaluations),
\emph{sell} (negative evaluations), and \emph{null} (neutral
statements).  With these classifiers, they subsequently annotated the
rest of the downloaded 25,000 posts, taking the majority votes of the
five systems as the final labels, and scrutinized the
interrelationship between these predictions and the observed stock
indices.
%% This study revealed that user chats strongly correlated with stock
%% developments in a reactive way: changes in stock prices had
%% typically lead to fluctuations of public opinions but not vica
%% versa.

\citet{Glance:05} also used sentiment analysis for business
intelligence purposes by mining users' opinions on Usenet newsgroups
with a set of hand-crafted rules. TODO: add more works

A slightly different domain and objective were addressed by
\citet{Turney:02} who performed a two-class classification of 410
Epinions comments, dividing customers' reviews of automobiles, banks,
movies, and travel destinations into \emph{recommended} (thumbs up)
and \emph{not recommended} (thumbs down) ones.  In order to make these
decisions, the proposed system first computed the sum of the pointwise
mutual information (PMI) scores between the adjectival and adverbial
phrases occurring in a review text and the word ``excellent'', and
then subtracted from this the PMIs of the found phrases in conjunction
with the word ``poor''.  Reviews with negative results were
subsequently considered as \emph{thumbs down} and comments with
non-negative total scores were correspondingly classified as
\emph{thumbs up}.

According to \citet{Turney:02}, the most challenging type of reviews
to analyze in these experiments were the movie critiques (the accuracy
on this subset only reached 66\%, whereas, for banks and automobiles,
it attained 80 and 84\% respectively).  This finding was also
confirmed by \citet{Pang:02} who tried out several machine learning
classifiers on a manually annotated corpus of $\approx2,000$ write-ups
from the Internet Movie Database (IMDb).  The best results (82.9\%
accuracy) for the two-class classification task (\emph{positive}
versus \emph{negative}) were attained by an SVM system which used the
presence of unigrams as classification features.

Due to its high commercial impact, opinion mining of customer reviews
soon became one of the most popular topics in the sentiment analysis
research. \citet{Dave:03}, for example, attempted to classify C|Net
and Amazon reviews of movies and electrical appliances as positive or
negative using the Na\"{\i}ve Bayes and SVM approaches.
%% The authors found that replacing certain entities, such as product
%% names, abbreviations, or numerals, with special meta-tokens and
%% using token n-grams of different lengths had a significant positive
%% effect on the accuracy of both classifiers.
TODO: add more works

With the increasing spread of blogging services and social networks,
sentiment researchers have also gradually shifted the focus of their
work to these nascent text genres. \citet{Mishne:05} and
\citet{Mishne:07}, for instance, tried to classify Livejournal blogs
according to the moods of their authors (e.g.  \emph{amused},
\emph{tired}, \emph{happy} etc.).  The gold labels of their
$\approx$~815,000 blog corpus were obtained automatically from blog
labels on the Livejournal website.  On this corpus, the authors
trained a supervised SVM classifier, reaching an average of 8\%
improvement over the 50\% baseline.

\citet{Chesley:06} also applied an SVM system in order to classify
user blogs into objective, positive and negative subjective ones.  The
authors derived their features from the Wiktionary and the InfoXtract
lexicon \citep{Srihari:03} and attained an accuracy increase of up to
15~\% over the majority class baseline.  This research direction was
further continued by \citet{Godbole:07}, who applied a lexicon-based
method to detect users' opinions in newspapers and blogs, and
\citet{Gill:08}, who conducted an inter-annotator agreement study of
mood detection in blogs, finding that raters' consensus on the
expressed emotions strongly increased with the length of blog entries.

Speaking of blog length, it should certainly be said that the
inception of the micro-blogging service Twitter in 2006 was a real
game changer to the opinion mining field: the sudden availability of
huge amounts of data, the presence of all possible social, national,
and age groups as well as a high idiosyncracy of the language used on
this service gave rise to numerous scientific publications, which we
think are worth to be described in a separate subsection.

\subsection{Sentiment Analysis of Twitter}

From its very onset in 2006, Twitter has constantly attracted the
attention of many NLP-practitioners and scientists, with sentiment
researchers being arguably one of the most active of these groups.
This trend seems ever exapanding in recent years: For instance, in
2015, a whole section of the international ACL Workshop on
Computational Approaches to Subjectivity, Sentiment and Social Media
Analysis (WASSA 2015) was solely dedicated to the peculiarities of the
opinion mining on Twitter.  Sentiment detection on Twitter also
remains an active track of the SegEval Shared Task TODO: cite Nakov.
But despite its great popularity, most of this work on this topic
still concentrates on English data only.

One of the first notable works on sentiment analysis of microblogs was
done by \citet{Go:09}.  In their experiments, the authors collected a
set of 1,600,000 Twitter messages containing smileys.  Based on these
emoticons, they automatically derived polarity classes of these tweets
(positive or negative) and then used these bootstrapped labels to
train the Na\"{\i}ve Bayes, MaxEnt, and SVM classifiers.  The best
$F$-score for this two-class classification problem could be achieved
by the last system and run up to 82.2\%.

Similar work was done later by \citet{Pak:10} who used the Na\"{\i}ve
Bayes approach to differentiate between neutral, positive, and
negative tweets. \citet{Barbosa:10} also gathered a collection of
200,000 tweets from three publicly available sentiment web-services.
Using the majority prediction of these three services as their gold
labels, the authors trained an SVM classifier on this corpus and then
let their system predict the subjectivity and polarity classes of new
unseen messages.

Works attempting a more fine-grained sentiment analysis on Twitter
usually try to derive a common polarity class for each message with
respect to a particular target that is mentioned in that microblog.

\citet{Jiang:11}, for instance, tried to classify the polarity of
microblogs pertaining to a predefined set of specific topics, like
\emph{Obama}, \emph{Google}, \emph{iPad} etc.  To this end, the
authors manually labeled a corpus of 1,939 messages and trained a
binary SVM model in order to predict the subjectivity and the polarity
of the tweets with respect to the given subjects.

This classifier could achieve an accuracy of 68.2\% for the
subjectivity classification and 85.6\% for the polarity prediction.
The $F$-score of this system for the latter task could further be
improved from 66\% to 68.3\% by incorporating the information about
the predicted polarity class of the re-tweets, replies, and other
microblogs posted by the same author.

\citet{Mitchell:13} broadened the set of possible targets by allowing
any named entities found in microblogs to be associated with a
specific polarity.  For that purpose, the authors combined a CRF-based
NER system with a sentiment predicting CRF by considering three
different possibilities of such combination: a pipeline approach, a
joint multi-layer model, and a single classifier with a combined
tagset.  The best scores on their corpora of 7,105 Spanish and 2,350
English tweets could be achieved with the joint and pipeline
approaches.  The accuracy of recognizing the opinionated named
entities amounted to 31\% for Spanish and 30.4\% for English.

Other notable works in this direction include \citet{Chunping:14} who
first applied a Na\"{\i}ve Bayes classifier to predict the
subjectivity class of microblogs and then sequentially used two CRF
models to predict the particular type of subjectivity (such as anger,
fear, happiness etc.) for message sentences.

Other notable works in this direction include \citet{Dong:14} who used
a recurrent neural network to predict the polarity class associated
with the opinion targets.  They, however, assumed the targets of
sentiments to be apriori known and only were interested whether a
positive or a negative judgement was made about them.

\citet{Derks:08}

The \texttt{SentiStrength} system proposed by \cite{Thelwall:12} used
an extensive list of 763 polar terms in order to predict positive and
negative scores for MySpace comments.  The manually assigned scores of
these terms were automatically fine-tuned during training using a
perceptron-like technique.  In addition to the core lexicon, the final
implementation of this system also utilized a set of heuristic methods
and auxiliary modules such as spelling correction algorithm,
dictionaries of booster words and negations as well as special rules
for emoticons, repeated letters, and exclamation marks.  It correctly
predicted positive emotions in 60.6~\% of the cases and attained
73.5~\% accuracy at predicting negative sentiment scores.  All
predictions were made at the level of complete messages.

