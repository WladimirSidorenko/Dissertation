Titel:

Sentimentanalyse deutschen Twitters


Zusammenfassung:

Die enorme Popularität von Online-Kommunikationsdiensten in den
letzten Jahrzehnten hat nicht unser Leben massiv geändert (so dass
Nachrichten sich wie Fegefeuer übers Internet ausbreiten, Präsidenten
ihre Entscheidungen auf Twitter ankündigen, und Ergebnisse politischer
Wahlen auf Facebook entschieden werden) sondern auch zu einem
dramatischen Anstieg der Datenmenge geführt, die über solche
Plattformen ausgetauscht werden.  Deswegen braucht man heutzutage
dringend zuverlässige, qualitätvolle NLP-Programme, um neue
gesselschaftliche Bedürfnisse und Risiken in unzensierten
Nutzernachrichten automatisch erkennen und abschätzen zu können.
Leider sind die meisten modernen NLP-Anwendungen entweder auf die
Analyse der Standardsprache (wie wir sie aus Zeitungstexten kennen)
ausgerichtet oder im besten Fall an die Spezifika englischer Social
Media angepasst.

Diese Dissertation reduziert den bestehenden Rückstand, indem sie das
``Neuland'' der deutschen Online-Kommunikation betritt und sich einer
seiner produktivsten Formen zuwendet---den Nutzerdiskussionen auf
Twitter.  Diese Arbeit erforscht insbesondere die Art und Weise, wie
Leute ihre Meinungen auf diesem Online-Service äußern, analysiert
existierende Verfahren zur automatischen Erkennung ihrer Gefühle und
schlägt neue Verfahren vor, die viele heutige State-of-the-Art-Systeme
übertreffen.

Zu diesem Zweck stelle ich ein neues Korpus deutscher Tweets vor, die
manuell von zwei menschlichen Experten mit Sentimenten (polaren
Meinungen), ihren Quellen (sources) und Zielen (targets) sowie
lexikalischen polaren Termen und deren kontextuellen Modifizierern
annotiert wurden.  Mit Hilfe dieser Daten untersuche ich vier große
Teilgebiete der Sentimentanalyse: (i) automatische Generierung von
Sentiment-Lexika, (ii) aspekt-basiertes Opinion-Mining, (iii)
Klassifizierung der Polarität von ganzen Nachrichten und (iv)
diskurs-bewusste Sentimentanalyse.

In der ersten Aufgabe vergleiche ich drei populäre Gruppen von
Lexikongenerierungsmethoden: wörterbuch-, corpus- und
word-embedding-basierte Verfahren, und komme zu dem Schluss, dass
wörterbuch-basierte Ansätze generell bessere Polaritätslexika liefern
als die letzten zwei Gruppen.  Abgesehen davon, schlage ich einen
neuen Linearprojektionsalgorithmus vor, dessen Resultate deutlich
besser als viele automatisch generierte Polaritätslisten sind.

Weiterhin, in der zweiten Aufgabe, untersuche ich zwei gängige
Herangehensweisen an die automatische Erkennung der Textspannen von
Sentimenten, Sources und Targets: Conditional Random Fields (CRFs) und
rekurrente neuronale Netzwerke.  Ich erziele bessere Ergebnisse mit
der ersten Methode und verbessere diese Werte noch weiter durch
alternative Topologien von CRF-Graphen.

Bei der Analyse der Nachrichtenpolarität, stelle ich drei große
Sentiment-Paradigmen gegenüber: lexikon-, Machine-Learning--, und
Deep-Learning--basierte Systeme, und versuche die erste und die letzte
dieser Gruppen in einem Verfahren zu vereinigen, indem ich eine neue
neuronale Netwerkarchitektur vorschlage: bidirektionales rekurrentes
Netwerk mit lexikon-basierter Attention (LBA).

Im letzten Kapitel unternehme ich einen Versuch, die Prädiktion der
Gesamtpolarität von Tweets über die Diskursstruktur der Nachrichten zu
informieren.  Zu diesem Zweck wende ich den vorgeschlagenen
LBA-Klassifikator separat auf jede einzelne elementäre Diskurs-Einheit
(EDU) eines Microblogs an und induziere die allgemeine semantische
Ausrichtung dieser Nachricht mit Hilfe von zwei neuen Methoden:
latenten marginalisierten CRFs und rekursivem Dirichlet-Prozess.
