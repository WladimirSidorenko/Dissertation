% FILE: introduction.tex  Version 0.01
% AUTHOR: Uladzimir Sidarenka

% This is a modified version of the file main.tex developed by the
% University Duisburg-Essen, Duisburg, AG Prof. Dr. Günter Törner
% Verena Gondek, Andy Braune, Henning Kerstan Fachbereich Mathematik
% Lotharstr. 65., 47057 Duisburg entstanden im Rahmen des
% DFG-Projektes DissOnlineTutor in Zusammenarbeit mit der
% Humboldt-Universitaet zu Berlin AG Elektronisches Publizieren Joanna
% Rycko und der DNB - Deutsche Nationalbibliothek

\chapter{Foreword}

\section{Overview}
As social media become more and more ubiquitous, the need for an
automatic analysis of their data rises.  This analysis, however, is
greatly aggravated by the fact that the language style used on the Web
is fundamentally different from the style that is typical for
newspapers or scientific articles.  Indeed, sentences like the ones
shown in Example \ref{exmp:intro:tweets:en} (taken from
\citet{HanBaldwin:11}) are highly unlikely to appear in editorials or
government documents even though their wording is commonplace on the
U.S. English Twitter.
\begin{example}\label{exmp:intro:tweets:en}
u must be talkin bout the paper but I was thinkin movies

\dots so hw many time remaining so I can calculate it?
\end{example}
Similar discrepancies between the formalism of the official style and the
casual nature of spontaneous Web conversations can be observed in other
languages too, and German is not an exception.

It is, however, unclear whether the idiosyncracies of the online style
should be considered as a drawback or an advantage for the automated
language analysis.  While most of the NLP-researchers tend to consider
these peculiarities as a hindrance and suggest converting online texts
to a more standard language-like form before doing any processing
(cf. relevant works in Section \ref{sec:normalization:relwork}), other
scientists at least object that a straightforward conversion would
loose many significant details and therefore lead to a decrease in the
performance.  \citet{Brody:11}, for instance, claim that the
intentional prosodic lengthenings of words (such as \texample{sooooooo
  strong} or \texample{coooolllllll}) often serve as vivid indicators
of opinionated sentences and keeping these elongations in text would
result in a better sentiment analysis.  \citet{Eisenstein:13}
partially supports this idea by noting that also in cases of lexical
normalization, when we are replacing a colloquial variant of some
expression with its standard language equivalent, we can also observe
a considerable shift in the original meaning.  %% Even such non-verbal
%% elements as the online discourse deictics (e.g. \texample{\upshape
%%   <--} (the arrow sign), \texample{\upshape\^{}} (the carat), and
%% \texample{\upshape *} (the asterisk)) might play an important
%% pragmatic role in discourse which should also be taken into account
%% when doing text analysis (cf. \citet{Collister:11,Collister:12}).

\paragraph{Goals.}

Providing an answer to the question whether the stylistic
peculiarities of the online language can do more harm or good to the
automated analysis is precisely one of the major goals of this
dissertation.  We cannot, however, achieve this goal without realizing
first what these stylistic peculiarities in fact are.  That means, our
first and primary objective is \emph{to find out linguistic phenomena
  that actually account for the idiosyncracies of the Web genre}.

After determining the online language-specific elements, the next
naturally arising question is what to do about these elements---should
we leave them unchanged or should we process them in some special way
and, if so, what this special way might look like?  Thus, the second
preliminary objective is \emph{to find effective methods for handling
  the specifics of the Web language}.  In scope of this goal, we
should juxtapose two approaches: the one of doing nothing and the one
of normalizing that specifics.

For the normalization method, we should also \emph{provide an
  appropriate metric for an intrinsic evaluation of this technique}.
However, evaluating an approach intrinsically can tell us much about
the quality of its work, but a crucial fact about the text
preprocessing is that people are usually not interested in the
preprocessing by itself but much more in its effect on the downstream
modules, i.e., its extrinsic impact.  Therefore, after intrinsically
evaluating our preprocessing strategy, we should \emph{extrinsically
  asses its effect on the downstream NLP applications.}  We do so on
the example of two main NLP objectives: sentiment and discourse
analysis.

\paragraph{Research objects.}

However, before we start addressing our goals, we first would like to
clarify some methodological aspects of our work.

First of all, we should note that in order to assess the impact of
stylistic peculiarities on the performance of automatic text
applications, we need to answer the question of what these
peculiarities actually are, i.e., which linguistic phenomena in fact
contribute to the idiosyncracy of the online genre.  In order to
answer this question, we should conduct an extensive study of
out-of-vocabulary (OOV) words found in Twitter microblogs and divide
found OOVs into separate classes depending on their word formation
type.  Then, we shall investigate which of the suggested classes are
typical only for the online language and which are common for all text
genres.

Secondly, after determining the Web-specific elements, we should
\begin{inparaenum}[\itshape a)\upshape]
\item investigate the effect of those elements on the automatic analysis and
\item find an efficient strategy for mitigating the negative consequences of
  that effect.
\end{inparaenum}
For solving the former task, we will compare the performance of the existing
NLP methods obtained on standard language texts with their respective results
achieved on microblog messages.  For solving the latter task, we will first
introduce two general techniques that are commonly used in computational
linguistics for adjusting existing NLP tools to new domains.  These techniques
are called \emph{domain adaptation} and \emph{text normalization}.  We will
briefly describe each of them and shortly point out their strengths and
weaknesses.  After that, we will mainly concentrate on the latter method --
the \emph{text normalization}.

In this task, our goal will be to provide a formal definition of the text
normalization task with regard to Twitter specifics.  As we should see later
and as is also confirmed by \citet{Eisenstein:13}, it will turn out to be
surprisingly difficult to find a precise definition of the normalization.  The
reason for it lies in the fact that the notion of the language ``norm'' by
itself appears to be lax and slippery.

After providing a working definition of normalization, our next goal will be
to investigate different normalization strategies and to find out which of
these strategies are most suitable for treating Twitter-specific phenomena.
This, of course, would not be possible without an appropriate evaluation
metric.  % for measuring how good the performed normalization is.
We will first rely on purely intrisic (\emph{in vitro}) metrics which measure
the normalization quality on its own.

For sure, an in vitro evaluation measure can tell much about the
quality of the performed preprocessing.  But like for many other
NLP-related tasks, a good performance of a standalone module does not
necessarily lead to an equal quality improvement in further downstream
processing.  This is especially true for the text normalization task
whose mere positive effect on the subsequent analysis is often called
into question.  \citet{DuBois:07}, for example, claims that language
variation serves a pragmatic and/or stancetaking function and,
consequently, eliminating variation would strip those additional
layers of meaning.  \citet{Brody:11} provide a concrete example
showing that intentional prosidic lengthenings of words are often a
vivid indicator of opinionated sentences and keeping these elongations
in text would result in better sentiment analysis.

At this point, we arrive at the third methodological aspect that we need to
address.  Deciding whether Twitter-genre is more or less amenable to automatic
processing and evaluating the effects of text normalization should be done by
inspecting different levels of automatic linguistic analysis.  Because
language is not a uniform object but much more a complex hierarchical
structure, we cannot draw an overall conclusion about its difficulty in
general, if we only inspect one of its multiple levels.  In this work, we
decided to concentrate on three levels:
\begin{inparaenum}[\itshape i)\upshape]
  \item subsentenial (on the example of sentence splitting and tokenization),
  \item sentential (on the example of fine-grained sentiment analysis), and
  \item the suprasentential or discourse level (on the example of discourse
    segmentation and parsing).
\end{inparaenum}

For each of these levels, we will perform automatic analyses of standard
language texts and compare their results with figures obtained on Twitter
corpora.  Since annotated Twitter data are still scarce, we had to develop our
own corpus for each of the above tasks.  In this work, we will briefly discuss
the annotation scheme, the format, the selection criteria and several other
issues involved in the creation of each of these corpora.

Finally, we should note that all evaluations of automatic results should be
done only with respect to the difficulty of that particular tasks for humans.
For this purpose, we will conduct and present extensive inter-annotator
agreement studies for each of our presented corpora and also discuss which
elements, topics, and other linguistic criteria caused most difficulties
during the annotation procedure.  We will then compare the results of the
automatic systems with the results obtained of the inter-annotator agreement
in order to compare how better or worse an automatic system works if compared
to humans.

In the concluding part of our dissertation, we will summarize our results
obtained in each chapter and also investigate how different levels of
automatic analysis might benefit form each other, and how text normalization
procedure affects the final results.

\section{Motivation, Methods, Objects and Goals}
In this work, we should only concentrate on German Twitter.  Though
comparative studies of social media texts in other languages and from other
platforms would certainly be of outermost interest, we only confine ourselves
to this data source, since, in our opinion, any solid comparative research
should first be preceded by thorough studies of the particular domains taken
in isolation and again, in our opinion, little work has been done so far on
German online genre in general and German microblogs in particular.

The motivation for choosing especially Twitter platform is based on the
following factors:
\begin{itemize}
  \item First of all, Twitter data are easy to obtain via public APIs, even
    though they, unfortunately, cannot be distributed in the same
    unproblematic way;
  \item Secondly, the amount of data communicated through this platform is
    growing so rapidly, that the need for the automatic processing of them is
    as urgent as it has never been before for any other kind of social media;
  \item Thirdly, the language of tweets is always at the cutting edge of the
    modern language development.  The free, uncensored way in which people can
    post their information allows for quick responses to any changes in modern
    technology and society.  These changes certainly get reflected in the
    language that people use, and one, of course, could expect that some of
    the changes introduced into the language of the Web might sooner or later
    find their way into the norm of the standard language.  Therefore,
    studying peculiarities of tweets might help us better predict the
    evolution of other linguistic norms;
  \item Fourthly, microblogs renownedly proliferate with various kinds of
    social media-specific phenomena.  Some of these phenomena like, for
    example, @-mentions or \#hashtags are so predominant that they even have
    started penetrating other online platforms like
    Facebook\footnote{\url{https://www.facebook.com/}},
    Instagram\footnote{\url{instagram.com/}},
    Myspace\footnote{\url{https://myspace.com/}} etc.  Therefore, studying
    Twitter might help us better understand peculiarities of other online text
    genres;
  \item Finally, due to a programmatic restriction of the maximal tweet length
    to 140 characters, the concentration of the above mentioned phenomena is
    allegedly one of the highest among all social media types.  Therefore,
    techniques that turn out to bring good results for Twitter might be even
    more efficient for treating data coming from other platforms.
\end{itemize}

%% The justification for choosing precisely this genre as typical
%% representative of the ensemble of online languages is given in Section
%% \ref{sct:intro:twitter}.
The object of our research will be lingustic differences of Twitter
data from the standard language texts and the impact of these
differences on the performace of NLP applications.

\section{Contributions and Outline of this Work}
