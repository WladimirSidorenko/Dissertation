% FILE: main.tex  Version 2.1
% AUTHOR:
% Universität Duisburg-Essen, Standort Duisburg
% AG Prof. Dr. Günter Törner
% Verena Gondek, Andy Braune, Henning Kerstan
% Fachbereich Mathematik
% Lotharstr. 65., 47057 Duisburg
% entstanden im Rahmen des DFG-Projektes DissOnlineTutor
% in Zusammenarbeit mit der
% Humboldt-Universitaet zu Berlin
% AG Elektronisches Publizieren
% Joanna Rycko
% und der
% DNB - Deutsche Nationalbibliothek

\chapter{Discourse-Aware Sentiment Analysis}


\section{Data Preparation}\label{sec:cgsa:data}

\section{Discourse-Aware Sentiment Analysis Methods}

% \done[inline]{\citet{Bickerstaffe:10}}

% \citet{Bickerstaffe:10} also considered the rating prediction task,
% addressing this problem with the minimum-spanning-tree (MST) SVM
% approach.  In the initial step of this method, they constructed a
% strongly connected graph whose vertices were associated with the most
% representative example (determined via the average all-pairs Tanimoto
% coefficient) of each star rating and the edge weights represented the
% Tanimoto distances between those nodes.  Afterwards, they determined
% the MST of this graph using the Kruskal's
% algorithm~\cite[see][pp.~567--574]{Cormen:09} and, finally,
% constructed a decision tree from this MST, replacing the MST vertices
% with binary SVM classifiers, which had to discern the respective
% rating groups. An evaluation on the four-star review corpus
% of~\citet{Pang:05} showed an improvement by up to~7\% over the
% previous state of the art, boosting it to 59.37\% average accuracy.


\done[inline]{\citet{Pang:02}}

\citet{Pang:02}, who experimented with three different approaches to
document-level sentiment analysis---Na{\"i}ve Bayes, Maximum Entropy,
and SVM with unigram and bigram features, pointed out that it was
insufficient to rely on the mere presence or majority of certain
polarity clues because these clues could any time be negated by a
single antithesis relation (see Example~\ref{disc-snt:exmp-pang02}
from \citet{Pang:02}).

\begin{example}[Polarity reversal via discourse antithesis]\label{disc-snt:exmp-pang02}
  \noindent\upshape This film should be brilliant.  It sounds like a
  great plot, the actors are first grade, and the supporting cast is
  good as well, and Stallone is attempting to deliver a good
  performance.  However, it can't hold up.
\end{example}

\done[inline]{\citet{Pang:04}}

One of the first approaches to coarse-grained sentiment analysis that
explicitly addressed discourse phenomena was presented
by~\citet{Pang:04}.  In their seminal work on predicting the semantic
orientation of movie reviews, the authors emphasized the need for
restricting the input to the polarity classifer to only subjective
sentences, ignoring objective ones which could easily confuse the
predictor.  To deal with this problem, they trained another
classification system which first assigned an initial subjectivity
value to every sentence in text; then constructed a graph, connecting
each sentential node to the nodes of its its neighbors and two
additional sink vertices representing the subjective and objective
classes; and, finally, devided this graph into two parts, allocating
all sentences to either of the two sinks and finding a minimum-cut
partition.

\done[inline]{\citet{Hu:04}, Section 3.6}

Similarly, \citet{Hu:04} in their work on mining and summarizing
customer reviews used discourse clues as a fallback strategy for
determining user's opinion about particular product features: The
authors first tried to determine the attitude toward a feature by
simply counting the number of postive and negative terms appearing in
the same sentence as the mentioned product aspect.  In case of a tie,
they resorted to counting these clues in the immeadiate nearby context
of the feature, and, if these also were equal, used the polarity of
the previous opinionated sentence, reversing it to the opposite if the
current sentence started with ``\emph{but}''.

\done[inline]{\citet{Mao:06}}

\citet{Mao:06} proposed the idea of isotonic CRFs in which they
explicitly modeled the constraint that features which were stronger
associated with either polarity classes had to have higher
coefficients than less predictive attributes.  After proving that this
formalism also allowed to directly model the ordinal scale of
sentiment scores (with lower CRF outputs indicating the negativity of
a sentence, and higher scores showing its positive class), the authors
used this approach to model the sentiment flow in a document.  For
this purpose, they first predicted the polarity value for each
sentence of a document in isolation and then convolved these outputs
with a Gaussian kernel, getting a smoothed polarity curve for the
whole analyzed text at the end.

\done[inline]{\citet{Polanyi:06}}

\citet{Polanyi:06} listed connectors and discourse relations among the
most important factors which could significantly change the intensity
and polarity of opinionated words.  They claimed that concessive links
between discourse segments might significantly weaken the strength of
an opinion, and, vice versa, elaborations on sentiments might notably
increase their persuasiveness.

\done[inline]{\citet{Thomas:06}}

\citet{Thomas:06} enhanced an SVM-based sentiment classification
system for predicting speaker's attitude in political speeches with
information about the inter-speaker agreement, incorporating these
links into the global cost function.  Thanks to this change, the
authors achieved $\approx$4\% improvement in accuracy (from 66.05 to
70.81\%) over the baseline classifer which analyzed each utterance in
isolation.

\done[inline]{\citet{McDonald:07,Sadamitsu:08}}

\citet{McDonald:07} proposed a joint framework for simultaneously
predicting the polarity of a document and its constituent parts (which
could be either paragraphs or sentences).  For this purpose, the
authors considered the semantic orientation of the whole text and its
single sentences as latent variables in a Markov random field,
connecting each unobserved sentence polarity node to the nodes of the
adjacent clauses as well as the overal polarity node of the complete
document, and then figuring out the best configuration of all
unobserved variables at the end.  With this method, they could
outperform both sentence- and document-level classifiers which
predicted the polarity classes of their input in isolation
(disregarding the context and hierarchical structure), and even
surpassed a cascaded system where the output of a sentence classifier
was fed into a document-level predictor, achieving 62.6\% sentence
accuracy (for three classes) and 82.8\% document-level precision (for
two classes) on a corpus of 600 reviews.  A similar approach was also
suggested by~\citet{Sadamitsu:08} who attained 82.74\% accuracy at
predicting the polarity class of customer reviews using hidden
conditional random fields and also looking for the most probable joint
configuration of sentence and document labels.

\done[inline]{\citet{Snyder:07}}

\citet{Snyder:07} proposed a Good Grief algorithm for jointly
predicting users' evaluations of different restaurant aspects.  For
this purpose, they first classified the attitude of the user to each
single predefined trait (food, ambience, service, etc.) and then
applied another clasifier in order to predict whether these scores
should rather agree or disagree with each other.  In the final step,
the authors looked for the ranking which best satisfied both of the
above predictions (i.e., ranks of individual aspects and their overall
agreement), achieving this way 0.632 ranking loss on a corpus of
$\approx$4,500 reviews and outperforming the renowned PRank algorithm
\cite{Crammer:01} which determined the rank for each aspect in
isolation.

\done[inline]{\citet{Voll:07}}

The effect of discourse phenomena was also pointed out by
\citet{Voll:07} who noted the fact that the mere occurrence of
positive or negative terms in a text was not necessarily indicative of
its main polarity if these terms appeared in off-topic sentences or
subordinate clauses.  To check this hypothesis, the authors compared
three different approaches to lexicon-based classification of customer
reviews:
\begin{inparaenum}[(i)]
\item by simply applying the SO-CAL system to all adjectives appearing in
the review,
\item by only taking into account those ones which appeared in the
  top-post nuclei of the sentences (as defined by the Rhetorical
  Structure Theory), and
\item by restricting the SO-CAL's input to clauses which had been
  previously preclassified as belonging to the main topic of the text.
\end{inparaenum}
They found the last option working best, yielding 73\% accuracy for
this two-class prediction task on the Epinion review corpus
of~\citet{Taboada:06}.  Unfortunately, the RST-based method did not
improve upon the baseline and resulted in only 69\% precision.  This,
however, might be partially due to the fact that the authors
completely ignored all nuclei and satellites within sentences except
for the main ones, did not consider the discourse relations between
the RST nodes, and also completely ignored all inter-sentential links.

\done[inline]{\citet{Somasundaran:08a,Somasundaran:08}}

\citet{Somasundaran:08a,Somasundaran:08} introduced the concept of
\emph{opinion frames} (OF)---special data structures for capturing the
relations between opinions in the discourse.  Depending on the type of
the opinions (either arguing~[\emph{A}] or sentiment~[\emph{S}]),
their polarity towards the targets (either positive~[\emph{P}] or
negative~[\emph{N}]), and semantic relationship between the two
targets (either alternative~[\emph{Alt}] or same~[\emph{same}]), they
distinguished 32 types of such frames: \emph{SPSPsame},
\emph{SPSNsame}, \emph{APAPalt}, etc., dividing them into reinforcing
and non-reinforcing ones; and also demonstrated the amenability of
this concept to automatic classification and its utility to
disambiguating the polarity of specific opinions.  Nevertheless, as
noted by the authors, OF and common discourse analysis frameworks,
although frequently going hand in hand, were not redundant to each
other, so that reinforcing frames could be expressed by both
contrastive and non-contrastive discourse relations, and vice-versa
non-reinforcing frames were not necessarily bound to a contrast in the
discourse.

\done[inline]{\citet{Somasundaran:09a,Somasundaran:09b}}

In a later work, \citet{Somasundaran:09b,Somasundaran:09a} also
introduced a joint inference framework based on the Iterative
Classification Algorithm (ICA) and Integer Linear Programming (ILP)
for joinly predicting the best configuration of single opinions and
their frames.  In this approach, the authors first applied a local SVM
classifier to compute the probabilities of polarity classes (positive,
negative, or neutral) of individual dialog acts and then harnessed the
ICA and ILP systems to determine which of the predicted opinions were
connected via opinion frames and whether these frames were reinforcing
or not.  Given a perfect information about the opinion links, this
joint method outperformed the local classifier by more than 9
percentage points, reaching 77.72\% accuracy on the AMI meeting
corpus~\cite{Carletta:05}.

\done[inline]{\citet{Asher:08}}

\citet{Asher:08} presented an annotation scheme and pilot corpus of
English and French texts labeled according to these guidelines, in
which they tried to explicitly take the SDRT theory as a basis for
sentiment representation.  For this purpose, the authors first asked
their annotators to analyze the segmented discourse structure of the
corpus texts and then ascribe one of the four major opinion categories
(reporting, judgement, advice, or sentiment) along with their
subcategories (e.g., inform, assert, blame, recommend) to each
discourse unit which featured at least one opinionated word from a
lexicon.  Afterwards, they showed that, with a simple set of rules,
one could easily propagate these opinions through the discourse
graphs, increasing the strengths or reversing the polarity of
sentiments depending on the type of discourse relations that connected
the segments.

\done[inline]{\citet{Yessenalina:10}}

Similarly, \citet{Yessenalina:10} proposed a latent-variable approach
in which they tried to predict the overall polarity of a document by
jointly selecting a subset of sentences which were most indicative of
document's semantic orientation and predicting the document's class
(either positive or negative) based on this subset.  To achieve this
goal, the authors adopted the latent-SVM method of \citet{Yu:09},
training a linear classifier on individual sentences with latent
classes and making the final prediction using 30\% of the sentences
which this classifier was most sure about.  To account for discourse
phenomena, they also enhanced feature representations of analyzed
sentences with attributes extracted from their preceding clauses and
added characteristics of the whole document to the model.  This way,
\citet{Yessenalina:10} attained 93.22\% accuracy on the movie review
corpus of \citet{Pang:04} and scored 77.09\% on the collection of
congressional floor debates introduced by \citet{Thomas:06}.

\done[inline]{\citet{Trivedi:13}}

Later on, \citet{Trivedi:13} refined this approach by introducing
special \emph{connector-augmented} transition features, which
reflected whether an explicit connector at the beginning of a sentence
implied a \emph{continuation} or \emph{shift} of the polarity of the
preceding discourse unit.  These attributes turned out to be extremely
useful, boosting the prediction accuracy on the movie review corpus
of~\citet{Maas:11} from 88.21 to 91.36\% in comparison with the
connector-unaware model.

\done[inline]{\citet{Heerschop:11}}

\citet{Heerschop:11} compared three different ways of incorporating
discourse information into a lexicon-based sentiment analysis system:
by increasing polarity scores of words that appeared near the end of
the document, by assigning higher weights to the tokens in the nuclei
of RST trees than its satellites, and, finally, by training a genetic
algorithm which learned separate coefficients for the nuclei and eight
types of satellite relations (\textsc{Attribution},
\textsc{Background}, \textsc{Cause}, etc.).  An evaluation of these
approaches on the movie review corpus of~\citet{Pang:04} showed the
superior performace of the first option (0.608 accuracy and 0,597
macro\F).  However, after adding an offset to the decision boundary
(accounting for the fact that negative reviews could contain multiple
positive terms) significantly improved the results of the last
classifier, which eventually outperformed all other competitors,
yielding 0.72 accuracy and macro-averaged~\F.

\done[inline]{\citet{Zhou:11}}

\citet{Zhou:11} used automatically derived RST trees to disambiguate
the polarity of complex sentences which contained both positive and
negative terms.  To determine the semantic orientation of the whole
sentence, the authors applied a set of heuristic rules that described
possible polarity changes of elementary discourse units based on their
nucleus/satellite-status and discourse relation connecting them to the
parent.  With these rules, \citeauthor{Zhou:11} attained a
statistically significant improvement in sentence-level polarity
classification on the NTCIR MOAT corpus~\cite{Xu:10}, successfully
resolving more than a half of ambiguities.

\done[inline]{\citet{Zirn:11}}

An approach which probably comes closest to ours was proposed
by~\citet{Zirn:11}, who used a lexicon-based sentiment system to
compute polarity scores of elementary discourse units, and then
applied a set of Markov logic rules to enforce consistency of these
polarity assignments over an automatically derived RST tree.  Apart
from experimenting with tree structures, the authors also checked
whether simply preferring the same semantic orientation for linearly
adjacent segements would improve the accuracy.  Surprisingly, this
latter option worked the best, achieving 69.02\% accuracy on the
Amazon review dataset of~\citet{Blitzer:07} and significantly
outperforming both discourse-unaware and RST-tree--based baseline
classifiers.

\done[inline]{\citet{Wang:13},\citet{Chenlo:13,Chenlo:14}}

Another RST-based framework was proposed by~\citet{Wang:13} who also
computed polarity scores of elementary discourse segments, and
determined the polarity of the whole document by computing a linear
combination of these scores multiplied with their doscourse
coefficients.  These coefficients were learned automatically during
training and, similarly to the approach of~\citet{Zirn:11}, depended
on the status of the segment in the RST tree (either nucleus or
sattelite) and the relation connecting it to the ancestor node.  Using
a restricted subset of such relations (\textsc{Contrast},
\textsc{Cause}, \textsc{Generalization}, and \textsc{Condition}), the
authors achived a considerable improvement over the baseline system in
which all segments were weighted equally (0.8528 versus 0.8386\F).  A
similar method was also used by \citet{Chenlo:13,Chenlo:14} for
analyzing blog posts, where it also proved its efficiency, leading to
much better results than discourse-unaware baselines.

\done[inline]{\citet{Bhatia:15}}

Other ways of incorporating discourse structure into an opinion mining
application were proposed by~\citet{Bhatia:15} who presented two
methods for augmenting a sentiment analysis system with discourse
information:
\begin{inparaenum}[(i)]
\item discourse depth reweighting (DDR) and
\item rhetorical recursive neural network (R2N2).
\end{inparaenum}

In the former approach, the authors first computed the sentiment score
$\lambda_i$ of each elementary discourse unit $i$ as:
\begin{equation*}
  \lambda_i = \max\left(0.5, 1 - d_i/6\right),
\end{equation*}
where $d_i$ stands for the depth of the $i$-th EDU in the discourse
tree of the whole document.  Afterwards, they estimated the overall
polarity of the document~$\Psi$ by summing up the linear predictions
for each discourse unit ($\theta^T\cdot\mathbf{w}_i$), scaling these
prediction by the factor~$\lambda_i$:
\begin{equation*}
  \Psi = \sum_i\lambda_i\mathbf{\theta}^T\cdot\mathbf{w}_i = \mathbf{\theta}^T\cdot\sum_i\lambda_i\mathbf{w}_i,
\end{equation*}
In this equation, $\mathbf{\theta}$ represents a vector of polarity
scores ($-1$ for negative terms and $+1.$ for positive entries) for
all word in the vocabulary (as obtained from the sentiment lexicon
of~\citet{Wilson:05}), and $w_i$ denotes the bag-of-words
representation of the $i$-th EDU.

In the R2N2 method, \citet{Bhatia:15} adopted the RNN approach
of~\citet{Socher:13} and recursively computed polarity scoreb of each
discourse $i$ unit as follows:
\begin{equation*}
  \psi_i = tanh\left(K_n^{(r_i)} \psi_{n(i)} + K_s^{(r_i)}\psi_{s(i)} \right),
\end{equation*}
where $K_n^{(r_i)}$ and $K_s^{(r_i)}$ denote the nucleus an satellite
coefficients associated with the rhetorical relation $(r_i)$, and
$\psi_{n(i)}$ and $\psi_{s(i)}$ represent the sentiment scores of the
nucleus and satellite nodes of the $i$-th discourse unit.  With this
method, the authors achieved 84.1\% two-class prediction accuracy on
the moview review corpus of~\citet{Pang:04} and 85.6\% on the dataset
of~\citet{Socher:13}.

\todo[inline]{Others}

\done[inline]{\citet{Riloff:03}}

\citet{Riloff:03} added a set of discourse-related features, such as
relative sentence lengths, the average number of subjective clues in
the preceding, current, and following clauses, and the relative number
of these clues with respect to the corresponding sentence lengths,
getting more than 2\% accuracy improvement over a baseline Na{\"i}ve
Bayes classifier which did not utilize this information.

\section{Evaluation}

\section{Summary and Conclusions}
