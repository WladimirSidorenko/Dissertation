\chapter{Coarse-Grained Sentiment Analysis}\label{sec:snt:cgsa}

\section{Coarse-Grained Sentiment Analysis with Lexicon-Based Methods}

\section{Coarse-Grained Sentiment Analysis with Machine Learning
  Frameworks}

\section{Coarse-Grained Sentiment Analysis with Deep Neural Networks}

\section{Coarse-Grained Sentiment Analysis using Language and Domain
  Adaptation}

\section{Evaluation}
\subsection{Effect of Distant Supervision}
\subsection{Effect of Normalization}

\section{Related Work}

\textbf{Lexicon-Based Methods}

Bruce and Wiebe, 2004

Hu and Liu, 2004

\citet{Kim:04} experimented with three different methods of
determining the overall polarity of a sentence:
\begin{inparaenum}[(i)]
  \item by multiplying the signs of polar terms found in sentence,
  \item taking their sum, and
  \item taking the geometric mean of polarity scores;
\end{inparaenum}
finding that the first and last options worked best for the Document
Undestanding Corpus.\footnote{\url{http://duc.nist.gov/}}

% Intensity Classification
Polanyi and Zaenen (2006)

\citet{Kennedy:06}

Taboada and Grieve (2004)

Taboada, Anthony, and Voll (2006)

Finally, a veritably seminal work on lexicon-based approaches was
introduced by~\citet{Taboada:11} who presented a manually compiled
sentiment lexicon,\footnote{The authors hand-annotated all occurrences
  of adjectives, nouns, and verbs found in a corpus of 400 Epinions
  reviews with ordinal categories ranging from -5 to 5 which reflected
  the semantic orientation of a term (positive vs. negative) and its
  polar strength (weak vs. strong).} and used this resource to compute
the overall \emph{semantic orientation} (SO) of text.  Inspired by the
ideas of~\citet{Polanyi:06}, to make this calculation more precise,
the authors also incorporated a set of additional heuristic rules by
changing the prior SO values of negated, itensified, and downtoned
terms, ignoring irrealis sentences, and adjusting weights of specific
sections of a document.  An extensive evaluation of this method showed
a superior performance of the manual lexicon in comparison with other
polarity lists including the Subjectivity Dictionary~\cite{Wilson:05},
Maryland Polarity Set~\cite{Mohammad:09}, and
\textsc{SentiWordNet}~\cite{Esuli:06c}.  Moreover, the authors also
proved the robustness of their SO computation procedure for other
topics and text genres, hypothesizing that lexion-based approaches
were more domain-independent than traditional supervised learning
techniques.

\textbf{Traditional Supervised Machine Learning Frameworks}

One of the first attempts to analyze message-level sentiments on
Twitter was made by \citet{Go:09}.  For their experiments, the authors
collected a set of 1,600,000 tweets containing smileys.  Based on
these emoticons, they automatically derived polarity classes for these
messages (positive or negative) and used them to train a Na\"{\i}ve
Bayes, MaxEnt, and SVM classifier.  The best $F$-score for this
two-class classification problem could be achieved by the last system
and run up to 82.2\%.

Similar work was also done by \citet{Pak:10} who used the Na\"{\i}ve
Bayes approach to differentiate between neutral, positive, and
negative microblogs; and \citet{Barbosa:10} who gathered a collection
of 200,000 tweets, subsequently analyzing them with three publicly
available sentiment web-services and training an SVM classifier on the
results of these predictors.  In a similar way, \citet{Agarwal:11}
compared a simple unigram-based SVM approach with two other
full-fledged systems, one which relied on a rich set of manually
defined features, and another used partial tree
kernels~\cite{Moschitti:06}.  The authors evaluated these methods on a
commercially acquired corpus of 8,753 foreign-language tweets, which
were automatically translated into English, finding that a combination
of these methods worked best for both two- and three-way prediction
tasks.

The state-of-the-art results for message level polarity prediction on
tweets were established by~\citet{Mohammad:13}, whose system (a
supervised SVM classifier) used a rich set of various features
including word and character n-grams, PoS statistics, Brown
clusters~\cite{Brown:92}, etc., and also strongly benefitted from
automatic corpus-based polarity lists---Sentiment~140 and NRC
Hashtag~\cite{Mohammad:12,Kiritchenko:14}.  This approach ranked first
at the SemEval competition~2013~\cite{Nakov:13} and anchieved the
fourth place on the rerun of this task one year
later~\cite{Rosenthal:14}, being outperformed by the supervised
logistic regression approach of~\citet{Miura:14}, who used a heavy
preprocessing of the data and a special balancing scheme for
underrepresented classes.  Later on, these results were further
improved by the apporaches of~\citet{Hagen:15} and \citet{Deriu:16},
which both relied on ensembles of multiple independent classifiers.

\cite{Nakagawa:10}

Wiebe 2002, Riloff 2003

Wiebe, Bruce, \& O'Hara 1999
Hatzivassiloglou \& Wiebe 2000
Wiebe 2000;
Wiebe et al. 2002
Yu \& Hatzivassiloglou 2003

\textbf{Deep Neural Networks}

\citet{Yessenalina:11}

A real breakthrough in the use of deep neural networks for the
sentence-level sentiment analysis happened with the pioneering work
of~\citet{Socher:11}, who first introduced a recursive autoencoder
(RAE).  In this system, the authors obtained a fixed-width vector
representation for complex phrases $\vec{v}$ by recursively merging
the vectors of adjacent tokens (say $\vec{w}_1$ and $\vec{w}_2$),
first multiplying these vectors with a compositional matrix $W$ and
then applying a non-linear function ($softmax$) to the resulting
product:
\begin{align*}
  \vec{c} &= softmax\left(W\cdot\begin{bmatrix}
  \vec{w}_1\\
  \vec{w}_2
  \end{bmatrix}\right)
\end{align*}
Using a max-margin classifier on top of the resulting phrase
representation, \citet{Socher:11} could improve the state-of-the-art
results on predicting the sentence-level polarity of user's blog
posts~\cite{Potts:10} and also outperformed the system
of~\citet{Nasukawa:03} on the MPQA data set~\cite{Wiebe:05}.

Later on, \citet{Socher:12} further improved these scores with the
help of a recursive matrix-vectors space model (RMVSM), in which each
word was associated with a 2-tuple of a vector and matrix---e.g.,
$(\vec{w}_1, W_1)$ and $(\vec{w}_2, W_2)$---and the compositionality
function was redefined as follows:
\begin{align*}
  \vec{c} &= softmax\left(W\cdot\begin{bmatrix}
  W_2\cdot\vec{w}_1\\
  W_1\cdot\vec{w}_2
  \end{bmatrix}\right)
\end{align*}

\citet{Wang:15}

\textbf{Language and Domain Adaptation}

One of the first works which pointed out the importance of domain
adaptation in sentiment analysis was presented by~\citet{Aue:05}.  In
their experiments, the authors trained separate SVM classifiers on
four different document collections: movie revies, book reviews,
customer feedback from a product support service, and a feedback
survey from a customer knowledge base; finding that each classifier
performed best when applied to the same domain as it was trained on.
In order to find an optimal way of overcoming this domain specificity,
\citet{Aue:05} tried out four different options:
\begin{inparaenum}[(i)]
\item\label{sent-cgsa:lst:rel-wrk1} training one classifier on all but
  the target domain and applying it to the latter;
\item using the same procedure as above, but limiting the features to
  only those which also appeared in the target texts;
\item taking an ensemble of individual classifiers each of which was
  trained on a different data collection; and, finally,
\item using a minimal subset of labeled in-domain data to train a
  Na{\"i}ve Bayes system with the expectation-maximization
  \cite[EM;][]{Dempster:77} algorithm.
\end{inparaenum}
The authors found the ensemble and EM options working best for their
cross-domain task, achieving an accuracy of up to 82.39\% for the
two-class prediction (positive vs negative) on new unseen text genres.

Another notable contribution to the domain adaptation research was
made by~\citet{Blitzer:07}.  Relying on their previous work on
structural correspondence learning~\cite{Blitzer:07}, in which they
used a set of \emph{pivot features} (features which frequently
appeared in both target and source domains) to find an optimal
correspondence of the remaining attributes,\footnote{In particular,
  the authors trained $m$ binary predictors for each of their $m$
  pivot features in order to find other attributes which frequently
  co-occurred with the pivots.  Afterwards, they composed these $m$
  resulting weight vectors into a single matrix
  $W := [\vec{w}_{1},\ldots,\vec{w}_{m}]$, took an SVD decomposition
  of this matrix, and used the top $h$ left singular vectors to
  translate source features to the new domain.} the authors refined
their method by pre-selecting the pivots using their PMI scores and
improving misaligned feature projections using a small set of labeled
target examples.  With these modifications, \citeauthor{Blitzer:07}
were able to reduce the average adaptation loss (the accuracy drop
when transferring a classifier to a different domain) from 9.1 to
4.9~percent when testing on the domains of book, dvd, electical
appliances, and kitchen reviews.

Other important works on domain adaptation for sentiment analysis
include those of~\citet{Read:05} who pointed out that sentiment
classification might not only depend on domain but also on topic,
time, and language style in which the text was written; \citet{Tan:07}
who proposed using the classifier trained on the source domain to
classify unlabeled instances from the target genre, and then
iteratively retrain the system on the enriched data set.  Finally,
\citet{Andreevskaia:08} proposed a combination of a lexicon- and
ML-based system, claiming that this ensemble would be more resistible
to the domain shift than each of these systems on their own.

Another line of research was introduced by~\citet{Glorot:11} who
proposed stacked denoising autoencoders (SDA)---a neural network
architecture in which an input vector $\vec{x}$ was first mapped to a
smaller representation $\vec{x}'$ via some function
$h: \vec{x}\mapsto\vec{x}'$, and then restored to its approximate
original state via an inverse transformation
$g: \vec{x}'\mapsto\vec{x}''\approx\vec{x}$.  In their experiments,
the authors optimized the parameters of the functions $h$ and $g$ on
both target and source data, getting approximate representations of
instances from both data sets; and then trained a linear SVM
classifier on the restored representations of the source instances,
subsequently applying this classifier to the target domain.  This
approach was further refined by~\citet{Chen:12} who analytically
computed the reconstruction function~$g$, and used both original and
restored features to predict the polarity labels of the target
data.\footnote{Both approaches were trained tested on the Amazon
  Review Corpus of~\citet{Blitzer:07}.}


Further notable contributions to domain adaptation in general were
made by~\citet{Daume:07} who proposed to replicate each extracted
feature three times and train the first replication on both domains,
the second repetion only on source, and the third copy only on target
domain, for which he assumed a small subset of labeled examples was
available; \citet{Yang:15} who trained neural embeddings of features,
trying to predict which instance attributes frequently co-occured with
each other;

\citet{Ganchev:10}

Xue, 2008

\todo[inline]{Add description}

\section{Summary and Conclusions}\label{slsa:subsec:conclusions}
