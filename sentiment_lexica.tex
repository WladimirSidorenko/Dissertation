% FILE: sentiment_lexica.tex  Version 0.01
% AUTHOR: Uladzimir Sidarenka

% This is a modified version of the file main.tex developed by the
% University Duisburg-Essen, Duisburg, AG Prof. Dr. Günter Törner
% Verena Gondek, Andy Braune, Henning Kerstan Fachbereich Mathematik
% Lotharstr. 65., 47057 Duisburg entstanden im Rahmen des
% DFG-Projektes DissOnlineTutor in Zusammenarbeit mit der
% Humboldt-Universitaet zu Berlin AG Elektronisches Publizieren Joanna
% Rycko und der DNB - Deutsche Nationalbibliothek

\section{Sentiment Lexica}
\subsection{Ontology-based Identification of Subjective Elements}
\subsection{Corpus-based Identification of Subjective Elements}
\subsection{Machine Learning Approaches to Identification of Subjective Expressions}

\subsection{Related Work}

Among the first who addressed the problem of the automatic generation
of sentiment lexica were \citet{Hatzivassi:97}.  In their work, the
authors relied on the hypothesis that coordinatively conjoined terms
often share the same semantic orientation.  To test this conjecture,
they automatically extracted all pairs of conjoined adjectives from
the Wall Street Journal (WSJ) corpus and represented these adjectives
as nodes in a graph.  The arcs weights of this graph were supposed to
show the strength and direction by which two coordinatively conjoined
terms influenced each others' polarity.  In order to derive these
weights automatically, \citeauthor{Hatzivassi:97} trained a log-linear
regression model on those pairs in which both nodes belonged to a
manually labeled seed set of 1,336 adjectives and then let this model
predict the weights for the rest of the arcs.  In the final step, the
resulting graph was partitioned into two clusters -- that of positive
and that of negative terms -- which were subsequently used to enrich
the seed set.  This method, enhanced by the possibility of recognizing
gradable adjectives, was later used in the classification experiments
of \citet{Hatzivassi:00} to predict subjective and objective sentences
in the WSJ.

A different way of bootstrapping polarity terms from large text
corpora was proposed by \citet{Turney:03}.  Following
\citeauthor{Turney:02}'s original approach for classifying reviews
\citep{Turney:02}, they generated a polarity lexicon by first taking a
seed set of 14 a priory known polar adjectives (seven negative and
seven positive) and then expading this set with the words that had the
strongest pointwise mutual information associations with the chosen
seeds.  The PMI scores were computed as the log ratio between the
number of hits in which a new word $w$ appeared with any of the seed
terms divided by the total number of hits for the complete seed set.
As hits, the authors considered the number of relevant documents
returned by \texttt{AltaVista} for given search queries.  This system
attained an accuracy of 82.84\% on the General Inquirer Lexicon
\citep{Stone:66} and correctly predicted polar terms from the lexicon
of \cite{Hatzivassi:97} in 87.13\% of the cases. This method could
also further be improved by using cosine similarities between word
vectors from an LSA matrix instead of web-based PMIs.

One of the allegedly first attempts to derive a sentiment lexicon from
a lexical ontology was made by \citet{Kim:04}.  In their work, the
authors expanded their initial seed set of 34 adjectives and 44 verbs
to a list of 18,192 presumably polar terms by iteratively enriching
the seed words with their synonyms and antonyms from the WordNet
database \citep{Miller:95}.

%% Another
%% interesting finding of this paper was surpassed by using the cosine
%% similarities between word vectors in an LSA matrix instead of PMI
%% scores from web crawlers.

%% More precisely, the social orientation PMI (SO-PMI) of a new word
%% $w$ was defined as: \begin{equation*} \text{SO-PMI}(w) =
%% \log_2\bigg(\frac{\prod_{p\in\mathcal{P}}\text{hits}(w\text{NEAR}p)%
%% \prod_{n\in\mathcal{N}}\text{hits}(w\text{NEAR}n)}%
%% {\prod_{p\in\mathcal{P}}\text{hits}(p)\prod_{n\in\mathcal{N}}\text{hits}(n)}\bigg) \end{equation*}
%% where $\mathcal{P}$ and $\mathcal{N}$ are the seed sets of positive
%% and negative adjectives respectively and
%% $\text{hits}(\cdot\text{NEAR}\cdot)$ is the number

\citet{Takamura:05} applied the Ising spin model from the statistical
mechanics to determine the semantic orientation of words.  They
represented all words found in \emph{WordNet} \cite{Miller:95}, the
Wall Street Journal, and the Brown corpus as nodes in a graph.  The
edges of this graph represented associativity links and were
established between two words if one of these word was a synonym, an
antonym, or a hyponym of the other one or appeared in its gloss or
context.  Taking into account the a priori known polarities of some of
the terms, the Ising model then tried to find an approximation of the
most likely polarity combination of all terms over all possible
assignments.

%% The authors evaluated the accuracy of their model on the General
%% Inquirer lexicon \cite{Stone:66}.  Its final results (81.9\%) were
%% comparable to the figures obtained by \citet{Turney:03} in their
%% method (82.84\%) and significantly outperformed the precision of
%% the approach proposed by \citet{Kamps:04} (73.4 versus 70.8).

A purely dictionary-based method for generating sentiment lexicons was
proposed by \citet{Esuli:06b}.  The authors automatically assigned
positive, negative, and neutral polarity scores to synsets in
\emph{WordNet} by iteratively expanding seed sets for each of these
three polarity classes using a committee of binary and multiclass
classifiers.  At each step of this process, these classifiers were
trained on the seed sets obtained from the previous runs and then used
to predict if further synsets immediately accessible from the seeds
would belong the same polarity class as their seed term.

\subsubsection{Sentiment Lexica for German}

One of the first attempts to create a sentiment dictionary for German
was made by \citet{Remus:10}.  In their work, the authors
automatically translated the General Inquirer lexicon \cite{Stone:66}
into German.  In order to incorporate domain-specific knowledge into
this translated resource, they also collected a set of terms that were
strongly associated with positive or negative product reviews and
added this set to their translations.  Finally, the resulting lexicon
was enriched with inflection forms and frequent collocations of the
translated expressions.  The authors automatically estimated polarity
scores of their obtained 3,648 lexicon lemmas as the difference
between their positive and negative PMIs (i.e. PMI scores between the
collected terms and the pre-defined sets of positive or negative
expressions).

Similar work was also done by \citet{Waltinger:10} who compiled a list
of 10,141 subjective terms by first automatically translating the
Subjectivity Clues lexicon \cite{Wilson:05} and then manually
reassessing polarity scores of the translated items.  The author
expanded this list with the most frequent German synonyms of the
translated terms and also added a set of negated opinionated phrases
(e.g. \emph{nicht schlecht} (\emph{not bad})).  The resulting
dictionary was used as a source of features for an automatic
classification of the polarity of Amazon reviews and showed superior
accuracy in comparison with other automatically translated resources.

A slightly different approach was taken by \citet{Clematide:10} who
manually annotated synsets from \emph{GermaNet} \cite{Hamp:97} with
their prior polarities and polarity strengths.  A subsequently
conducted study revealed, however, that the stock of polar adjectives
obtained in this way was insufficient for doing proper subjectivity
analysis of literary texts.  In order to overcome this problem, the
authors followed the idea of \citet{Hatzivassi:97} and extracted an
additional set of 918 adjectives which frequently co-occurred in
conjoined phrases with subjective terms from their dictionary.  After
manually inspecting each of the candidate terms, the authors added
this pruned set of new adjectives to their original lexicon.  The
total size of this final dictionary run up to 7,432 entries, 2,779 of
which were positive.

\subsection{Domain-Specific Sentiment Lexica}

\citet{Chetviorkin:14} obtained a set of possible subjective terms
from English and Russian microblogs by using an ensemble of supervised
machine learning classifiers that had previously been trained on a
manually annotated corpus of movie reviews.  In order to determine the
prior polarity of the extracted terms, the authors first calculated
approximate polarity scores of the processed messages using general
polarity lexicons and then took these rough estimates as prior
polarity expectations of the candidate expressions.  The posterior
scores of these expressions were computed using the Ising spin model
in a similar way to the approach proposed by \citet{Takamura:05}.  The
resulting lexicon comprised 2,772 words for Russian and 2,786 lexical
items for English.


\subsection{Conclusions}
