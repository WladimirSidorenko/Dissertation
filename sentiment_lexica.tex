% FILE: sentiment_lexica.tex  Version 0.01
% AUTHOR: Uladzimir Sidarenka

% This is a modified version of the file main.tex developed by the
% University Duisburg-Essen, Duisburg, AG Prof. Dr. Günter Törner
% Verena Gondek, Andy Braune, Henning Kerstan Fachbereich Mathematik
% Lotharstr. 65., 47057 Duisburg entstanden im Rahmen des
% DFG-Projektes DissOnlineTutor in Zusammenarbeit mit der
% Humboldt-Universitaet zu Berlin AG Elektronisches Publizieren Joanna
% Rycko und der DNB - Deutsche Nationalbibliothek

\section{Sentiment Lexica}\label{sec:snt:lex}

Along with sentiment corpora, sentiment lexica are commonly considered
to be one of the most fundamental building blocks of many modern
opinion mining systems.  They serve as a valuable source of features
for machine-learning methods and act as a core element of
lexicon-based approaches.  The latter have proven to be robust
techinques for the purposes of coarse-grained sentiment analysis,
frequently surpassing even the most sophisticated statistical
algorithms.

Interestingly enough, the earlier works on sentiment lexica
\cite{Stone:66,Hatzivassi:97,Hatzivassi:00} even pre-date the official
history of sentiment analysis as an independent NLP discipline (if we
regard the allegedly first mention of this field in
\citet{Nasukawa:03} as the date of its onset).  This again confirms
the fact that extensive lists of opinionated words are an essential
prerequisite for many subsequent opinion mining tasks.

As with the sentiment analysis in general, the composition and utility
of sentiment lexica crucially depends on the domains from which they
are being sampled and to which they are being applied.

\subsection{Existing German Lexica}
\begin{table}[h]
  \begin{center}
    \bgroup \setlength\tabcolsep{0.1\tabcolsep}\scriptsize
    \small
    \begin{tabular}{|p{0.21\columnwidth}| % first columm
        *{8}{>{\centering\arraybackslash}m{0.1\columnwidth}|}} % next nine columns
      \hline
          \multirow{2}*{\bfseries Element} & \multicolumn{3}{c|}{Positive
        Expressions} & %
      \multicolumn{3}{c|}{Negative Expressions} & %
      \multirow{2}*{Macro-$F1$} & %
      \multirow{2}*{Micro-$F1$}\\\cline{2-7}

      & Precision & Recall & $F1$ & Precision & Recall & $F1$ & & \\\hline
      \multicolumn{9}{|c|}{\cellcolor{cellcolor}Existing Lexica}\\\hline

      GPC & 17.7\stddev{6.07} & 48.35\stddev{13.26} &%
      12.66\stddev{3.59} & 9.42\stddev{4.37} & 45.99\stddev{15.58} &
      7.6\stddev{3.12} & 22.51\stddev{1.9} & 89.56\stddev{1.28}\\

      SWS & 29.26\stddev{11.3} & 29.26\stddev{11.3} &
      16.39\stddev{4.95} & 36.03\stddev{14.42} & 36.45\stddev{15.29} &
      \textbf{17.16}\stddev{5.49} & 27.48\stddev{2.95} &
      95.61\stddev{0.78}\\

      ZPL & 33.00\stddev{11.69} & 31.14\stddev{10.53} &
      15.60\stddev{4.81} & 23.68\stddev{12.12} & 25.15\stddev{11.85} &
      11.76\stddev{5.37} & 25.45\stddev{2.71} & 95.93\stddev{0.66}\\

      GPC $\cap$ SWS $\cap$ ZPL & \textbf{46.22}\stddev{13.44} &
      36.43\stddev{13.46} & \textbf{19.77}\stddev{5.87} &
      \textbf{48.06}\stddev{17.22} & 26.93\stddev{12.99} &
      16.35\stddev{5.96} & \textbf{28.45}\stddev{3.16} &
      \textbf{96.94}\stddev{0.6}\\

      GPC $\cup$ SWS $\cup$ ZPL & 16.89\stddev{5.77} &
      \textbf{49.98}\stddev{12.96} & 12.35\stddev{3.49} &
      9.36\stddev{4.4} & \textbf{49.05}\stddev{15.9} &
      7.66\stddev{3.18} & 22.37\stddev{1.91} &
      88.97\stddev{1.26}\\\hline
      \multicolumn{9}{|c|}{\cellcolor{cellcolor}State-of-the-art Approaches}\\\hline

      SentiWordNet$^{\mathrm{ternary}}_{\mathrm{Rocchio}}$ & 67.09\stddev{22.16} &
      14.74\stddev{7.79} & 11.73\stddev{5.59} & 4.57\stddev{4.57} &
      5.88\stddev{5.4} & 2.48\stddev{2.37} & 21.08\stddev{2.15} &
      96.04\stddev{0.72}\\

      Ising Spin Model & \stddev{} & \stddev{} & \stddev{} & \stddev{}
      & \stddev{} & \stddev{} & \stddev{} & \stddev{}\\\hline

      \multicolumn{9}{|c|}{\cellcolor{cellcolor}Our Method}\\\hline
    \end{tabular}
    \egroup
    \caption{Classification results.\\ {\small (GPC -- German Polarity
        Clues \cite{Waltinger:10}, SWS -- SentiWS \cite{Remus:10}, ZPL
        -- Zurich Polarity Lexicon \cite{Clematide:10})}}
    \label{tbl:results}
  \end{center}
\end{table}

\subsection{Ontology-based Lexicon Generation}

\subsection{Corpus-based Lexicon Generation}

\subsection{Lexicon Induction Using Neural Word Embeddings}

\subsection{Related Work}

Among the first who addressed the problem of the automatic generation
of sentiment lexica were \citet{Hatzivassi:97}.  In their work, the
authors relied on the hypothesis that coordinatively conjoined terms
often share the same semantic orientation while adversatively linked
words rather express opposite polarities.  To test this conjecture,
they automatically extracted all pairs of conjoined adjectives from
the Wall Street Journal (WSJ) corpus and represented those adjectives
as nodes in a graph.  The arcs weights of this graph were to show the
strength and direction by which two coordinatively conjoined terms
influenced each others' polarity.  To derive these weights,
\citeauthor{Hatzivassi:97} trained a log-linear regression model on
those pairs of terms in which both nodes belonged to a manually
labeled seed set of 1,336 adjectives and then let this model predict
the weights for the rest of the arcs.  In the final step, the
resulting graph was partitioned into two clusters -- that of positive
and that of negative terms -- which were subsequently used to enrich
the initial seed set.
%% This method, enhanced by the possibility of recognizing gradable
%% adjectives, was later used in the classification experiments of
%% \citet{Hatzivassi:00} to predict subjective and objective sentences in
%% the WSJ.

A different way of bootstrapping polarity terms from large text
corpora was proposed by \citet{Turney:03}.  Following
\citeauthor{Turney:02}'s original approach for classifying reviews
\citep{Turney:02}, the authors generated a polarity lexicon by first
taking a seed set of 14 a priory known polar adjectives (seven
negative and seven positive ones) and then expading this set with the
words that had the strongest pointwise mutual information associations
with the chosen seeds.  The PMI scores were computed as the log ratio
between the number of times a new word $w$ appeared with any of the
seed terms, divided by the total number of search hits for the
complete seed set.  As search hits, the authors considered the number
of relevant documents returned by the \texttt{AltaVista} search engine
for the given queries.  This system attained an accuracy of 82.84\% on
the General Inquirer Lexicon \citep{Stone:66} and correctly predicted
polar terms from the lexicon of \cite{Hatzivassi:97} in 87.13\% of the
cases. %% This method could also be further improved by using cosine
%% similarities between word vectors from an LSA matrix instead of
%% web-based PMIs.

Other notable works on corpus-based lexicon induction include
\citet{Kanayama:06}, who enhanced the method of
\citeauthor{Hatzivassi:97} by incorporating iter-sentential coherence
relations.  \citet{Kaji:07} also followed a corpus-based approach as
they mined opinionated sentences from HTML pages using structural and
linguistic clues and then extracted new polar terms from these
sentences, considering words having the highest PMI association scores
with the rest of the sentences as subjective.

One of the allegedly first attempts to derive a sentiment lexicon from
a lexical ontology instead of a corpus was made by \citet{Kim:04}.  In
their work, the authors expanded an initial seed set of 34 adjectives
and 44 verbs to a list of 18,192 presumably polar terms by iteratively
enriching the seed words with their synonyms and antonyms from the
\texttt{WordNet} database \citep{Miller:95}. In a similar way,
\citet{Godbole:07} enriched their topic-specific seed sets of polar
expressions by following the synonymy and antonymy links in
\texttt{WordNet} and exponentially decreasing the probability of a new
word being polar with the growing path length from a seed term.

%% Another interesting finding of this paper was surpassed by using
%% the cosine similarities between word vectors in an LSA matrix
%% instead of PMI scores from web crawlers.

%% More precisely, the social orientation PMI (SO-PMI) of a new word
%% $w$ was defined as: \begin{equation*} \text{SO-PMI}(w) =
%% \log_2\bigg(\frac{\prod_{p\in\mathcal{P}}\text{hits}(w\text{NEAR}p)%
%% \prod_{n\in\mathcal{N}}\text{hits}(w\text{NEAR}n)}%
%% {\prod_{p\in\mathcal{P}}\text{hits}(p)\prod_{n\in\mathcal{N}}\text{hits}(n)}\bigg) \end{equation*}
%% where $\mathcal{P}$ and $\mathcal{N}$ are the seed sets of positive
%% and negative adjectives respectively and
%% $\text{hits}(\cdot\text{NEAR}\cdot)$ is the number

%% The authors evaluated the accuracy of their model on the General
%% Inquirer lexicon \cite{Stone:66}.  Its final results (81.9\%) were
%% comparable to the figures obtained by \citet{Turney:03} in their
%% method (82.84\%) and significantly outperformed the precision of
%% the approach proposed by \citet{Kamps:04} (73.4 versus 70.8).

Another purely dictionary-based method was described by
\citet{Esuli:06b}.  The authors automatically assigned positive,
negative, and neutral polarity scores to synsets in \texttt{WordNet}
by iteratively expanding seed sets for each of these three polarity
classes using a committee of binary and multiclass classifiers.  At
each step of this process, these classifiers were trained on the seed
sets obtained from the previous runs and then used to predict whether
further synsets immediately accessible from the recently expanded
seeds would belong the same polarity class as their seed term.

\citet{Takamura:05} attempted to unite corpus- and dictionary-based
approaches into a single framework.  To this end, the authors adopted
the Ising spin model from the statistical mechanics and represented
all words found in \texttt{WordNet}, in the Wall Street Journal, and
the Brown corpus as nodes in a graph.  The edges of this graph
represented associativity links and were established between any two
words, if one of these word was a synonym, an antonym, or a hyponym of
the other one or appeared in its gloss or context.  Taking into
account the a priori known polarities of some of the terms, the Ising
model then tried to find an approximation of the most likely polarity
combination of all terms in the graph over all possible polarity
assignments.

\subsubsection{Sentiment Lexica for German}

One of the first attempts to create a sentiment dictionary for German
was made by \citet{Remus:10}.  In their work, the authors
automatically translated the General Inquirer lexicon \citep{Stone:66}
into German.  In order to incorporate domain-specific knowledge into
this translated resource, they also collected a set of terms that were
strongly associated with positive or negative product reviews and
added this set to their translations.  Finally, the resulting lexicon
was enriched with inflection forms and frequent collocations of the
translated expressions.  The authors automatically estimated polarity
scores of their obtained 3,648 lexicon lemmas as the difference
between their positive and negative PMIs (i.e. PMI scores between the
collected terms and the pre-defined sets of positive or negative
expressions).

Similar work was also done by \citet{Waltinger:10} who compiled a list
of 10,141 subjective terms by first automatically translating the
Subjectivity Clues lexicon \citep{Wilson:05} and then manually
reassessing polarity scores of the translated items.  The author
expanded this list with the most frequent German synonyms of the
obtained terms and also added a set of negated opinionated phrases
(e.g. \emph{nicht schlecht} (\emph{not bad})).  The resulting
dictionary was used as a source of features for an automatic
classification of the polarity of Amazon reviews and showed superior
accuracy in comparison with other automatically translated resources.

A slightly different approach was taken by \citet{Clematide:10} who
manually annotated synsets from \emph{GermaNet} \cite{Hamp:97} with
their prior polarities and polarity strengths.  A subsequently
conducted study revealed, however, that the stock of polar adjectives
obtained in this way was insufficient for doing proper subjectivity
analysis of literary texts.  In order to overcome this problem, the
authors followed the idea of \citet{Hatzivassi:97} and extracted an
additional set of 918 adjectives which frequently co-occurred in
conjoined phrases with subjective terms from their dictionary.  After
manually inspecting each of the candidate terms, the authors added
this pruned set of new adjectives to their original lexicon.  The
total size of this final dictionary run up to 7,432 entries, 2,779 of
which were positive.

\subsubsection{Domain-Specific Sentiment Lexica}

\citet{Chetviorkin:14} obtained a set of possible subjective terms
from English and Russian microblogs by using an ensemble of supervised
machine learning classifiers that had previously been trained on a
manually annotated corpus of movie reviews.  In order to determine the
prior polarity of the extracted terms, the authors first calculated
approximate polarity scores of the processed messages using general
polarity lexicons and then took these rough estimates as prior
polarity expectations of the candidate expressions.  The posterior
scores of these expressions were computed using the Ising spin model
in a similar way to the approach proposed by \citet{Takamura:05}.  The
resulting lexicon comprised 2,772 words for Russian and 2,786 lexical
items for English.


\subsection{Conclusions}
\newpage
