\chapter{Coarse-Grained Sentiment Analysis}\label{sec:snt:cgsa}

Having familiarized ourselves with the peculiarities of the creation
of a sentiment corpus, the different ways to automatically induce new
polarity lists, and the difficulties of fine-grained opinion mining,
we now move on to the presumably most popular sentiment analysis
objective---the coarse-grained analysis or CGSA, in which we need to
determine the overall polarity of a message.

Traditionally, this task has been addessed with either of three
popular method groups:
\begin{inparaenum}[(i)]
  \item lexicon-based approaches,
  \item machine-learning-based (ML) techniques, and
  \item deep-learning-based (DL) applications.
\end{inparaenum}
In this chapter, we are going to scrutinize the most prominent
representatives of each of these paradigms and also tackle a much more
ambitious goal, namely to check whether we can achieve results
comparable with the scores of these methods when the language of the
domain we train on is completely different from the language of the
test data.

We begin our comparison by first presenting the metrics that we will
use in our subsequent evaluation.  After a brief description of the
data preparation step, we proceed to the actual estimation of popular
lexicon-, ML-, and DL-based approaches, explaining and evaluating them
in Sections~\ref{sec:cgsa:lexicon-based}, \ref{sec:cgsa:ml-based},
and~\ref{sec:cgsa:dl-based} respectively.  Then,
in~Section~\ref{sec:cgsa:domain-adaptation}, we also show which
results can be obtained by using cross-lingual transfer, where we
train a classifier on English microblogs and then adapt this system to
German messages.  Finally, we conclude with an extensive evaluation of
different hyperparameters and settings (including various types of
sentiment lexicons, different kinds of word embeddings, the utility of
the text normalization step, and the impact of additional noisily
labeled training data), summarizing our results and recapping our
findings at the end of this chapter.

\section{Evaluation Metrics}\label{sec:cgsa:eval-metrics}

To estimate the quality of the compared systems, we will rely on two
established evaluation metrics which are commonly used for measuring
CGSA results: One of these metrics is the macro-averaged \F-score over
the two major polarity classes~(positive and negative): { \small%
  \begin{equation*}
    F_1 = \frac{F_{pos} + F_{neg}}{2}.
  \end{equation*}%
  \normalsize%
}%
This measure was first introduced by the organizers of the SemEval
competition~\cite{Nakov:13,Rosenthal:14,Rosenthal:15} and has become a
de facto standard not only for the SemEval dataset, but virtually for
all related coarse-grained sentiment tasks and corpora.

The second metric is the micro-averaged \F-score over all three
possible semantic orientations (positive, negative, and neutral),
which basically corresponds to the accuracy over the complete labeled
dataset~\cite[see][p.~577]{Manning:99}.  This measure both predates
and supersedes the SemEval evaluation as it had already been applied
in the very first works on coarse-grained opinion
mining~\cite{Wiebe:99,Das:01,Read:05,Kennedy:06,Go:09} and was again
reintroduced at the GermEval Shared Task on Sentiment
Analysis~2017~\cite{Wojatzki:17}.

Moreover, in addition to these two metrics, we will also give a
detailed information on precision, recall, and \F-scores of each
particular polarity class in order to get a better intuition about
precise strengths, weaknesses, and biases of each evaluated method.

\section{Data Preparation}\label{sec:cgsa:data}

Similarly to the data preparation steps used for fine-grained
sentiment analysis, we preprocessed all tweets involved in our
experiments with the text normalization system
of~\citet{Sidarenka:13}, tokenized them using the same adjusted
version of Potts'
tokenizer,\footnote{\url{http://sentiment.christopherpotts.net/code-data/happyfuntokenizing.py}}
lemmatized and assigned part-of-speech tags to these tokens with the
\texttt{TreeTagger} of \citet{Schmid:95}.  Moreover, like in the
previous chapter, we automatically obtained morphological features for
each word, and induced syntactic trees for each sentence with the help
of the \texttt{Mate} dependency parser
\cite{Bohnet:13}. % Apart from the
% PotTS dataset, we also applied this procedure to the microblogs of
% the German Twitter snapshot~\cite{Scheffler:14}, which will be used
% in our subsequent experiments on noisy supervision.

We again divided the PotTS corpus~\cite{Sidarenka:16} into a training,
development, and test set, using 70\% of the tweets for learning, 10\%
for tuning and picking the optimal hyperparameters, and the remaining
20\% for evaluating the results.  We inferred the polarity labels for
these microblogs with a simple heuristic rule akin to the one used
by~\citet{Wiebe:05a}, and assigned the positive (negative) class to
the messages which had exclusively positive (negative) sentiments,
skipping all microblogs that simultaneously contained multiple
opinions with different semantic orientations.  In cases when a
sentiment was absent, we recoursed to a fallback strategy by
considering all tweets with only positive (negative) polar terms as
positive (negative), disregarding the messages which featured
expressions from both polarity classes, and taking the rest of the
corpus (i.e., posts with neither sentiments nor polar terms) as
neutral instances.

A few examples of such heuristically inferred labels are provided
below:
\begin{example}[Coarse-Grained Sentiment Annotations]\label{snt:cgsa:exmp:anno1}
  \noindent\textup{\bfseries\textcolor{darkred}{Tweet:}} {\upshape Ich finde den Papst putzig \smiley{}}\\
  \noindent I find the Pope cute \smiley{}.\\
  \noindent\textup{\bfseries\textcolor{darkred}{Label:}}\hspace*{2em}\textbf{%
    \upshape\textcolor{green3}{positive}}\\[1.5em]
  \noindent\textup{\bfseries\textcolor{darkred}{Tweet:}} {\upshape typisch Bayern kaum ist der neue Papst da und schon haben
  sie ihn in der Tasche ...}\\
  \noindent Typical Bavaria The new Pope is hardly there, as they already have him in their pocket\\
  \noindent\textup{\bfseries\textcolor{darkred}{Label:}}\hspace*{2em}\textbf{%
    \upshape\textcolor{midnightblue}{negative}}
\end{example}
As we can see, our simple rule provides reasonable decisions in most
of the cases.  However, since this approach is still an approximation
and consequently prone to errors (especially in the cases where the
polarity of the whole microblog differs from the semantic orientation
of its single tokens or is expressed without any explicit polar
expressions at all, see Example~\ref{snt:cgsa:exmp:anno2}), we also
decided to evaluate all CGSA methods presented in this chapter on
another German Twitter corpus, which has been specifically annotated
with message-level polarities---SB10k.

\begin{example}[Erroneous Sentiment
  Annotations]\label{snt:cgsa:exmp:anno2}
  \noindent\textup{\bfseries\textcolor{darkred}{Tweet:}} {\upshape Unser Park, unser Geld, unsere Stadt! -NICHT unser Finanzminister! \smiley{} \#schmid \#spd \#s21 \#btw13}\\
  \noindent Our park, our money, our city! -NOT our Finance Minister! \smiley{} \#schmid \#spd \#s21 \#btw13\\
  \noindent\textup{\bfseries\textcolor{darkred}{Label:}}\hspace*{2em}\textbf{%
    \upshape\textcolor{green3}{positive*}}\\[1.5em]
  \noindent\textup{\bfseries\textcolor{darkred}{Tweet:}} {\upshape Auf die Lobby-FDP von heute kann Deutschland verzichten ...}\\
  \noindent Germany can go without today's lobby FDP\\
  \noindent\textup{\bfseries\textcolor{darkred}{Label:}}\hspace*{2em}\textbf{%
    \upshape\textcolor{black}{neutral*}}
\end{example}

The SB10k dataset was introduced by~\citet{Cieliebak:17}, and
comprises a total of 9,738 tweets.  These messages were sampled from a
larger snapshot of 5M German microblogs gathered between August and
November~2013.  To ensure lexical diversity and proportional polarity
distribution in this corpus, the authors first split all posts of this
snaphsot into 2,500 clusters using $k$-means algorithm with unigram
features.  Afterwards, from each of these groups, they selected tweets
with at least one positive and one negative term from the German
Polarity Clues lexicon~\cite{Waltinger:10}.  Each of these messages
was subsequently annotated by at least three human experts from a pool
of 34 different coders.  The resulting inter-rater reliability (IRR)
of these data run up to 0.39 Krippendorff's
$\alpha$~\cite{Krippendorff:07}.  Unfortunately, due to the
restrictions of Twitter's terms of use (which only allow to distribute
the ids of the microblogs along with their labels), we were able to
retrieve merely 7,476 tweets of this corpus, which nevertheless
constitute a substantial amount of data, comparable to the size of the
PotTS dataset.

In addition to the aforementioned two corpora (PotTS and SB10k), we
also automatically annotated all microblogs of the German Twitter
Snapshot~\cite{Scheffler:14}, following the procedure proposed
by~\citet{Read:05} and~\citet{Go:09}, and assigning the positive
(negative) class to the tweets which contained the respective
emoticons.  However, in contrast to the previous datasets, we will not
use these tweets for evaluation, but solely utilize them for training
in our distant supervision experiments.

The resulting statistics on the number of messages and polarity class
distribution in these data are shown in
Table~\ref{snt-cgsa:tbl:corp-dist}.
\begin{table}[h]
  \begin{center}
    \bgroup \setlength\tabcolsep{0.1\tabcolsep}\scriptsize
    \begin{tabular}{p{0.162\columnwidth} % first columm
        *{6}{>{\centering\arraybackslash}p{0.13\columnwidth}}} % last two columns
      \toprule
      \textbf{Dataset} & \multicolumn{4}{c}{\bfseries Polarity Class}%
      & \multicolumn{2}{c}{\bfseries Agreement}\\\cmidrule(lr){2-5}\cmidrule(lr){6-7}
                       & \textbf{Positive} & \textbf{Negative} %
                                           & \textbf{Neutral} & \textbf{Mixed*} %
                                                              & $\alpha$ & $\kappa$\\\midrule

      \textbf{PotTS} & 3,380 & 1,541 & 2,558 & 513 & 0.66 & 0.4\\
      \textbf{SB10k} & 1,717 & 1,130 & 4,629 & 0 & 0.39 & NA\\
      \textbf{GTS} & 3,326,829 & 350,775 & 19,453,669 & 73,776 & NA & NA\\\bottomrule
\end{tabular}
    \egroup
    \caption[Polarity class distribution in PotTS, SB10k, and the
    German Twitter Snapshot.]{Polarity class distribution in PotTS,
      SB10k, and the German
      Twitter Snapshot (GTS).\\
      \emph{(* -- the \emph{mixed} polarity was excluded from our
        experiments)}}
    \label{snt-cgsa:tbl:corp-dist}
  \end{center}
\end{table}

As we can see, each of the datasets has its own unique composition of
polar tweets: The PotTS corpus, for example, shows a conspicuous bias
towards the positive class with 42\% of the microblogs belonging to
this polarity.  We can partially explain this effect by the following
reasons: first of all, it might be due to the coarseness of the
heuristic rule that we applied to infer the labels for these messages;
and, secondly, it might also stem from the initial selection criteria
that we used to compile the data for this collection.  As you might
remember, we a priori composed the major part of this dataset from
tweets which contained smileys or had at least one polar expression
from the SentiWS lexicon~\cite{Remus:10}.  Since most of these
emoticons were positive (which is evident from the statistics of the
German Twitter snapshot), the selected posts also became skewed
towards this semantic orientation.

The second most frequent group of the PotTS corpus is formed by
neutral microblogs, which account for 32\% of the data.  Finally,
negative messages represent the absolute minority of all tweets
(merely 19\%), which, however, is less surprising as the same tendency
can be observed for the SB10k and German Twitter Snapshot too.

Regarding the last two corpora, we can observe a more uniform (though
not identical) behavior as both collections are dominated by neutral
posts, which constitue 62\% of SB10k data and 84\% of the German
Twitter Snapshot.  The positive class, again, makes up a big part of
these datasets (23\% of SB10k and 14\% of the snapshot), but its
influence this time is much less pronounced than in the PotTS case.
Finally, as we already mentioned, negative tweets are the least
represented semantic representation across all three sources.  The
only group which has even less instances than this class is the mixed
polarity.  We, however, will skip the mixed orientation in our
experiments for the sake of simplicity and uniformity of the
evaluation.\footnote{As we will see later, some of the CGSA methods
  (especially the lexicon-based ones) can hardly be extended to the
  prediction of more than three polarity classes.}

Last but not least, the results of the inter-rater reliability check
confirm the superior quality of the PotTS corpus, which, even despite
an approximate label inference, still has an $\alpha$
agreement~\cite{Krippendorff:07} that is almost 1.7 times as high as
the respective score of SB10k (0.66 versus 0.39).  However, Cohen's
$\kappa$ of these data (0.4), which is only available for this
dataset, is merely on the verge between fair and moderate values.
Nevertheless, since labels used in this experiments are ordinal rather
than nominal in their nature (i.e., we can compute the \emph{distance}
between distinct labels, which, for example, would be bigger for the
pair \emph{positive} vs. \emph{negative} than for the pair
\emph{positive} vs. \emph{neutral}), we find the Krippendorff's metric
more appropriate for assessing the quality of the annotation for this
task.

\section{Lexicon-Based Methods}\label{sec:cgsa:lexicon-based}

The first group of approaches that we are going to explore in this
chapter using the described data are lexicon-based (LB) systems.  Just
like sentiment lexicons themselves, LB methods for coarse-grained
opinion mining have attracted a lot of attention from the very
inception of the sentiment analysis field.  Starting with the research
of~\citet{Hatzivassi:00}, who gave a statistical proof that the mere
occurrence of a subjective adjective from an automatically compiled
polarity list was a highly reliable indicator of the whole sentence
being subjective, more and more works dealing with the use of lexicons
for determining the overall polarity of the text appeared on the
scene.

One of the first notable steps in this direction was made
by~\citet{Das:01}, who proposed an ensemble of five classifiers (two
of which were purely lexicon-based and the other three heavily relied
on lexicon features) to predict the polarity of stock messages
(\emph{buy}, \emph{sell}, or \emph{neutral}), achieving an accuracy of
62\% on a corpus of several hundreds stock board messages.  A much
simpler method for a related task was suggested by~\citet{Turney:02},
who determined the \emph{semantic orientation} (SO) of reviews by
averaging the PMI scores of their terms, getting these scores from an
automatically generated sentiment lexicon.  With this approach, the
author could reach an accuracy of 74\% on a corpus of 410 manually
labeled Epinions comments.  In the same vein, \citet{Hu:04} computed
the overall polarity of a sentence by comparing the numbers of
positive and negative terms appearing in it, reversing the orientation
of terms in case of negation.  Finally, \citet{Kim:04} compared three
different approaches to determining the polarity of a sentence:
\begin{inparaenum}[(i)]
\item by multiplying the signs of its polar terms,
\item by taking the sum of their scores, and
\item by computing the geometric mean of these values;
\end{inparaenum}
finding the first and the last option working best on the Document
Undestanding Corpus.\footnote{\url{http://duc.nist.gov/}}

% % Hu and Liu, 2004
% Similarly, \citet{Hu:04} determined the semantic orientation of
% sentences in customer reviews by simply comparing the number of
% positive and negative terms found in these passages. Since the
% authors, however, were primarily interested in estimating the polarity
% towards particular product features mentioned in the clauses, they
% additionally applied a fallback strategy in case of a tie by checking
% which of the polar lexicon terms appeared closer to the features, and
% assuming the polarity of the preceding sentence if these numbers were
% also equal.

% % Taboada et al., 2004
% Largely inspired by the Appraisal theory of~\citet{Martin:00},
% \citet{Taboada:04} enhanced the original method of~\citet{Turney:02}
% by increasing the weights of polar adjectives which occurred in the
% middle and at the end of a document, and also augmenting these values
% with the affect, judgement, and appreciation scores.  Similarly to
% polarity, the appraisal scores were calculated automatically by
% computing the PMI of their cooccurrence with different pronouns using
% a web search engine.

% Polanyi and Zaenen, 2006; Kennedy and Inkpen, 2006
In~\citeyear{Polanyi:06}, \citeauthor{Polanyi:06} presented an
extensive overview and analysis of common lexicon-based sentiment
methods existing at that time, arguing that, besides considering the
lexical valence (i.e., semantic orientation) of polar expressions, it
was also necessary to incorporate syntactic, discourse-level, and
extra-linguistic factors such as negations, intensifiers, modal
operators (e.g., \emph{could} or \emph{might}), presuppositional items
(e.g., \emph{barely} or \emph{failure}), irony, reported speech,
discourse connectors, genre, attitude assessment, reported speech,
multi-entity evaluation, etc.  This theoretical hypothesis was also
proven empirically by \citet{Kennedy:06}, who investigated two ways to
determine the polarity of customer reviews: In the first of these
approaches, they simply compared the numbers of positive and negative
terms appearing in a text, assigning the analyzed review to the class
with the greater number of items.  In the second attempt, they
enhanced the original system with additional information about
contextual valence shifters, increasing or decreasing the sentiment
score of a term if it was preceded by an intensifier or downtoner, and
changing the polarity sign of this score to the opposite in case of a
negation.  With this adjustment, the authors achieved a statistically
significant improvement, boosting the accuracy of the two-class
prediction on a corpus of product and movie reviews from 67.9 to
69.3\%.

% Taboada et al., 2011
Finally, a veritably seminal work on lexicon-based techniques was
presented by~\citet{Taboada:11}, who introduced a manually compiled
polarity list\footnote{The authors hand-annotated all occurrences of
  adjectives, nouns, and verbs found in a corpus of 400 Epinions
  reviews with ordinal categories ranging from -5 to 5 which reflected
  the semantic orientation of a term (positive vs. negative) and its
  polar strength (weak vs. strong).} and used this resource to
estimate the overall semantic orientation of the text.  Drawing on the
ideas of~\citet{Polanyi:06}, the authors incorporated a set of
additional heuristic rules into their computation by changing the
prior SO values of negated, itensified, and downtoned terms, ignoring
irrealis and interrogative sentences, and adjusting the weights of
specific document sections.  An extensive evaluation of this approach
showed the superior performance of the manual lexicon in comparison
with other polarity lists including the Subjectivity
Dictionary~\cite{Wilson:05}, Maryland Polarity Set~\cite{Mohammad:09},
and \textsc{SentiWordNet}~\cite{Esuli:06c}.  Moreover, the authors
also demonstrated the effectiveness of their method for other topics
and text genres, hypothesizing that lexion-based approaches were in
general more robust to domain shifts than traditional supervised
machine-learning techniques.

% % Taboada et al., 2006
% Another important contribution to the development of lexicon-based
% approaches was made by~\citet{Taboada:06}, who compared three popular
% polarity lists---a PMI lexicon computed with the original method
% of~\citet{Turney:02} using the AltaVista's NEAR operator; a similar
% polarity list obtained with the help of Google's AND queries; and,
% finally, the manually compiled General Inquirer lexicon
% of~\citet{Stone:66}.  The authors evaluated these resources both
% intrinsically (by comparing them with GI entries) and extrinsically
% (by computing the polarity of 400 manually annotated Epinions
% reviews).  To estimate the overall polarity of a review for the second
% task, \citeauthor{Taboada:06} calculated the average SO value of all
% polar terms found in the review, obtaining these scores from the
% mean-normalized lexicons, and flipping the polarity sign to the
% opposite in case of the negation.

% Musto et al., 2014
It is therefore less surprisingly that lexicon-based systems have also
quickly found their way into sentiment analysis of social media: For
example, one such approach, specifically tailored to Twitter data, was
proposed by~\citet{Musto:14}, who examined four different ways to
compute the overall polarity scores of microblogs: \emph{basic},
\emph{normalized}, \emph{emphasized}, and
\emph{normalized-emphasized}; evaluating these strategies with four
distinct lexicons: \textsc{Sen\-ti\-Word\-Net}~\cite{Esuli:06c},
\textsc{Word\-Net-\-Affect}~\cite{Strapparava:04},
\textsc{MPQA}~\cite{Wiebe:05}, and
\textsc{SenticNet}~\cite{Cambria:14}.  In all of these methods, the
authors first split the input message into a list of
\emph{micro-phrases} based on the occurrence of punctuation marks and
conjunctions.  Afterwards, they calculated the polarity score for each
of these segments and estimated the overall polarity of the whole
tweet by uniting the scores of its micro-phrases.
\citeauthor{Musto:14} obtained their best results (58.99\% accuracy on
the SemEval-2013 dataset) with the normalized-emphasized approach, in
which they averaged the polarity scores of segments' tokens, boosting
these values by 50\% for informative parts of speech (adjectives,
nouns, and adverbs) and considering the sum of the micro-phrase scores
as the final overall polarity of the microblog.

% the authors obtained their best results using the
% \textsc{SentiWordNet} lexicon of~\citet{Esuli:06c}

% Jurek et al., 2015
Another Twitter-aware system was presented by~\citet{Jurek:15}, who
computed the negative and positive polarity of a message ($F_p$ and
$F_n$ respectively) using the following equations: { \small%
  \begin{align}
    F_P &= \min\left(\frac{A_P}{2 - \log(3.5\times W_P + I_P)}, 100\right),\\
    F_N &= \max\left(\frac{A_N}{2 - \log(3.5\times W_N + I_N)}, -100\right);\label{cgsa:eq:jurek}
  \end{align}%
  \normalsize%
}%
where $A_P$ and $A_N$ represent the average scores of positive and
negative lexicon terms found in the tweet
($A_p = \frac{\sum_{w\in\textrm{msg}}s^p_w}{\lVert\textrm{msg}\rVert}$
with $s^p_w$ denoting the positive lexicon score of the term $w$);
$W_P$ and $W_N$ stand for the raw counts of polar tokens; and $I_P$
and $I_N$ denote the number of intensifiers preceding these words.  In
addition to that, before estimating the average values, the authors
also modified the polarity scores $s_w$ of negated words by applying
the following heuristics: { \small%
  \begin{align}
neg(s_w) =
    \begin{cases}
        \min\left(\frac{s_w - 100}{2}, -10\right) & \text{if } s_w > 0,\\
        \max\left(\frac{s_w + 100}{2}, 10\right), & \text{if } s_w < 0.
    \end{cases}
\end{align}%
\normalsize%
}%
Furthermore, besides computing the polarity scores $F_p$ and $F_n$,
\citeauthor{Jurek:15} also determined the subjectivity degree of the
message by replacing the $A_P$ and $A_N$ terms in
Equation~\ref{cgsa:eq:jurek} with an average of conditional
probabilitites of the tweet being subjective given the occurrences of
the respective polar terms.\footnote{These probabilities were
  calculated automatically on the noisily labeled data set
  of~\citet{Go:09}.}  The authors considered a microblog as neutral if
its absolute polarity was less than 25 and the subjectivity value was
not greater than 0.5.  Otherwise, they assigned a positive or negative
label to this message depending on the sign of the polarity score.
With this approach, \citeauthor{Jurek:15} achieved an accuracy
of~77.3\% on the manually annotated subset of \citeauthor{Go:09}'s
corpus and reached 74.2\% on the IMDB review corpus~\cite{Maas:11}.

% Kolchyna et al., 2015
Finally, \citet{Kolchyna:15} also explored two different ways of
computing the overall polarity of a microblog:
\begin{inparaenum}[(i)]
\item by simply averaging the scores of the lexicon terms found in the
  message and
\item by taking the signed logarithm of this average:
\end{inparaenum}
\begin{equation*}
  \text{Score}_{\log} =
  \begin{cases}
    \text{sign}(\text{Score}_{\text{AVG}})\log_{10}(|\text{Score}_{\text{AVG}}|) & %
    \text{if |Score}_{\text{AVG}}| > 0.1,\\
    0, & \text{otherwise};
  \end{cases}
\end{equation*}%
comparing theses approaches on the SemEval-2013
dataset~\cite{Nakov:13}.  The authors determined the final polarity
class of a tweet using $k$-means clustering, which utilized both of
the above polarity values as features.  They showed that the
logarithmic strategy performed better than the simple average
solution, yielding an accuracy of 61.74\%.  % In addition to that,
% \citeauthor{Kolchyna:15} also checked whether plain lexicon scores
% could serve as useful attributes for an ML-based method.  For this
% purpose, they retrained a cost-sensitive SVM
% classifier~\cite{Masnadi:12} after extending its $n$-gram feature
% set with lexicon features, getting almost five percent accuracy
% improvement (from 86.62 to 91.17) on the IMDB movie review
% dataset~\cite{Pang:02}.

As it was unclear how all of these works would perform on the PotTS
and SB10k corpora, we reimplemented the approaches of~\citet{Hu:04}
(as a relatively simple baseline), \citet{Taboada:11},
\citet{Musto:14}, \citet{Jurek:15}, and \citet{Kolchyna:15}, and
applied these systems to the test sets of the aforementioned data.

Following our comparison in Chapter~\ref{chap:snt:lex}, we chose the
Zurich Polarity List as the primary sentiment lexicon for the tested
methods.  However, a significant drawback of this resource, which
unfortunately slipped through our evaluation, is that most of its
entries are weighted uniformly, having a polarity score of either 0.7
or 1.  We decided to keep the original values as is, and only
multiplied the scores of negative terms by -1 as all of the tested
approaches presupposed different score signs for terms with opposite
semantic orientations (plus for positive entries and minus for the
negative ones).\footnote{We will investigate the impact of other
  lexicons with presumably better scoring later in
  Section~\ref{cgsa:subsec:eval:lexicons}.}  Moreover, because some
analyzers (e.g., \citet{Taboada:11} and \citet{Musto:14}) expected
part-of-speech tagged entries, we automatically tagged all terms of
this polarity list using \texttt{TreeTagger} \cite{Schmid:95},
assigning to them their most probable tag sequences and (to address
ambiguity) PoS sequences whose probability was at least a half of the
maximal one, duplicating the entries if such alternative variant was
present.

Furthermore, since all of the systems except for that
of~\citet{Kolchyna:15} by default returned continuous real values, but
our evaluation required discrete polarity labels (\emph{positive},
\emph{negative}, or \emph{neutral}) instead, we discretized the
results of these approaches using the following simple procedure: We
first determined the optimal threshold values for the scores of each
particular polar class on the training and development
sets,\footnote{Since none of the methods required training or involved
  any sophisticated hyper-parameters, we used both training and
  development data to optimize the threshold scores.} and then derived
polarity labels for new test messages by comparing their predicted SO
score with these thresholds.  To achieve the former objective (i.e.,
find the optimal thresholds), we exhaustively searched through all
unique polarity values assigned to the training and development
instances and checked whether using this value as a boundary between
two adjacent polarity classes (sorted in ascending order of their
positivity) would increase the overall macro-\F{} on the train and dev
sets.

The final results of this evaluation are shown in
Table~\ref{snt-cgsa:tbl:lex-res}.

\begin{table}[h]
  \begin{center}
    \bgroup \setlength\tabcolsep{0.1\tabcolsep}\scriptsize
    \begin{tabular}{p{0.162\columnwidth} % first columm
        *{9}{>{\centering\arraybackslash}p{0.074\columnwidth}} % next nine columns
        *{2}{>{\centering\arraybackslash}p{0.068\columnwidth}}} % last two columns
      \toprule
      \multirow{2}*{\bfseries Method} & %
      \multicolumn{3}{c}{\bfseries Positive} & %
      \multicolumn{3}{c}{\bfseries Negative} & %
      \multicolumn{3}{c}{\bfseries Neutral} & %
      \multirow{2}{0.068\columnwidth}{\bfseries\centering Macro\newline \F{}$^{+/-}$} & %
      \multirow{2}{0.068\columnwidth}{\bfseries\centering Micro\newline \F{}}\\
      \cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}

      & Precision & Recall & \F{} & %
      Precision & Recall & \F{} & %
      Precision & Recall & \F{} & & \\\midrule

      \multicolumn{12}{c}{\cellcolor{cellcolor}PotTS}\\
      % Thresholds (PotTS):
      % Hu-Liu: F1: 0.415769; thresholds: [-0.30000000000000004, 0];
      % uses negation;
      % Taboada: f1_abs: 0.349700; f1_cnt: 0.194517; f1_mean: 0.352276
      % best F1: 0.352276; self._thresholds: [-0.10000000000000002, 0.14]; (mean scores)
      % uses: negation, intensification, irrealis;
      % Musto: F1: 0.420251; thresholds: [-0.033333333333333326, 0.02500000000000009];
      % uses: negation;
      % Jurek: F1: F1: 0.317588; thresholds: [-0.0053197382707281865, 0.0017843579564678833];
      % uses: negation and intensifiers;
      % Kolchyna:
      % uses: negation;

      % Hu-Liu Commands:
      % -----------------
      % cgsa_sentiment train -t musto -l cgsa/data/lexicons/zrch.manual.txt \
      % data/PotTS/preprocessed/train/*.tsv data/PotTS/preprocessed/dev/*.tsv
      %
      % cgsa_sentiment test -m cgsa/data/models/cgsa.model data/PotTS/preprocessed/test/*.tsv\
      % > data/PotTS/preprocessed/predicted/hu-liu/hu-liu.test
      %
      % cgsa_evaluate data/PotTS/preprocessed/test/ \
      % data/PotTS/preprocessed/predicted/hu-liu/hu-liu.test
      %
      % Hu-Liu Results:
      % ----------------
      % Training hu-liu
      % Testing hu-liu
      % Evaluating hu-liu
      % General Statistics:
      % precision    recall  f1-score   support
      % positive       0.45      0.21      0.29       680
      % negative       0.22      0.16      0.18       287
      % neutral       0.37      0.66      0.47       558
      % avg / total       0.38      0.37      0.34      1525
      % Macro-Averaged F1-Score (Positive and Negative Classes): 23.73%
      % Micro-Averaged F1-Score (All Classes): 36.5902%

      HL & \textbf{0.45} & 0.21 & 0.29 & %
       0.22 & 0.16 & 0.18 & %
       \textbf{0.37} & 0.66 & 0.47 & %
       \textbf{0.237} & 0.366\\

       % Taboada Commands:
       % -----------------
       % cgsa_sentiment train -t musto -l cgsa/data/lexicons/zrch.manual.txt \
       % data/PotTS/preprocessed/train/*.tsv data/PotTS/preprocessed/dev/*.tsv
       %
       % cgsa_sentiment test -m cgsa/data/models/cgsa.model data/PotTS/preprocessed/test/*.tsv\
       % > data/PotTS/preprocessed/predicted/taboada/taboada.test
       %
       % cgsa_evaluate data/PotTS/preprocessed/test/ \
       % data/PotTS/preprocessed/predicted/taboada/taboada.test
       %
       % Taboada Results:
       % ----------------
       % Training taboada
       % Testing taboada
       % Evaluating taboada
       % General Statistics:
       % precision    recall  f1-score   support
       % positive       0.45      0.17      0.25       680
       % negative       0.23      0.15      0.18       287
       % neutral       0.37      0.72      0.49       558
       % avg / total       0.38      0.37      0.32      1525
       % Macro-Averaged F1-Score (Positive and Negative Classes): 21.45%
       % Micro-Averaged F1-Score (All Classes): 36.7869%
      TBD & \textbf{0.45} & 0.17 & 0.25 & %
        \textbf{0.23} & 0.15 & 0.18 & %
        \textbf{0.37} & \textbf{0.72} & \textbf{0.49} & %
        0.215 & 0.368\\

       % Musto Commands:
       % -----------------
       % cgsa_sentiment train -t musto -l cgsa/data/lexicons/zrch.manual.txt \
       % data/PotTS/preprocessed/train/*.tsv data/PotTS/preprocessed/dev/*.tsv
       %
       % cgsa_sentiment test -m cgsa/data/models/cgsa.model data/PotTS/preprocessed/test/*.tsv\
       % > data/PotTS/preprocessed/predicted/musto/musto.test
       %
       % cgsa_evaluate data/PotTS/preprocessed/test/ \
       % data/PotTS/preprocessed/predicted/musto/musto.test
       %
       % Musto Results:
       % ----------------
       % Training musto
       % Testing musto
       % Evaluating musto
       % General Statistics:
       % precision    recall  f1-score   support
       % positive       0.44      0.20      0.28       680
       % negative       0.21      0.17      0.19       287
       % neutral       0.37      0.64      0.47       558
       % avg / total       0.37      0.36      0.33      1525
       % Macro-Averaged F1-Score (Positive and Negative Classes): 23.31%
       % Micro-Averaged F1-Score (All Classes): 35.8033%

       MST & 0.44 & 0.2 & 0.28 & %
        0.21 & \textbf{0.17} & \textbf{0.19} & %
        \textbf{0.37} & 0.64 & 0.47 & %
        0.233 & 0.358\\

       % Jurek Commands:
       % ---------------
       % cgsa_sentiment train -t jurek -l cgsa/data/lexicons/zrch.manual.txt \
       % data/PotTS/preprocessed/train/*.tsv data/PotTS/preprocessed/dev/*.tsv
       %
       % cgsa_sentiment test -m cgsa/data/models/cgsa.model data/PotTS/preprocessed/test/*.tsv\
       % > data/PotTS/preprocessed/predicted/jurek/jurek.test
       %
       % cgsa_evaluate data/PotTS/preprocessed/test/ \
       % data/PotTS/preprocessed/predicted/jurek/jurek.test
       %
       % Jurek Results:
       % ----------------
       % Training jurek
       % Testing jurek
       % Evaluating jurek
       % General Statistics:
       % precision    recall  f1-score   support
       % positive       0.43      0.23      0.30       680
       % negative       0.23      0.11      0.15       287
       % neutral       0.36      0.66      0.47       558
       % avg / total       0.37      0.37      0.34      1525
       % Macro-Averaged F1-Score (Positive and Negative Classes): 22.67%
       % Micro-Averaged F1-Score (All Classes): 36.8525%

      JRK & 0.43 & \textbf{0.23} & \textbf{0.3} & %
       \textbf{0.23} & 0.11 & 0.15 & %
       0.36 & 0.66 & 0.47 & %
       0.227 & \textbf{0.369}\\

       % Training kolchyna
       % Testing kolchyna
       % Evaluating kolchyna
       % General Statistics:
       % precision    recall  f1-score   support
       % positive       0.41      0.17      0.24       680
       % negative       0.21      0.10      0.14       287
       % neutral       0.36      0.72      0.48       558
       % avg / total       0.35      0.36      0.31      1525
       % Macro-Averaged F1-Score (Positive and Negative Classes): 18.77%
       % Micro-Averaged F1-Score (All Classes): 35.6721%
      KLCH & 0.41 & 0.17 & 0.24 & %
       0.21 & 0.1 & 0.14 & %
       0.36 & \textbf{0.72} & 0.48 & %
       0.188 & 0.357\\

      \multicolumn{12}{c}{\cellcolor{cellcolor}SB10k}\\

      % Training hu-liu
      % Testing hu-liu
      % Evaluating hu-liu
      % General Statistics:
      % precision    recall  f1-score   support
      % positive       0.41      0.43      0.42       354
      % negative       0.24      0.28      0.26       212
      % neutral       0.66      0.63      0.64       930
      % avg / total       0.54      0.53      0.54      1496
      % Macro-Averaged F1-Score (Positive and Negative Classes): 33.88%
      % Micro-Averaged F1-Score (All Classes): 53.0080%
      HL & \textbf{0.41} & \textbf{0.43} & \textbf{0.42} & %
        0.24 & 0.28 & 0.26 & %
        0.66 & 0.63 & 0.64 & %
        0.339 & 0.53\\

        % Training taboada
        % Testing taboada
        % Evaluating taboada
        % General Statistics:
        % precision    recall  f1-score   support
        % positive       0.41      0.38      0.40       354
        % negative       0.22      0.25      0.23       212
        % neutral       0.65      0.66      0.66       930
        % avg / total       0.54      0.53      0.53      1496
        % Macro-Averaged F1-Score (Positive and Negative Classes): 31.27%
        % Micro-Averaged F1-Score (All Classes): 53.2086%
      TBD & \textbf{0.41} & 0.38 & 0.4 & %
        0.22 & 0.25 & 0.23 & %
        0.65 & 0.66 & 0.66 & %
        0.313 & 0.532\\

        % Training musto
        % Testing musto
        % Evaluating musto
        % General Statistics:
        % precision    recall  f1-score   support
        % positive       0.38      0.37      0.38       354
        % negative       0.26      0.31      0.28       212
        % neutral       0.65      0.64      0.64       930
        % avg / total       0.53      0.53      0.53      1496
        % Macro-Averaged F1-Score (Positive and Negative Classes): 32.95%
        % Micro-Averaged F1-Score (All Classes): 52.6070%
      MST & 0.38 & 0.37 & 0.38 & %
        0.26 & \textbf{0.31} & 0.28 & %
        0.65 & 0.64 & 0.64 & %
        0.33 & 0.526\\

        % Training jurek
        % Testing jurek
        % Evaluating jurek
        % General Statistics:
        % precision    recall  f1-score   support
        % positive       0.40      0.37      0.38       354
        % negative       0.36      0.25      0.30       212
        % neutral       0.68      0.75      0.71       930
        % avg / total       0.57      0.59      0.58      1496
        % Macro-Averaged F1-Score (Positive and Negative Classes): 33.98%
        % Micro-Averaged F1-Score (All Classes): 58.8904%
      JRK & 0.4 & 0.37 & 0.38 & %
        \textbf{0.36} & 0.25 & \textbf{0.3} & %
        \textbf{0.68} & 0.75 & 0.71 & %
        \textbf{0.34} & \textbf{0.589}\\

        % Training kolchyna
        % Testing kolchyna
        % Evaluating kolchyna
        % General Statistics:
        % precision    recall  f1-score   support
        % positive       0.39      0.17      0.24       354
        % negative       0.21      0.13      0.16       212
        % neutral       0.65      0.85      0.73       930
        % avg / total       0.53      0.58      0.54      1496
        % Macro-Averaged F1-Score (Positive and Negative Classes): 19.90%
        % Micro-Averaged F1-Score (All Classes): 58.4893%
      KLCH & 0.39 & 0.17 & 0.24 & %
        0.21 & 0.13 & 0.16 & %
        0.65 & \textbf{0.85} & \textbf{0.73} & %
        0.199 & 0.585\\\bottomrule
\end{tabular}
    \egroup
    \caption[Evaluation of lexicon-based CGSA methods.]{
      Evaluation of lexicon-based CGSA methods.\\
      {\small HL~--~\citet{Hu:04}, TBD~--~\citet{Taboada:11}, MST~--~\citet{Musto:14},
        JRK~--~\citet{Jurek:15}, KLCH~--~\citet{Kolchyna:15}}}
    \label{snt-cgsa:tbl:lex-res}
  \end{center}
\end{table}

As we can see from the figures, the performance of the tested methods
widely varies across different polarity classes and datasets: For
example, the most simple approach of~\citet{Hu:04} achieves
surprisingly good results on the PotTS corpus, attaining the highest
precision on the positive class and also yielding quite competitive
scores for negative messages, which in turn leads to a superior
macro-averaged \F{} (0.237) for all classes.  The more elaborate
analyzer of~\citet{Taboada:11}, which can be viewed as an extension of
\citeauthor{Hu:04}'s system, can still keep up the high precision of
predicted positive microblogs, and even improves on the precision of
the negative and neutral classes, but nevertheless looses 0.012
overall macro-\F{} against the first system due to a lower recall of
subjective tweets.  A better performance in this respect is shown by
the remaining three methods, each of which establishes a new recall
benchmark for at least one polarity group: The MST analyzer, for
instance, sets the best recall score for the negative class, the JRK
system noticeably boosts the results for the positive orientation, and
the approach of~\citet{Kolchyna:15} attains the best recall value for
neutral messages, being on par with the results of~\citet{Taboada:11}.
Mostly due to this high recall on the dominating positive polarity
class, the classifier of~\citet{Jurek:15} also reaches the highest
micro-averaged \F{}-score among all competitors on this dataset.

A slightly different situation can be observed with the SB10k dataset.
This time, the method of~\citet{Hu:04} clearly dominates its
competitors on the positive class, but fails to surpass the
alternative approaches on any other metric.  As in the previous case,
the Taboada system preserves the high precision of positive tweets,
and even performs a bit better on the neutral polarity, but falls
against the former system in terms of the macro-averaged scores due to
a lower recall.  Similarly to the foregoing experiment, the MST
approach again shows the highest recall of negative microblogs, but
rather poor macro- and micro-\F{} results, since the negative class is
by far the most underrepresented one in either corpora and the overall
performace is not affected by this success.  Finally, the last two
classifiers---JRK and KLCH---show quite promising figures for the
negative and neutral polarities, with the system of~\citet{Jurek:15}
setting up a new record for the micro- and macro-averaged \F{}-scores
(0.302 and 0.619 respectively) on this corpus.

\subsection{Polarity-Changing Factors}\label{subsec:cgsa:lex-methods:pol-change}

Since one of the most important components of any lexicon-based CGSA
approach is the analysis of factors which might significantly affect
the prior polarity of polar terms, we decided to recheck the utility
of these modules for different methods.  In order to do so, we
deactivated one by one parts of the systems which analyzed different
phenomena of the surrounding context and recomputed the \F{}-scores
with these changes.

\begin{table}[h]
  \begin{center}
    \bgroup \setlength\tabcolsep{0.1\tabcolsep}\scriptsize
    \begin{tabular}{p{0.15\columnwidth} % first columm
        *{10}{>{\centering\arraybackslash}p{0.082\columnwidth}}}
      \toprule
      \multirow{2}{0.15\columnwidth}{%
      \bfseries Polarity-Changing\newline Factors} & %
      \multicolumn{10}{c}{\bfseries CGSA System}\\
      & \multicolumn{2}{c}{\bfseries HL} & \multicolumn{2}{c}{\bfseries TBD} %
      & \multicolumn{2}{c}{\bfseries MST} %
      & \multicolumn{2}{c}{\bfseries JRK} & \multicolumn{2}{c}{\bfseries KLCH}\\%
      \cmidrule(lr){2-3}\cmidrule(lr){4-5}\cmidrule(lr){6-7} %
      \cmidrule(lr){8-9}\cmidrule(lr){10-11}

      & Macro\newline \F{}$^{+/-}$ & Micro\newline \F{} %
      & Macro\newline \F{}$^{+/-}$ & Micro\newline \F{} %
      & Macro\newline \F{}$^{+/-}$ & Micro\newline \F{} %
      & Macro\newline \F{}$^{+/-}$ & Micro\newline \F{} %
      & Macro\newline \F{}$^{+/-}$ & Micro\newline \F{}\\\midrule

      \multicolumn{11}{c}{\cellcolor{cellcolor}PotTS}\\
      All & \textbf{0.237} & 0.366 & 0.215 & 0.368 & 0.233 & 0.358 %
      & 0.227 & 0.369 & 0.188 & 0.357\\

      % Training hu-liu
      % Testing hu-liu
      % Evaluating hu-liu
      % General Statistics:
      % precision    recall  f1-score   support
      % negative       0.22      0.15      0.18       287
      % neutral       0.37      0.66      0.47       558
      % positive       0.45      0.22      0.29       680
      % avg / total       0.38      0.37      0.34      1525
      % Macro-Averaged F1-Score (Positive and Negative Classes): 23.64%
      % Micro-Averaged F1-Score (All Classes): 36.5246%

      % Training taboada
      % Testing taboada
      % Evaluating taboada
      % General Statistics:
      % precision    recall  f1-score   support
      % negative       0.23      0.14      0.18       287
      % neutral       0.37      0.72      0.49       558
      % positive       0.45      0.17      0.25       680
      % avg / total       0.38      0.37      0.32      1525
      % Macro-Averaged F1-Score (Positive and Negative Classes): 21.36%
      % Micro-Averaged F1-Score (All Classes): 36.8525%

      % Training musto
      % Testing musto
      % Evaluating musto
      % General Statistics:
      % precision    recall  f1-score   support
      % negative       0.22      0.16      0.19       287
      % neutral       0.37      0.64      0.47       558
      % positive       0.44      0.22      0.29       680
      % avg / total       0.37      0.36      0.34      1525
      % Macro-Averaged F1-Score (Positive and Negative Classes): 23.98%
      % Micro-Averaged F1-Score (All Classes): 36.2623%

      % Training jurek
      % Testing jurek
      % Evaluating jurek
      % General Statistics:
      % precision    recall  f1-score   support
      % negative       0.23      0.11      0.15       287
      % neutral       0.36      0.66      0.47       558
      % positive       0.45      0.25      0.32       680
      % avg / total       0.38      0.37      0.34      1525
      % Macro-Averaged F1-Score (Positive and Negative Classes): 23.31%
      % Micro-Averaged F1-Score (All Classes): 37.3770%

      % Training kolchyna
      % Testing kolchyna
      % Evaluating kolchyna
      % General Statistics:
      % precision    recall  f1-score   support
      % negative       0.23      0.11      0.15       287
      % neutral       0.36      0.74      0.49       558
      % positive       0.43      0.16      0.23       680
      % avg / total       0.37      0.36      0.31      1525
      % Macro-Averaged F1-Score (Positive and Negative Classes): 19.03%
      % Micro-Averaged F1-Score (All Classes): 36.3279%
      --Negation & 0.236 & 0.365 & 0.214 & 0.369 & 0.24 & %
       0.363 & 0.233 & \textbf{0.374} & 0.19 & 0.363\\

       % Training taboada
       % Testing taboada
       % Evaluating taboada
       % General Statistics:
       % precision    recall  f1-score   support
       % negative       0.23      0.14      0.18       287
       % neutral       0.37      0.73      0.49       558
       % positive       0.46      0.17      0.25       680
       % avg / total       0.38      0.37      0.33      1525
       % Macro-Averaged F1-Score (Positive and Negative Classes): 21.50%
       % Micro-Averaged F1-Score (All Classes): 37.0492%

       % Training jurek
       % Testing jurek
       % Evaluating jurek
       % General Statistics:
       % precision    recall  f1-score   support
       % negative       0.23      0.11      0.15       287
       % neutral       0.36      0.66      0.47       558
       % positive       0.43      0.23      0.30       680
       % avg / total       0.37      0.37      0.34      1525
       % Macro-Averaged F1-Score (Positive and Negative Classes): 22.67%
       % Micro-Averaged F1-Score (All Classes): 36.8525%

      --Intensification & NA & NA & 0.215 & 0.37 & NA &  %
      NA & 0.227 & 0.369 & NA & NA\\

      % Training taboada
      % Testing taboada
      % Evaluating taboada
      % General Statistics:
      % precision    recall  f1-score   support
      % negative       0.22      0.15      0.18       287
      % neutral       0.37      0.69      0.48       558
      % positive       0.45      0.19      0.27       680
      % avg / total       0.38      0.37      0.33      1525
      % Macro-Averaged F1-Score (Positive and Negative Classes): 22.32%
      % Micro-Averaged F1-Score (All Classes): 36.5246%
      --Others & NA & NA & 0.223 & 0.365 & NA &  %
      NA & NA & NA & NA & NA\\

      \multicolumn{11}{c}{\cellcolor{cellcolor}SB10k}\\

      All & 0.339 & 0.53 & 0.313 & 0.532 & 0.33 & 0.526 %
      & 0.34 & 0.589 & 0.199 & 0.585\\

      % Training hu-liu
      % Testing hu-liu
      % Evaluating hu-liu
      % General Statistics:
      % precision    recall  f1-score   support
      % negative       0.23      0.27      0.25       212
      % neutral       0.66      0.62      0.64       930
      % positive       0.41      0.42      0.42       354
      % avg / total       0.54      0.53      0.53      1496
      % Macro-Averaged F1-Score (Positive and Negative Classes): 33.17%
      % Micro-Averaged F1-Score (All Classes): 52.6738%

      % Training taboada
      % Testing taboada
      % Evaluating taboada
      % General Statistics:
      % precision    recall  f1-score   support
      % negative       0.22      0.25      0.23       212
      % neutral       0.66      0.66      0.66       930
      % positive       0.41      0.37      0.39       354
      % avg / total       0.53      0.53      0.53      1496
      % Macro-Averaged F1-Score (Positive and Negative Classes): 30.98%
      % Micro-Averaged F1-Score (All Classes): 53.1417%

      % Training musto
      % Testing musto
      % Evaluating musto
      % General Statistics:
      % precision    recall  f1-score   support
      % negative       0.23      0.26      0.24       212
      % neutral       0.65      0.63      0.64       930
      % positive       0.38      0.38      0.38       354
      % avg / total       0.53      0.52      0.52      1496
      % Macro-Averaged F1-Score (Positive and Negative Classes): 31.33%
      % Micro-Averaged F1-Score (All Classes): 51.7380%

      % Training jurek
      % Testing jurek
      % Evaluating jurek
      % General Statistics:
      % precision    recall  f1-score   support
      % negative       0.30      0.16      0.21       212
      % neutral       0.68      0.75      0.72       930
      % positive       0.40      0.40      0.40       354
      % avg / total       0.56      0.58      0.57      1496
      % Macro-Averaged F1-Score (Positive and Negative Classes): 30.46%
      % Micro-Averaged F1-Score (All Classes): 58.4893%

      % Training kolchyna
      % Testing kolchyna
      % Evaluating kolchyna
      % General Statistics:
      % precision    recall  f1-score   support
      % negative       0.21      0.08      0.11       212
      % neutral       0.66      0.89      0.76       930
      % positive       0.42      0.19      0.26       354
      % avg / total       0.54      0.61      0.55      1496
      % Macro-Averaged F1-Score (Positive and Negative Classes): 18.62%
      % Micro-Averaged F1-Score (All Classes): 61.0963%
      --Negation & 0.332 & 0.527 & 0.31 & 0.531 & 0.313 & %
       0.517 & 0.305 & 0.585 & 0.186 & \textbf{0.611}\\

       % Training taboada
       % Testing taboada
       % Evaluating taboada
       % General Statistics:
       % precision    recall  f1-score   support
       % negative       0.22      0.24      0.23       212
       % neutral       0.66      0.66      0.66       930
       % positive       0.42      0.40      0.41       354
       % avg / total       0.54      0.54      0.54      1496
       % Macro-Averaged F1-Score (Positive and Negative Classes): 31.95%
       % Micro-Averaged F1-Score (All Classes): 54.0107%

       % Training jurek
       % Testing jurek
       % Evaluating jurek
       % General Statistics:
       % precision    recall  f1-score   support
       % negative       0.36      0.25      0.30       212
       % neutral       0.68      0.76      0.72       930
       % positive       0.41      0.37      0.39       354
       % avg / total       0.57      0.59      0.58      1496
       % Macro-Averaged F1-Score (Positive and Negative Classes): 34.09%
       % Micro-Averaged F1-Score (All Classes): 59.3583%
      --Intensification & NA & NA & 0.32 & 0.54 & NA &  %
        NA & \textbf{0.341} & 0.594 & NA & NA\\

        % Training taboada
        % Testing taboada
        % Evaluating taboada
        % General Statistics:
        % precision    recall  f1-score   support
        % negative       0.23      0.28      0.25       212
        % neutral       0.66      0.64      0.65       930
        % positive       0.42      0.40      0.41       354
        % avg / total       0.54      0.53      0.53      1496
        % Macro-Averaged F1-Score (Positive and Negative Classes): 32.82%
        % Micro-Averaged F1-Score (All Classes): 52.8743%
      --Others & NA & NA & 0.328 & 0.529 & NA &  %
      NA & NA & NA & NA & NA\\\bottomrule
\end{tabular}
    \egroup
    \caption[Evaluation of polarity-changing factors for lexicon-based CGSA methods.]{
      Evaluation of polarity-changing factors for lexicon-based CGSA methods.\\
      {\small HL~--~\citet{Hu:04}, TBD~--~\citet{Taboada:11}, MST~-- \citet{Musto:14}, JRK
        -- \citet{Jurek:15}, KLCH -- \citet{Kolchyna:15}}}
    \label{snt-cgsa:tbl:lex-res-ablation}
  \end{center}
\end{table}

As we can see from the results in
Table~\ref{snt-cgsa:tbl:lex-res-ablation}, the method of~\citet{Hu:04}
achieves its best scores when all context analyzing components are
switched on.  This, however, is not always the case for the remaining
systems.  For example, the approach of~\citet{Taboada:11} noticeably
benefits from the deactivation of intensifier handling, but shows
mixed changes when the analysis of negations and other context factors
(e.g., irrealis, quotes, and interrogative sentences) is turned off:
In the former case, its macro-averaged \F{}-score degrades on both
corpora, but the micro-averaged result improves on PotTS and slightly
deteriorates on SB10k from 0.532 to 0.531.  In case of irrealis and
other factors, we see an obvious improvement of all macro-scores, but
observe the opposite effect on the micro-averaged results.  Similarly,
the system of~\citet{Musto:14} achives better figures on the PotTS
corpus when it disregards negations, but yields worse results on the
SB10k dataset with the same changes.  Finally, the last two systems
(JRK and KLCH) both achive their top scores when either negation or
intensification handling is deactivated.

\subsection{Error Analysis}\label{subsec:cgsa:lex-methods:err-analysis}

\todo[inline]{provide examples of errors made by different methods}

%% Hu-Liu
% <<<	gold:	positive
% >>>	predicted:	neutral
% 365765698049409024	Aw %PosSmiley so sss und Chancen los :'D

% <<<	gold:	positive
% >>>	predicted:	neutral
% 373466243119849472	 Und wen beschuldigst du ?  - " Auslnder . " " oh cool ! " %PosSmiley diktatorhighfive

% <<<	gold:	neutral
% >>>	predicted:	positive
% 395055148101160960	Feel Better - Blog : Loslassen heisst besonders auch die Illusion des freien Willens loszulassen ... %Link by

% <<<	gold:	neutral
% >>>	predicted:	positive
% 369486117105463297	DTN Germany : Brse Frankfurt : Dax bleibt gefangen im 300- Punkte - Schacht : Der Deutsche Leitindex bewegt sich in ...

% <<<	gold:	neutral
% >>>	predicted:	positive
% 370989586253893633	nur wer gross denkt kann grosses erreichen maskulin Motivation

% <<<	gold:	neutral
% >>>	predicted:	positive
% 371998274699673600	FCBayern Peps System - Rotation : Mnchen - Pep Guardiola hlt Philipp Lahm fr einen der intelligentesten Fussba ......

% <<<	gold:	neutral
% >>>	predicted:	negative
% 371621600728064000	 Aufstieg gefhrdet  : FC Carl Zeiss entlsst Trainer Petrik Sander - Thringer Allgemeine %Link Jena FCC

%% Taboada
% <<<	gold:	neutral
% >>>	predicted:	positive
% 373570140199485440	mathe fragen Eine Person hat ihre Ersparnisse in vier unterschiedlich grosse Posten ...

% <<<	gold:	neutral
% >>>	predicted:	positive
% 392619096254078977	%Link Vergleichen Sie ! Unsere Preise liegen bis 70% unter dem Wettbewerb . Probieren Sie 14 Tage vllig kostenlos .

% <<<	gold:	positive
% >>>	predicted:	neutral
% 382494978645442560	Ist kuschlig heute ! %PosSmiley Gleich erst du CDU / CSU - Fraktionssitzung . Ob der Platz reicht ? btw13 ...

% <<<	gold:	positive
% >>>	predicted:	neutral
% 390420987516166145	Ein ziemlich geniales Werkzeug fr lau . Dafr kann man Werbung schon hinnehmen , finde ich .

% <<<	gold:	positive
% >>>	predicted:	neutral
% 375929960453521408	geleakte technische details wren nett , eine ?

% <<<	gold:	negative
% >>>	predicted:	neutral
% 392231940947857408	Weh ?

% <<<	gold:	positive
% >>>	predicted:	negative
% 368092089998770176	Aber die Seite schaut echt toll aus : 3 Und da steckt sau viel Liebe drin : 3

% <<<	gold:	positive
% >>>	predicted:	negative
% 328196281539391488	ah okay ja hat mir die evelyn schon erzhlt . ein bisschen halt %PosSmiley also ich komme aus ungarn und bin in budapest geboren %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 326070261013172224	Gibt ' s noch nicht zu kaufen im Kino meiner Wahl . Steht aber auf der Todo - Liste ! %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 311941317112512512	endlich ! die letzten tage ohne papst , waren ja kaum auszuhalten ...

% <<<	gold:	positive
% >>>	predicted:	neutral
% 375219139146551296	Huhu Meine lieben twitter freunde * knuff *

% <<<	gold:	positive
% >>>	predicted:	neutral
% 327389746068353024	Nur noch wenige Tage bis zur grossen Istanbul Verlosung auf Facebook jetzt mitmachen und gewinnen mit ICS

% <<<	gold:	neutral
% >>>	predicted:	positive
% 391982409261932544	Anlage Thun sichtbar gesetzt

% <<<	gold:	positive
% >>>	predicted:	neutral
% 324968719296106496	Nordkorea ist so fortschrittlich , dass ihre Technik nahezu ausserirdisch ist . %PosSmiley %Link

% <<<	gold:	negative
% >>>	predicted:	neutral
% 319578631368237057	Das ist die Nahrungskette . CDU klaut von SPD nur belagerte Theman und die klauen die Piraten - Themen . Reise nach Jerusalem %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 328070432064409600	wenn ich so ein hbsches Mdchen auf der Strasse sehen wrde %PosSmiley - &gt; Direkt ansprechen Hahaha

% <<<	gold:	negative
% >>>	predicted:	neutral
% 369488214123241473	oh D: klingt nicht so toll : &lt;

% <<<	gold:	positive
% >>>	predicted:	neutral
% 311917697975857152	die Chance ist jedenfalls grsser als dass die Ford - WErke Kln Papst werden %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 390446572540268544	Was hast denn schnes gekauft ? %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 322426952130650112	Peine : Monika Berkhan will fr die Grnen antreten

% <<<	gold:	negative
% >>>	predicted:	neutral
% 370949715543982080	' Und was nehmen Sie ? ' - ' Ich nehme dann mal die traurige Wendung. '

% <<<	gold:	neutral
% >>>	predicted:	negative
% 395207577300398080	Verkehrsrecht absolute Antragsdelikte : Absolute Antragsdelikte sind Straftaten deren Verfolgung

% <<<	gold:	neutral
% >>>	predicted:	positive
% 373928522579836929	McDonald ' s oder Burger King ? Der grosse Fast Food Check !

% <<<	gold:	negative
% >>>	predicted:	neutral
% 379976336540188673	 Manche Mnner sind einfach rabiater  - das Weltbild der CDU schockiert mich gerade zutiefst . Wenn der Mann will , hat die ...

% <<<	gold:	positive
% >>>	predicted:	neutral
% 311918341298221056	Nee , ich gucke Twitter , das Papst guckt . %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 322255764024610816	Spiele zu Hause : Hallo schatzi , komm und schaue , wias ich alles fr dich habe %PosSmiley %Link

% <<<	gold:	positive
% >>>	predicted:	neutral
% 381888653427220480	das kursiert hier gerade bei Twitter %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 363432322965573633	Aber egal , wer da transzendental auf meinem Schoss sitzt , ... ich schubs ihn nu runter + geh ins Bett . Gn8 all Ihr Lieben

% <<<	gold:	positive
% >>>	predicted:	neutral
% 381690191770943488	Ich wnsche den Piraten , dass sie dieses Mal in den Bundestag einziehen . %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	negative
% 370077786633154560	ok , werde ich tun , vielen dank nk

% <<<	gold:	positive
% >>>	predicted:	neutral
% 319900482724298752	wie sehr ich dich liebe. wen meinst du ? den , der es auffngt . %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 352790468729384960	Ihr seid eingeladen ! %PosSmiley Gebloggt : Netzpolitische Standpunkte der Grnen . Eine Feedbackschleife .

% <<<	gold:	positive
% >>>	predicted:	neutral
% 311908809113223168	Leute denken an den Papst , ich denke an FCB %User

% <<<	gold:	positive
% >>>	predicted:	neutral
% 378243295111299072	das Herz brauche ich %PosSmiley wir sehen uns Sonntag ! %PosSmiley %User

% <<<	gold:	positive
% >>>	predicted:	neutral
% 311979464223518721	Weist er Rauch aus meinem Auspuff ! Bin ich jetzt Papst oder ist die Zylinderkopfdichtung kaputt ?

%% Musto
% <<<	gold:	neutral
% >>>	predicted:	negative
% 369613129019179010	Unsachliche Angriffe abwehren : Ratschlge fr eine erfolgreiche Gesprchsfhrung

% <<<	gold:	positive
% >>>	predicted:	neutral
% 389763404468330496	Genial %User zeigt ab Ende Oktober HardKnocks trainingscamp amfootball ischgefreimir

% <<<	gold:	neutral
% >>>	predicted:	positive
% 371617968591237120	sn solinetz up3sn Wall Street - Ausblick : US - Anleger brauchen Klarheit

% <<<	gold:	positive
% >>>	predicted:	neutral
% 395507843425525760	Endlich online : Meine Eindrcke vom twitcook07 . Danke an %User fr den netten Abend :

% <<<	gold:	positive
% >>>	predicted:	negative
% 337359737102422016	Pff. Der Tweet war nicht an deine SPD - Entscheidung gebunden . Aber Anlass %PosSmiley

% <<<	gold:	neutral
% >>>	predicted:	positive
% 369859657785155584	Grosse Ereignisse brauchen Sendezeit : %Link BP ltw grne _ raus fdp _ raus

% <<<	gold:	neutral
% >>>	predicted:	positive
% 394419333646262272	Neue News : iWork - Update : Kritik wchst

% <<<	gold:	positive
% >>>	predicted:	neutral
% 395958248811274240	Schner Beitrag aus %User aspekte zu Ian McEwans " Honig " .

% <<<	gold:	neutral
% >>>	predicted:	positive
% 377426395808681984	Guten Abend , meine Freunde . Wer spricht hier deutsch und russisch ? Bitte helft mir . Danke .

% <<<	gold:	positive
% >>>	predicted:	neutral
% 373400820253216768	Ich freue mich wie so ein kleines Kind an Weihnachten beim Geschenkeauspacken . %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 392674775799459840	Der %User tut echt geile musik machen . Nichts mit Boyband hier .

% <<<	gold:	neutral
% >>>	predicted:	positive
% 393363937435332608	Erfolgreiche Unternehmensseite : Design , Benutzerfreundlichkeit , SEO &amp; Content . Was fllt euch noch ein ?

% <<<	gold:	positive
% >>>	predicted:	neutral
% 394017561257705472	Diese S5E5 Episode mit den Zugberfall war wieder genial ! BreakingBad

% <<<	gold:	neutral
% >>>	predicted:	positive
% 366563874322915329	frei nach Hhner : Wenn nicht jetzt , wann dann ?

% <<<	gold:	positive
% >>>	predicted:	negative
% 383589209099214848	kollarimi kaldiramiyorum %PosSmileyd aber sonst geht es ee , sana sormali %PosSmileyd alles im grnen bereich ? %PosSmiley

% <<<	gold:	neutral
% >>>	predicted:	positive
% 364733631161307136	Qualitt es - Frottee - Handtcher &gt; &gt; aus 100% reiner Baumwolle &gt; &gt; indanthrengefrbt , also farbecht und usserst ...

% <<<	gold:	neutral
% >>>	predicted:	positive
% 384989783044259840	%Link Amanda Bynes : Grosse Fortschritte : Schauspielerin Amanda Bynes soll in ihre ... %Link

% <<<	gold:	positive
% >>>	predicted:	negative
% 325497013779173376	irgendwo muss sie sich ja auch verstecken %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 367303745392369664	museuminsel ich kunst grnen friede smile peace glcklich besuchen @ Alte Nationalgalerie

% <<<	gold:	neutral
% >>>	predicted:	positive
% 362913319776026624	%Link . Zudem : Putin trifft Obama bei G8 in Sept : Falls S. weiter leakt Putin geschwcht , US - Russ wichtiger .

% <<<	gold:	neutral
% >>>	predicted:	positive
% 370238151677468673	Spannende Herausforderungen %Link ( %Link

% <<<	gold:	neutral
% >>>	predicted:	positive
% 367995876759064576	Sehenswerter Kinospot ...

% <<<	gold:	neutral
% >>>	predicted:	positive
% 391008437498548224	Jamaikanisches 3- Gnge - Men : Angebot : Jamaikanisches 3- Gnge - Men

% <<<	gold:	positive
% >>>	predicted:	neutral
% 391120001690009600	Los in die sonne Leute viel Fun ich chill Aba ganz schn heiss %PosSmiley %PosSmiley %PosSmiley %PosSmiley :P:P:P:P

% <<<	gold:	neutral
% >>>	predicted:	positive
% 373103381541163009	Topbeitrag : SAP macht sein MES " Industrie 4.0 " - fit

% <<<	gold:	positive
% >>>	predicted:	neutral
% 392742048027377664	Hey was geht ab freut ihr euch auch schon auf Donnerstag auf Alarm fr Kobra 11 %PosSmiley

% <<<	gold:	neutral
% >>>	predicted:	positive
% 390489060898123776	Schwedenimmobilien , Hauskauf , Bau , Renovierung Re : Warum antwortet Makler in Arvika nicht ? : Hej ! Bei uns war ...

% <<<	gold:	neutral
% >>>	predicted:	positive
% 366562377019301888	Google erweitert Liste seiner " Open - Source - Patente "

% <<<	gold:	positive
% >>>	predicted:	neutral
% 369834882022658048	ben ben ben - unter immer schn hinter den creeps bleiben %PosSmiley

% <<<	gold:	neutral
% >>>	predicted:	positive
% 390913390161719296	jepp Leadsnger Samu Haber von Sunrise Avenue . Habe den unzhlige male live gesehen . Tochter war grosser Fan .

%% Jurek
% <<<	gold:	positive
% >>>	predicted:	neutral
% 391900414636875776	pony erfolgreich geschnitten trotz zittriger hnde , yeha

% <<<	gold:	neutral
% >>>	predicted:	positive
% 391193825403604992	DJ Hochzeit Rgen buchen bei Fischer Spezial

% <<<	gold:	neutral
% >>>	predicted:	positive
% 375404309296721920	nun raucht doch einfach eine Friedenspfeife. domian

% <<<	gold:	positive
% >>>	predicted:	negative
% 385089037037744128	Dissertationen waren frher auch nicht viel lnger ... %PosSmiley Herzliche Gratulation !

% <<<	gold:	positive
% >>>	predicted:	negative
% 337341027503464448	Nicht alles . Vieles . Reicht mir , um mich in der SPD wohlzufhlen , da ich kein Querulant bin . %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 365157939419422721	Erfolgreich geduscht !

% <<<	gold:	negative
% >>>	predicted:	neutral
% 375584811429421056	mum hat mich gerade gefragt ob ich schwanger bin und deshalb so schlecht drauf

% <<<	gold:	negative
% >>>	predicted:	neutral
% 328251428432912387	Internet - Kontrolle : Jeder Haushalt muss Modem der Deutschen Telekom kaufen | %Link ( Erst drosseln und nun ...

% <<<	gold:	positive
% >>>	predicted:	neutral
% 363367575394070530	Und wieder geht ein schner ( heisser ) Sommertag zu Ende - Sonne Baden Sonne  %Smiley

% <<<	gold:	negative
% >>>	predicted:	positive
% 367003785593229313	Normal bin ich ja nicht der mensch dwer sich beschwert wegen dem essen aber diese Pizza von Joeys ... boah wie ekelhaft

% <<<	gold:	neutral
% >>>	predicted:	positive
% 363371711145590784	ei ei ei . Gut der hat glaube zu einer Zeit Bundesliga gespielt , wo du dich Altersvedingt noch nicht fr Fussball interessiert hast %NegSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 366133131746611201	Toll . Sehr lblich . Sieht echt klasse aus .

% <<<	gold:	neutral
% >>>	predicted:	negative
% 390589443130015744	Angry Birds Trilogie : 16.10 . 2013 Wie aus dem Nichts hat das erfolgreiche Entwicklerstudio nun die Angry Birds ...

% <<<	gold:	neutral
% >>>	predicted:	positive
% 390806972263858176	DJ Hochzeit Rgen buchen bei Fischer Spezial

% <<<	gold:	neutral
% >>>	predicted:	positive
% 391374642222362624	DJ Hochzeit Rgen buchen bei Fischer Spezial

% <<<	gold:	negative
% >>>	predicted:	positive
% 322333419986108416	Heute Abend im Beans : die Pint Size Company fllt leider kurzfristig aus . Doch wir haben Ersatz : die ...

% <<<	gold:	positive
% >>>	predicted:	negative
% 377180450500136961	Ich muss gerade irgendwem , der mich nicht dafr judged , mitteilen , dass Franzsisch eine echt schne Sprache ist .

% <<<	gold:	positive
% >>>	predicted:	negative
% 311903151810809857	Kay . Meine TL ist voll mit ' Wir haben einen Papst ' . Wofr braucht man noch Nachrichten . Steht wieso alles Twitter ! %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	negative
% 377191664881647616	CDU / CSU - FDP - SPD - Grne - alles ein Pack - der Rest ist leider unrealistisch = Die Linke - zu engstirnig = Piraten / AFD wat ' n Wahlkrampf

% <<<	gold:	positive
% >>>	predicted:	negative
% 321828481027694593	%User jetzt ja %PosSmiley ich behalte dich trotzdem %PosSmiley

% <<<	gold:	neutral
% >>>	predicted:	positive
% 383577981462913025	Wird sich Homophobie zuknftig bereits am Essverhalten erkennen lassen ? Nudelboykott in Deutschland ! barilla cdu spd linke fdp afd

% <<<	gold:	neutral
% >>>	predicted:	positive
% 370623910183972864	87073 / Finanzantrag fr " Piraten klren auf " : 260 Euro x 3 Veranstaltungen = 780 Euro , abgelehnt leuff

% <<<	gold:	neutral
% >>>	predicted:	positive
% 393842079966576642	Stuttgart gegen Nrnberg - Verbeek holt ersten Punkt dank irrer sechs Minuten

% <<<	gold:	positive
% >>>	predicted:	negative
% 319120814479925248	Aiaiaiai , FC Bayern Munchen , Wir singen und tanzen auf dem Fussballfeld , Ein Schuss , Ein Tor , Die Bayern .. cc : %User ...

% <<<	gold:	neutral
% >>>	predicted:	positive
% 395969246288961536	Heisser Teller , kaltes Getrnk

% <<<	gold:	neutral
% >>>	predicted:	positive
% 372736987997810688	Guter Bericht der NN zu unserem Datenschutzspaziergang mit durchaus kontroversen Kommentaren :

% <<<	gold:	positive
% >>>	predicted:	negative
% 333707728352595969	Wenn eine knftige deutsche Bundeskanzlerin in Polen geboren wurde - das htte doch was ... %PosSmiley

% <<<	gold:	negative
% >>>	predicted:	neutral
% 337298433528459266	Vielleicht hat Rsler dort auch nur einen Patent - Troll - Workshop besucht .

% <<<	gold:	neutral
% >>>	predicted:	positive
% 364502554178494464	Browser - Game gratis Urban Rivale es Online Sammelkartenspiel %Link einfach ausprobieren Simulation Urban Rivale es

% <<<	gold:	neutral
% >>>	predicted:	positive
% 365040117204795393	Browser - Game gratis A Mystical Land das 3 D - Browserspiel %Link einfach ausprobieren Rollenspiele A Mystical Land

% <<<	gold:	neutral
% >>>	predicted:	positive
% 366186441375621122	Enttuschte Hoffnungen Handelsblatt

% <<<	gold:	positive
% >>>	predicted:	neutral
% 364359427878432769	16 Auszubildende beenden erfolgreich ihre Ausbildung

% <<<	gold:	neutral
% >>>	predicted:	positive
% 370840348719079424	Schnelles Internet auf dem Land %Link DSL

% <<<	gold:	neutral
% >>>	predicted:	positive
% 389668914981912576	New - York : Reichtum ttet Kreativitt %Link Gentrifizierung

% <<<	gold:	neutral
% >>>	predicted:	positive
% 372462684710899712	Retweet if you want new followers ? Schreibt halt was nettes , dann folgen euch die Leute von ganz allein . Ohne solche Drecksretweets issso

%% Kolchyna
% <<<	gold:	positive
% >>>	predicted:	neutral
% 373941923326595073	Dafr ist FranzFerdinand ' s Right Thoughts , Right Words , Right Action herrlich retro ( und kein bisschen lahm ) %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 311914681226895360	So lange der neue Papst nicht mit einem " I AM THE GOD OF HELLFIRE " den Balkon betritt , kann ich ihn nicht ernstnehmen !

% <<<	gold:	negative
% >>>	predicted:	neutral
% 371646489833267200	Romantischer Kitsch .

% <<<	gold:	negative
% >>>	predicted:	neutral
% 368299716284784640	Uh , %User holt sich Smail Morabit , ex %User . Schwieriger Charakter . Knnte schief gehen . Gewaltig sogar

% <<<	gold:	positive
% >>>	predicted:	negative
% 323889817609986049	Der beste Microsoft Knowledgebase - Artikel , den ich je gelesen habe .

% <<<	gold:	positive
% >>>	predicted:	neutral
% 395144449090932736	danke fr die Aufklrung ! Wieder was gelernt ! %PosSmiley Na , Du wirst schon noch richtig wach heute %PosSmiley Oh , SAP - Kurs geht weiter . Bussi

% <<<	gold:	positive
% >>>	predicted:	negative
% 322331163488305152	ist nicht beim twittern passiert %PosSmiley %Link

% <<<	gold:	negative
% >>>	predicted:	neutral
% 374249009252421634	ber den Mindestlohn zu sprechen ist scheinbar die Antwort auf jede Frage ! Nervt ! tvduell

% <<<	gold:	negative
% >>>	predicted:	neutral
% 374883699772624896	Deprimierend ... king kings queen queens knig knigin herrscher ungerecht unfair life leben ...

% <<<	gold:	positive
% >>>	predicted:	negative
% 321267167070941186	Kein Ding , ich hab ' s gesehen und habe sofort an dich gedacht . %PosSmiley

% <<<	gold:	negative
% >>>	predicted:	neutral
% 377430463691763712	Also eines kann ich Leuten gar nicht empfehlen , die Twitter Follower sammeln . Zustimmend ber die AfD zu zwitschern . %PosSmiley

% <<<	gold:	negative
% >>>	predicted:	neutral
% 323168226580238336	Schulterschluss dank Nordkorea - Krise - DIE WELT %Link politik news

% <<<	gold:	positive
% >>>	predicted:	negative
% 376781718994550784	ich kauf mir auch Pokemon Y , Yveltal sieht einfach klasse aus %PosSmiley

% <<<	gold:	negative
% >>>	predicted:	neutral
% 322439427588751360	Rt aus cobra11 sind sie von der Piratenpartei ? eine von der " bezahl mich und dein Arsch geht nicht in den Bau " - Partei !

% <<<	gold:	positive
% >>>	predicted:	negative
% 327722680243609601	viel besser. viel , viel viel ... mir guckt nur keiner mehr in die Augen beim Reden - aber das wird schon %PosSmiley

% <<<	gold:	negative
% >>>	predicted:	positive
% 322253122204487680	wieso habe ich keine follower ? %NegSmiley

% <<<	gold:	negative
% >>>	predicted:	neutral
% 324780992629977088	ich bin ja ohne meinen laptop und meine mails hilflos %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 390286874620608512	die Schnheit ankommt . Endlich mir folgt . Thanks heaps %PosSmiley

% <<<	gold:	negative
% >>>	predicted:	positive
% 366990732906610689	Und schon das erste Unglck passiert , nur weil ich zu schaue

% <<<	gold:	negative
% >>>	predicted:	neutral
% 365462646947987456	schade

% <<<	gold:	negative
% >>>	predicted:	neutral
% 368727002632564736	Mann kpft aus 14 m deutlich vorbei ! Schade ! Kmpfen , Mnner !

% <<<	gold:	positive
% >>>	predicted:	neutral
% 372290739226820608	klare Linie bei dt. Aussenpolitik wird jetzt schon gebraucht und von Schwarz - Gelb kommt nichts ! r2g wre also klarer Fortschritt

% <<<	gold:	positive
% >>>	predicted:	negative
% 311921636913860608	wir haben wieder einen Papst %PosSmiley %Link

% <<<	gold:	positive
% >>>	predicted:	neutral
% 395959234489106432	Sieht gut aus %PosSmiley

% <<<	gold:	neutral
% >>>	predicted:	positive
% 385166539453788160	ASUS Google Nexus 7 Tablet PC mit 16 GB , WLAN , 17,8 cm ( 7 Zoll ) ! : Berlin | Verkaufe absolut neuwertiges ASUS N ...

% <<<	gold:	positive
% >>>	predicted:	neutral
% 311912360224911361	+ + + EILMELDUNG + + + Weist er Rauch ! Der %User ist neuer Papst !

% <<<	gold:	negative
% >>>	predicted:	neutral
% 377113110752280576	New York Fashion Week . Genau vor meiner Haustr . Schade , dass mich Fashion ungefhr null interessiert . Call me Andrea . NewYork

% <<<	gold:	positive
% >>>	predicted:	neutral
% 373038906759217152	%Link .. - dieser Artikel macht mir Hoffnung . Unerklrliches CDU - Wahlkampfbltter - Sterben in Stuttgart ...

% <<<	gold:	positive
% >>>	predicted:	neutral
% 370196485386018816	Bestes Gefhl der Welt : Schuhe aus , barfuss laufen

% <<<	gold:	negative
% >>>	predicted:	positive
% 361148414999793664	FDP - MdB %User ist in HH bei einer Demo gegen berwachung durch Geheimdienst du von der Bhne geschubst und verletzt w ...

% <<<	gold:	positive
% >>>	predicted:	neutral
% 372340168889737216	Super : Gysi klarer Gewinner bei ARD berzeugtuns zur btw13 mit 45,3 % !

% <<<	gold:	positive
% >>>	predicted:	neutral
% 392882762618642432	Guten Morgen . Wnsch ' ich Dir auch ! Muss heute aufs Zollamt fahren meine Quilts abholen - yay , endlich ! Was liegt bei Dir an ?

% <<<	gold:	positive
% >>>	predicted:	neutral
% 393387262165000192	[ CD - Review ] Dream Theater - Dream Theater : Die Anzeichen dafr , dass DREAM THEATER momentan richtig Bock haben ...

% <<<	gold:	negative
% >>>	predicted:	neutral
% 334781168698392576	kann diesen h - Quatsch nicht ernst nehmen . Die Kinder spielen politik ,

% <<<	gold:	neutral
% >>>	predicted:	negative
% 392722875838660609	Schwche erfordert Strke KMK4Live

% <<<	gold:	negative
% >>>	predicted:	positive
% 373195320462934016	Fies . Fieser . Dsseldorf .

% <<<	gold:	positive
% >>>	predicted:	neutral
% 311928847299932160	Vielleicht hat der neue Papst ja sterr . Vorfahren , die nach 1945 nach Argentinien ausgewandert sind ? %PosSmiley sterreichbezug

% <<<	gold:	neutral
% >>>	predicted:	negative
% 365502304453017602	Mutter setzt Baby aus " Bitte kmmern Sie sich gut um sie " - S %Link : Sddeutsche . deMu ... %Link Mnchen Munich

% <<<	gold:	positive
% >>>	predicted:	neutral
% 335510804872953857	Und ganz anderes Bundesland dazu %PosSmiley %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 382201791791640576	Jetzt sehen FDP ler mal wie es ist , von heute auf morgen an die Luft gesetzt zu werden %PosSmiley btw13

% <<<	gold:	negative
% >>>	predicted:	neutral
% 366962769502814212	Vorsicht Horror pur ... %NegSmiley %Link

% <<<	gold:	positive
% >>>	predicted:	negative
% 311923441597034498	Hervorragende Raumaufteilung der Kardinle um den Papst herum . Bergoglio wird auch als Messis Stellvertreter im Vat ...

% <<<	gold:	positive
% >>>	predicted:	neutral
% 395638223185391616	%User sieht nach einer Fllung aus ? Gutes gelingen %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 370472634301300737	Letzter Lichtblick diese Woche : das neue Revamp Album ab morgen * freu *

% <<<	gold:	positive
% >>>	predicted:	neutral
% 369439078078369793	Werde ich mir irgendwie auch machen , klar . Aber die Vorfreude ist erstmal dahin . / %User

% <<<	gold:	positive
% >>>	predicted:	neutral
% 374131053973499904	Vielen lieben Dank an alle , die den Vorfall mit der AfD rtweetet haben . Dieses braune Gedankengut hat keinen Platz in ...

% <<<	gold:	positive
% >>>	predicted:	neutral
% 369353396978855936	jupii schaut gut aus ! Schreiben wir uns einfach noch ' ja ? %PosSmiley %PosSmiley %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 369744071209660416	Die 2. Klsser heissen die neuen 1. Klssler im Schuljahr und im Schulhaus Hofmatt 1 herzlich willkommen .

% <<<	gold:	positive
% >>>	predicted:	negative
% 333673514294996993	Die Politik " wissenschaft " kann also da keine " Wahrheit " erfassen , sondern lediglich Perspektiven zeigen . Aber nicht mehr %PosSmiley

% <<<	gold:	negative
% >>>	predicted:	neutral
% 394522706240344064	lindenstrasse armer gung

% <<<	gold:	negative
% >>>	predicted:	neutral
% 390196940194844672	Habe gehrt FRau Merkel bricht schon ihre Wahlversprechen : Strom wird teurer , Abgasnormen werden erhht , Lobbyspenden werde ...

% <<<	gold:	positive
% >>>	predicted:	negative
% 325341424742715392	Sie lassen uns keine Wahl , sie wollen das wir uns nie wiedersehen .

% <<<	gold:	positive
% >>>	predicted:	negative
% 311942005603303425	So genial , wie manche hier Witze ber den Papst reissen , aber das letzte Mal zu Weihnachten in der Kirche waren . Weihnachten 2007 .

% <<<	gold:	positive
% >>>	predicted:	negative
% 311924719928606720	Yeah wir haben einen neuen Papst ! %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 368065461469999104	Volker Kauder cdu - " zu viel Transparenz spielt den Terroristen in die Hnde " %Link heise prism bnd ...

% <<<	gold:	positive
% >>>	predicted:	negative
% 365125286653730816	Hebe echt kleine handen %PosSmiley

% <<<	gold:	negative
% >>>	predicted:	neutral
% 368339985897750530	Vorsicht ! Betrunkene Pilger !

% <<<	gold:	positive
% >>>	predicted:	negative
% 381406414658232321	letzter Infostand mit %User : done ! %PosSmiley ... heut Abend noch Wahlkampf in den Kneipen ... noch Fragen ? %Link 3 tw

% <<<	gold:	positive
% >>>	predicted:	neutral
% 390553837586505728	Kleiner Angeber %NegSmiley Aber gut gemacht . : 3

% <<<	gold:	positive
% >>>	predicted:	neutral
% 364665335158304768	Guten Tag ! Noch ein letzter Cafe und dann geht ' s los ...

% <<<	gold:	positive
% >>>	predicted:	negative
% 311910335424638977	Der Papst ist wohl der einzige mit millionen Groupies , bevor er berhmt ist .

% <<<	gold:	positive
% >>>	predicted:	neutral
% 322385213294526465	aber anil ich versteh dich manchmal nicht kommt dir dass hier alles nicht echt vor ? %NegSmiley ich will dich doch auch

% <<<	gold:	negative
% >>>	predicted:	positive
% 369258121274744832	Achso ja , wurde ja stndig in den Nachrichten gezeigt ! Mrchenstunde mit der SPD ! %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	negative
% 370954010368671745	Wow , sieht klasse aus ! %PosSmiley

% <<<	gold:	negative
% >>>	predicted:	positive
% 323714991419179008	Download - Option bei Podlove fehlt - so wird es eingebaut

% <<<	gold:	positive
% >>>	predicted:	neutral
% 326079693818327042	diese Wahl habe ich nicht %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	negative
% 391162246837317632	Zauberhaften FF back %User ...

% <<<	gold:	positive
% >>>	predicted:	neutral
% 380984186477506560	Weil er drum bettelt wie die FDP um Zweitstimmen : Ein herzliches ff an %User Weil ich ihn spter im Kanzleramt brauche . %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	negative
% 364659072924000256	Wer hat dir eig. deinen neuen Avatar gemacht ? Sieht echt klasse aus !

% <<<	gold:	positive
% >>>	predicted:	negative
% 311905048982585344	Habemus Papam . Wir haben einen neuen Papst . %PosSmiley

% <<<	gold:	negative
% >>>	predicted:	neutral
% 369808596046868480	Gerne doch %PosSmiley Aspartam ist ein mieses Dreckzeug , das sich sogar in speziell beworbenen Kinderprodukten findet . ...

% <<<	gold:	positive
% >>>	predicted:	negative
% 376439258246295552	Nenene , schon klar . Einfach nur weile es gepasst hat :'D Das wre ja wohl die hhe %PosSmiley o %PosSmiley Eiskalt wegtreten .

% <<<	gold:	neutral
% >>>	predicted:	negative
% 377346221750251520	Preisabschlag 50% Preis : 9,97 Euro . DVD : Dr. Quinn - rztin aus Leidenschaft : Die komplette erst du Staffel ( 5 DV ...

% <<<	gold:	negative
% >>>	predicted:	neutral
% 393320983668744192	Instachallenge Day16 what i am reading Fratzensammler Horror Wattpad

% <<<	gold:	negative
% >>>	predicted:	neutral
% 389843767106093057	Die Websites der NPD sind bei mir gerade down . Dabei suche ich Argumente aus der rechten Ecke ... Unauffindbar . %NegSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 368791959814426624	Video : Psycho - Katzen %Link fun Katze lustig Psycho verrckt Video witzig

% <<<	gold:	positive
% >>>	predicted:	neutral
% 312154659487903744	Mein Lieblingsfoto : Franziskus vor wenigen Tagen in der U - Bahn %PosSmiley Papst Franziskus Pope Francis ...

% <<<	gold:	positive
% >>>	predicted:	negative
% 323771792143572992	Ist mir eben zum ersten mal aufgefallen . Voll gut . %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 311958232451133440	Jesuiten sind dem Papst streng ergeben -

% <<<	gold:	positive
% >>>	predicted:	negative
% 394479467206545408	* lf * lass mich ! %NegSmiley des war echt so ! habe immernoch dauergrinser *-*

% <<<	gold:	positive
% >>>	predicted:	negative
% 311917065869070337	Mal Papst gucken - egal ob glubig oder nicht %PosSmiley

% <<<	gold:	neutral
% >>>	predicted:	positive
% 373405522159869952	Pussy bis zum Orgasmus geil gewichst : Sleezy Da wird man von den ganzen Usern vor der Cam heiss gemacht bis die ...

% <<<	gold:	negative
% >>>	predicted:	neutral
% 392347531969310721	mir geht heute sowieso alles auf die nerven

% <<<	gold:	positive
% >>>	predicted:	neutral
% 375361254904590336	richtig , Grssenwahn !

% <<<	gold:	positive
% >>>	predicted:	neutral
% 369375051910377472	Oh ja , ihr seid alle so krasse Eminem Fans . Wow , sogar ein Album habt ihr von ihm ? Respekt .

% <<<	gold:	positive
% >>>	predicted:	neutral
% 363031871648968704	Na endlich - der A400M wird ausgeliefert . Eine tolle Maschine . Wird sicher noch ein Exportschlager . EADS

% <<<	gold:	negative
% >>>	predicted:	neutral
% 317398352989925376	Den Flug ins All wrde ich ja verschenken . Am liebsten an den Winter ! Oder die Bundeskanzlerin ? Is doch One Way , oder ?

% <<<	gold:	positive
% >>>	predicted:	negative
% 375355215148756992	Meine liebsten ... euch noch einen netten abend ... augen fallen zu ... nachti .. %PosSmiley HEL

% <<<	gold:	positive
% >>>	predicted:	negative
% 371649493026226176	Wunderschn ! Jetzt mchte ich auch heiraten . " Wedding cheese cake for vet Matt and wife to be Hannah

% <<<	gold:	negative
% >>>	predicted:	neutral
% 323708837452451840	Man kommt ja vor lauter Reue gar nicht mehr dazu , neue Fehler zu machen .

% <<<	gold:	negative
% >>>	predicted:	neutral
% 362855278905016320	Photo : terk edilmis unutulmus emzik bebek vergessen einsam schnulli schnuller baby

% <<<	gold:	positive
% >>>	predicted:	negative
% 319188965599092737	Das wahre Gesicht : FDP will jetzt mehr , CDU erst spter : Abgeordnete streiten um ihr Gehalt

% <<<	gold:	neutral
% >>>	predicted:	negative
% 374853089624219648	18.20 Magazinbeitrag von der DEMO ab Freiheit 18h Mnchen Repression Polizeikessel %Link ... refugeestruggle non _ citizen

% <<<	gold:	positive
% >>>	predicted:	neutral
% 327895959130497025	Obelix &amp; Obelix ? ? %PosSmiley Schnappschuss von der Feierstunde zur Erffnung der Rmer Lippe Route auf Schloss ...

% <<<	gold:	positive
% >>>	predicted:	negative
% 324963648957194240	Bereits etliche Piraten , die sich fr den Bundestag bewerben , mit Demokratie - Schwerpunkt : %Link Ilike %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 318590915017076738	Warum die Linke ? Warum die Palstinenser ? Interview ( ber ein Buch ) , das einem Lichter aufsteckt : %Link Antisemistismus

% <<<	gold:	positive
% >>>	predicted:	neutral
% 385452674776563712	Wow , die beiden sind so gut !

% <<<	gold:	negative
% >>>	predicted:	neutral
% 370123282114039808	.. %PosSmileyh , Packung leer . Mist .

% <<<	gold:	positive
% >>>	predicted:	neutral
% 392016655951224832	nu ist er besoffen . Vielleicht besser . %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	negative
% 322419130470912000	die sind hrtere matratzen gewhnt %PosSmiley

% <<<	gold:	negative
% >>>	predicted:	neutral
% 372757560954089472	Streit um gebrauchte Softwarelizenzen : LG Hamburg hat Bedenken bei AGB - Klauseln : Der Markt ... %Link nachrichten rtl2

% <<<	gold:	positive
% >>>	predicted:	negative
% 364824630516645888	Hey %PosSmiley Donner ! Jetzt sind wir alle wieder wach ! Wow ! Ich dachte gerade echt Thor besucht uns. gewitter

% <<<	gold:	negative
% >>>	predicted:	neutral
% 323791558010880001	schon mal durch die trefferliste durchgehrt ? jede menge mist dabei %PosSmiley %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 384042624103231488	Eine Koalition mit Grnen und Kommunisten ist dann hoffentlich das Ende fr die Sozen und die kos . Whler wrden verh ...

% <<<	gold:	positive
% >>>	predicted:	neutral
% 325297200039088128	Hurra , die Kollektion Figuren und Statuetten ist endlich fertig ! %Link android androidgames gameinsight

% <<<	gold:	positive
% >>>	predicted:	neutral
% 371972672613130240	guter montag. ungewhnlich . hchst ungewhnlich !

% <<<	gold:	positive
% >>>	predicted:	neutral
% 363659977145470977	klar gerne ! Aber vorher muss ich endlich mal den Bericht zur Eger schreiben %PosSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 390538922880942080	guten abend. bitte folge mir mal. dann kann ich dir das erklren . danke ^ l

% <<<	gold:	negative
% >>>	predicted:	neutral
% 322016897665228800	Rechtes Netzwerk suchte Kontakt auch zu Zschpe : Wiesbaden ( dpa ) - Ein neues rechtsextremes Netzwerk in Gefng ...

% <<<	gold:	negative
% >>>	predicted:	neutral
% 390200056491806720	Und mein Fisch dauert noch 20 Minuten %NegSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 367933398351753216	Der Hannig wieder mit DTG Angabe . Gut , dass keine Grnen dabei sind ... %NegSmiley

% <<<	gold:	positive
% >>>	predicted:	neutral
% 311904195735351297	Nun ist es soweit : die Welt hat einen neuen Papst weist er Rauch

% <<<	gold:	positive
% >>>	predicted:	neutral
% 385467300473995265	lasagne - lasagne auflaufe hier %PosSmiley einen guten !

% <<<	gold:	neutral
% >>>	predicted:	negative
% 391965686710296576	Bundesliga : Kraftlose Dortmunder beweisen Charakter : Dortmund - Das Bild hatte Symbolchara ... %Link football Fussball

% <<<	gold:	positive
% >>>	predicted:	neutral
% 364680279576682496	In neun Monaten ... %PosSmiley Nein , sicher eher .


% \begin{example}[Error]\label{snt:cgsa:exmp:hl-error}
%   \noindent\textup{\bfseries\textcolor{darkred}{Tweet:}} {\upshape Ich finde den Papst putzig \smiley{}}\\
%   \noindent I find the Pope cute \smiley{}.\\
%   \noindent\textup{\bfseries\textcolor{darkred}{Label:}}\hspace*{2em}\textbf{%
%     \upshape\textcolor{green3}{positive}}\\[1.5em]
%   \noindent\textup{\bfseries\textcolor{darkred}{Tweet:}} {\upshape typisch Bayern kaum ist der neue Papst da und schon haben
%   sie ihn in der Tasche ...}\\
%   \noindent Typical Bavaria The new Pope is hardly there, as they already have him in their pocket\\
%   \noindent\textup{\bfseries\textcolor{darkred}{Label:}}\hspace*{2em}\textbf{%
%     \upshape\textcolor{midnightblue}{negative}}
% \end{example}

\section{Machine-Learning Methods}\label{sec:cgsa:ml-based}

Despite their immense popularity, linguistic plausibility, and
simplicity to implement, lexicon-based approaches often have been
criticized for the rigidness of their classification\footnote{Since
  these systems only rely on the precomputed weights of lexicon
  entries, considering these coefficients as constant, their decision
  boundaries frequently appear to be suboptimal as many terms might
  have different polarity and intensity values depending on the domain
  \cite[see][]{Eisenstein:17,Yang:17}.} and the inability to
incorporate additional, non-lexical attributes into the final
decisions.  Moreover, as noted by~\citet{Pang:02} and also confirmed
empirically by~\citet{Riloff:03} and \citet{Gamon:04}, many of the
linguistic expressions which actually correlate with the subjectivity
or polarity of a sentence (e.g., exclamation marks or spelling
variations) are very unlikely to be included into a sentiment lexicon
even by a human expert.  As a consequence of this, with the emergence
of new manually annotated corpora, lexicon-based systems have been
gradually superseded by supervised machine-learning techniques.

One of the first steps in this direction was taken
by~\citet{Wiebe:99}, who used a Na{\"i}ve Bayes classifier to
differentiate between subjective and objective statements.  Using
primarily binary features which reflected the presence of a pronoun,
an adjective, a cardinal number, or a modal verb in the analyzed
sentence, the authors achieved an accuracy of~72.17\% on this
two-class prediction task, outperforming the majority class baseline
by more than 20~percent.  An even better result (81.5\%) could be
reached when the dataset was restricted only to the examples with the
most confident annotations.

Inspired by the success of this approach,~\citet{Yu:03} presented a
more elaborated system, in which they first distinguished between
subjective and objective documents, then differentiated between polar
and neutral sentences, and, finally, classified the polarity of the
opinionated clauses.  As in the previous case, the authors used a
Na{\"i}ve Bayes predictor for the document-level task, reaching a
remarkable \F-score of~0.96 on this objective; and applied an ensemble
of NB systems to predict the subjectivity of single sentences.  To
determine the semantic orientation of a subjective clause,
\citeauthor{Yu:03} averaged the polarity scores of its tokens,
obtaining these scores from an automatically constructed sentiment
lexicon~\cite{Hatzivassi:97}.  This way, they attained an accuracy
of~91\% on a set of 38 sentences which had a perfect inter-annotator
agreement in their data.

Yet another multi-stage Na{\"i}ve Bayes model was proposed by
\citet{Pang:04}, who tried to classify the overall semantic
orientation of movie reviews (positive vs. negative) by first dividing
the sentences into subjective and objective ones (achieving 92\%
accuracy on this subtask) and then predicting the overall polarity of
a review using only subjective passages.  With this architecture, the
authors achieved statistically significant improvements over the
baseline method (in which they commonly considered all sentences
disregarding their subjectivity), boosting the accuracy of polarity
classification from~82.8 to~86.4\%.

In order to check the effectiveness of the Na{\"i}ve Bayes approach,
\citet{Pang:02} compared the results of NB, MaxEnt, and SVM systems on
the movie review classification task, attempting to predict whether a
review was perceived as thumbs up or thumbs down.  In contrast to the
previous works, they found the SVM classifier working best for this
objective, yielding 82.9\% accuracy when used with unigram features
only.  This conclusion paved the way for the following general triumph
of the support-vector approach, which was dominating the whole CGSA
research field for almost a decade ever since.  For example,
\citet{Gamon:04} also trained an SVM predictor on a rich set of
linguistic and surface-level features (including part-of-speech
trigrams, context-free phrase-structure patterns, and part-of-speech
information coupled with semantic relations) to distinguish between
positive and negative customer feedback, achieving 77.5\% accuracy and
$\approx$0.77~\F{} by using only top 2,000 attributes which had the
highest log-likelihood ratios with the target
classes.  % Interestingly enough,
% \citeauthor{Gamon:04} also could obtain quite competitive figures
% (74.5\% accuracy) by using linguistically motivated features only.
Furthermore, \citet{Pang:05} addressed the problem of multi-class
rating, trying to predict the number of stars that an author could
assign to a review.  For this purpose, they compared three different
SVM types:
\begin{inparaenum}[(i)]
\item one-versus-all SVM (OVA-SVM),
\item SVM regression,
\item and OVA-SVM with \emph{metric labeling};
\end{inparaenum}
getting their best results ($\approx$52\%~accuracy) with the last
option.
% \citet{Pang:05}
% In the last approach, in addition to maximizing the score of the
% correct labels, the authors also explicitly encoded the objective of
% minimizing the absolute difference between the predicted labels of
% similar training examples (measuring this similarity with the
% percentage of positive sentences).  This strategy brought
% statistically significant improvements over the first two baselines,
% yielding an average accuracy of $\approx$52\%.
Finally, \citet{Ng:06} proposed another multi-stage SVM system, where
they first classified whether the given text was a review or not and
then tried to predict its polarity in case it was.  Due to a better
usage of higher-order $n$-grams (where, instead of bluntly considering
all token sequences up to the length $n$ as new features, the authors
only took 5,000 most useful ones, measuring their utility with the
weighted log-likelihood ratio), \citet{Ng:06} even improved the then
state of the art on the \citeauthor{Pang:04}'s corpus, boosting the
accuracy of polarity classification from~87.1 to~90.5\%.

% \todo[inline]{Feature Selection}
% \done[inline]{\citet{Li:10b}}

% \citet{Li:10b} addressed the problem of polarity shifting using
% machine-learning techniques.  For this purpose, the authors first
% selected most frequent and indicative features of the two main
% polarity classes (positive and negative), and then culled training
% instances containing these attributes whose labels, however, were
% different from the ones sugested by the features.  After obtaining
% this polarity shifted subset, \citeauthor{Li:10b} trained several
% linear support-vector classifiers, one of which had to distinguish
% between polarity-shifted and polarity-preserving sentences, the other
% two were to classify the semantic orientation of these two groups
% (i.e., one system had to predict the polarity of shifted instances,
% and the other one had to determine the semantic orientation of
% polarity-preserving ones), and the last one was trained on the
% complete original dataset---the product review corpus
% of~\citet{Blitzer:06}---again to predict the polarity of complete
% sentences disregarding their possible polarity shifts.  The authors
% achieved their best results~(80,9\% average accuracy) using a
% combination of the last three systems with a special meta-classifier
% joining their single decisions.

% \done[inline]{\citet{Wiebe:05a}}

% A semi-supervised approach to sentence-level subjectivity prediction
% was proposed by~\citet{Wiebe:05a}.  Using an existing rule-based
% sentiment system, the authors classified a large set of unlabeled
% sentences from newspaper articles into subjective and objective ones,
% achieving 34.2\% recall and 90.4\% precision for the former class and
% getting 30.7\% recall and 82.4\% precision for the latter orientation.
% Afterwards, with the help of the AutoSlog-TS
% algorithm~\cite{Riloff:96}, they extracted frequent lexico-syntactic
% patterns that strongly correlated with the subjectivity of a sentence,
% and trained a Na{\"i}ve Bayes system, considering the occurrences of
% the learned patterns as features.  In an attempt to improve the
% results of this approach even further, \citeauthor{Wiebe:05a} also
% implemented a self-improvement strategy in which they relabeled the
% original unannotated dataset with the obtained NB classifier, then
% took one half of the most confidently classified sentences as a new
% training set, and extracted new subjectivity patterns, retraining the
% Na{\"i}ve Bayes module on the updated set of features.  With this
% final classifier, the authors attained an accuracy of 73.8\% on
% predicting the subjectivity of sentences in the MPQA
% corpus~\cite{Wiebe:05}, coming close to the results achieved by a
% fully supervised ML approach (76\%).

% \done[inline]{\citet{Riloff:06}}

% \citet{Riloff:06} addressed the problem of redundant features,
% hypothesizing that correlated attributes (such as unigram
% ``\emph{happy}'' and bigram ``\emph{very happy}'') would rather harm
% the performance of a classifier than improve its accuracy.  To prove
% this hypothesis, the authors defined two kinds of redundancy relations
% which could exist between intersecting input traits:
% \emph{representational} and \emph{behavioral} subsumption.  The former
% former type was assumed to hold between features~$A$ and $B$ if all
% occurrences of the attribute~$A$ were a strict superset of the
% occurrences of~$B$.  The behavioral subsumption meant that the
% information gain (IG) \cite{Forman:03} of the feture $B$ was at most
% some negligible value $\delta$ lower than the respective IG score of
% the attribute $A$.  In their experiments, \citeauthor{Riloff:06}
% observed that the accuracy of an SVM classifier indeed increased (from
% 81.7 to 82.7\% on the IMDBP dataset and from 74.4 to 74.9\% on the
% MPQA corpus) after they excluded all attributes that were
% representationally and behaviorally subsumed by other features.  These
% improvements even outperformed the gains that could be achieved with
% traditional feature selection methods.

% \todo[inline]{Higher-order $n$-grams}

% \done[inline]{\citet{Ng:06}}

% Further on, \citet{Ng:06} simultaneously addressed two classification
% problems: distinguishing whether a given text snippet was a review or
% not and determining the polarity of the review.  The authors attained
% impressive results (99.8\% accuracy) for the former task, using only
% SVM with unigram features.  Moreover, they also outperformed the then
% state of the art on the \citet{Pang:04}'s corpus, boosting the
% accuracy from~87.1 to~90.5\%.  These changes were mostly due to a
% smarter use of higher-order $n$-grams, where, instead of bluntly
% considering all token sequences up to the order $n$ as new features,
% \citet{Ng:06} only took 5,000 most useful ones, measuring their
% utility with the weightes log-likelihood ratio \cite{Nigam:00}.

% \done[inline]{\citet{Mejova:11}}

% \citet{Mejova:11} investigated the effect of different features on
% various datasets---the movie review corpus of~\citet{Pang:04}, the
% product reviews gathered by~\citet{Jindal:07}, and the customer
% feedback dataset of~\citet{Blitzer:06}, coming to the conclusion that,
% in general, preserving the original form of tokens (i.e., keeping the
% original token forms instead of lemmas) and using their frequency
% scores instead of binary values was beneficial to the results on all
% test sets.  The use of different $n$-gram lengths, however, had a
% mixed effect with the best scores typically yielded by the union of
% uni-, bi-, and tri-gram features.  Last but not least, they found the
% negation heuristics proposed by~\citet{Das:01} (adding the
% \texttt{\_NOT} suffix to all tokens following a negation up to the
% first punctuation) leading to only marginal improvements.  The authors
% achieved their best results (87.5\%, 94.7\%, and 89.6\% accuracy on
% the datasets of \citet{Pang:04}, \citet{Jindal:07}, and
% \citet{Blitzer:06}, respectively) with the union of unnormalized uni-,
% bi-gram and tri-gram features without negation when using term
% frequencies as feature values.

% \done[inline]{\citet{Riloff:03a}}

% \citet{Riloff:03a} addressed the problem of inusfficient manually
% annotated sentiment resources by proposing a bootstrapping method for
% training a subjectivity classifier.  In this approach, the authors
% first applied two high-precision predictors to a large collection of
% unlabeled sentences in order to get an initial set of subjective and
% objective instances.  Afterwards, they used the AutoSlog-TS
% algorithm~\cite{Riloff:96} to extract expressions which strongly
% correlated with the subjective class and employed these phrases to
% classify the remaining sentences from the corpus.
% \citeauthor{Riloff:03a} repeated the last two steps (pattern
% extraction and expansion of the training set) multiple times to
% transitively learn new subjective phrases.  With the final system, the
% authors achieved a precision of 0.902 on recognizing polar sentences,
% with their recall running up to 0.401.

% \done[inline]{\citet{Wilson:04,Wilson:06}}

% A related problem, namely that of classifying the strength of
% opinions, was addressed by~\citet{Wilson:04,Wilson:06}.  In
% particular, the authors proposed a wide variety of linguistic features
% (including automatically learned lexico-syntactic patterns similar to
% the ones used by~\citet{Riloff:03}, bags of words, and syntactic
% attributes such as lemma and PoS tag of the root of a dependency tree,
% lemmas and tags of its intermediate nodes and leaves, lexicalized
% relation tuples, i.e., tuples consisting of the lemma of a parent
% node, its grammatical relation to the child, and the lemma of the
% child itself, etc.), checking the utility of these attributes with
% three different classifiers: BoosTexter~\cite{Schapire:00},
% Ripper~\cite{Cohen:95}, and SVMLight~\cite{Joachims:99}.
% \citet{Wilson:04} achieved their best results (55\%~accuracy and
% 0.991~mean squared error) with the BoosTexter approach when using all
% the introduced features.

However, a real game changer in the sentiment analysis research field

\done[inline]{SemEval 2013}

\done[inline]{\citet{Mohammad:13}}

Finally, with the introduction of the SemEval competition in sentiment
analysis of
Twitter~\cite{Nakov:13,Rosenthal:14,Rosenthal:15,Nakov:16}, a plethora
of new CGSA applications have appeared on the scientific scene, most
of which relied on traditional supervised machine-learning techniques.
One of the most prominent and arguably well-known such systems was
proposed by~\citet{Mohammad:13}, who trained a linear SVM classifier
on an extensive set of linguistic features including character and
token $n$-grams, Brown clusters~\cite{Brown:92}, statistics on
part-of-speech tags, punctuation marks, elongated words etc.  However,
the most useful type of attributes, as noted by the authors, turned
out to be features that reflected information from various sentiment
lexicons.  In particular, depending on the type of the polarity list
from which such information was extracted, the authors introduced two
types of lexicon attributes: \emph{manual} and \emph{automatic} ones.
The former group was computed with the help of the NRC emotion
lexicon~\cite{Mohammad:13a}, MPQA polarity list~\cite{Wilson:05}, and
Bing Liu's manually compiled polarity set~\cite{Hu:04}.  For each of
these resources and for each of the non-neutral polarity classes
(positive and negative), \citeauthor{Mohammad:13} calculated the total
sum of the lexicon scores for all message tokens and also separately
estimated these statistics for each particular part-of-speech tag,
considering them as additional attributes.  Automatic features were
obtained using automatically generated Sentiment140 and Hashtag
Sentiment Base polarity lists \cite{Kiritchenko:14}.  Again, for each
of these lexicons, for each of the two polarity classes, the authors
produced four features representing the number of tokens with non-zero
scores, the sum and the maximum of all respective lexicon values for
all tweet tokens, and the score of the last term.  This final system
ranked first in the inaugural run of the SemEval task, attaining
0.69~\F-score on the three-way classification task, with the automatic
lexicon features alone accounting for at least five percent boost in
the performance of this model.

\done[inline]{\citet{Guenther:13}}

A similar solution (linear SVM with a rich set of features) was
presented by~\citet{Guenther:13}.  Akin to~\citet{Mohammad:13}, the
authors used unmodified and lemmatized unigrams, word clusters, and
lexicon features.  However, in contrast to the previous system, this
application utilized only one polarity list---that
of~\citet{Esuli:05}.  Partially due to this fact,
\citeauthor{Guenther:13} found the word cluster attribute working best
among all features, followed by the stemmed unigram attributes.  This
method also yielded competitive results (0.653~\F) on the
message-level polarity task, attaining second place in this
competition.

\done[inline]{SemEval 2014}

\done[inline]{\citet{Miura:14}}

Later on these results were further improved by~\citet{Miura:14}, who
also utilized a supervised ML approach with character and word
$n$-grams, word clusters, disambiguated senses, and lexicon scores of
message tokens.  Similarly to the NRC-Canada system
of~\citet{Mohammad:13}, the authors made heavy use of various kinds of
polarity lists including AFINN-111~\cite{Nielsen:11}, Liu's Opinion
Lexicon~\cite{Hu:04} , General Inquirer~\cite{Stone:66}, MPQA Polarity
List \cite{Wiebe:05a}, NRC Hashtag and Sentiment140
Lexicon~\cite{Mohammad:13}, and
\textsc{SentiWordNet}~\cite{Esuli:06a}.  However, contrary to
\citeauthor{Mohammad:13}'s approach, \citeauthor{Miura:14} also
applied a whole set of preprocessing steps such as spelling
correction, part-of-speech tagging with lemmatization, and a special
weighting scheme for underrepresented polarity classes.  These
enhancements, combined with a carefully tuned LogLinear classifier,
allowed the authors to boost the sentiment classification results on
SemEval~2014 test set to 0.71 average \F (measure on the two main
polarity classes---positive and negative).

\done[inline]{\citet{Guenther:14}}

In the same vein, \citet{Guenther:14} improved their results from the
previous SemEval run (from 0.654 to 0.691 two-class \F) by extending
their original system with a Twitter-aware
tokenizer~\cite{Owoputi:13}, spelling normalization module, and a
significantly increased of lexicon-based features (this time, instead
of simply relying on the \textsc{SentiWordNet} resource,
\citeauthor{Guenther:14} harnessed a whole ensemble of various
polarity lists including Liu's opinion list, MPQA subjectivity
lexicon, and TwittrAttr polarity resource).  As proved by the ablation
tests, the last change was of particular use to the classification
accuracy, improving the scores by almost five percent.

\done[inline]{SemEval 2015}

\done[inline]{\citet{Hagen:15}}

A different approach to the coarse-grained sentiment-analysis task was
proposed by~\citet{Hagen:15}, who, instead of developing their own
method from scratch, united four already existing solutions
(\citet{Mohammad:13}, \citet{Guenther:13}, \citet{Proisl:13}, and
\citet{Miura:14}) into a single ensemble, taking the average of the
predicted scores as the final decision of the complete system.  This
way, the authors achieved 0.648~\F{} on the SemEval-2015 test set,
attaining first place among 40 participants.

\done[inline]{\citet{Hamdan:15}}

Another supervised machine-learning system was proposed
by~\citet{Hamdan:15}, who also used an extensive set of features such
as word $n$-grams, negation existence, sentiment lexicons and
$Z$-score, which reflected the strength of statistical correlation
between a given term $t$ and the target class $c$ in the distribution
\cite[cf.][]{Hamdan:14}.  Similarly to~\citet{Mohammad:13}, the
authors used an extensive set of lexicon features, and also applied
attribute and class weighting as it was done by~\citet{Guenther:14}.
This way, \citeauthor{Hamdan:15} achieved 0.643~\F on the SemEval-2015
test get, getting third place among all competitors.

% One of the first attempts to analyze message-level sentiments on
% Twitter was made by \citet{Go:09}.  For their experiments, the authors
% collected a set of 1,600,000 tweets containing smileys.  Based on
% these emoticons, they automatically derived polarity classes for these
% messages (positive or negative) and used them to train a Na\"{\i}ve
% Bayes, MaxEnt, and SVM classifier.  The best $F$-score for this
% two-class classification problem could be achieved by the last system
% and run up to 82.2\%.

% Similar work was also done by \citet{Pak:10} who used the Na\"{\i}ve
% Bayes approach to differentiate between neutral, positive, and
% negative microblogs; and \citet{Barbosa:10} who gathered a collection
% of 200,000 tweets, subsequently analyzing them with three publicly
% available sentiment web-services and training an SVM classifier on the
% results of these predictors.  In a similar way, \citet{Agarwal:11}
% compared a simple unigram-based SVM approach with two other
% full-fledged systems, one which relied on a rich set of manually
% defined features, and another used partial tree
% kernels~\cite{Moschitti:06}.  The authors evaluated these methods on a
% commercially acquired corpus of 8,753 foreign-language tweets, which
% were automatically translated into English, finding that a combination
% of these methods worked best for both two- and three-way prediction
% tasks.

% The state-of-the-art results for message level polarity prediction on
% tweets were established by~\citet{Mohammad:13}, whose system (a
% supervised SVM classifier) used a rich set of various features
% including word and character n-grams, PoS statistics, Brown
% clusters~\cite{Brown:92}, etc., and also strongly benefitted from
% automatic corpus-based polarity lists---Sentiment~140 and NRC
% Hashtag~\cite{Mohammad:12,Kiritchenko:14}.  This approach ranked first
% at the SemEval competition~2013~\cite{Nakov:13} and anchieved the
% fourth place on the rerun of this task one year
% later~\cite{Rosenthal:14}, being outperformed by the supervised
% logistic regression approach of~\citet{Miura:14}, who used a heavy
% preprocessing of the data and a special balancing scheme for
% underrepresented classes.  Later on, these results were further
% improved by the apporaches of~\citet{Hagen:15} and \citet{Deriu:16},
% which both relied on ensembles of multiple independent classifiers.

\begin{table}[h]
  \begin{center}
    \bgroup \setlength\tabcolsep{0.1\tabcolsep}\scriptsize
    \begin{tabular}{p{0.162\columnwidth} % first columm
        *{9}{>{\centering\arraybackslash}p{0.074\columnwidth}} % next nine columns
        *{2}{>{\centering\arraybackslash}p{0.068\columnwidth}}} % last two columns
      \toprule
      \multirow{2}*{\bfseries Method} & %
      \multicolumn{3}{c}{\bfseries Positive} & %
      \multicolumn{3}{c}{\bfseries Negative} & %
      \multicolumn{3}{c}{\bfseries Neutral} & %
      \multirow{2}{0.068\columnwidth}{\bfseries\centering Macro\newline \F{}} & %
      \multirow{2}{0.068\columnwidth}{\bfseries\centering Micro\newline \F{}}\\
      \cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}

      & Precision & Recall & \F{} & %
      Precision & Recall & \F{} & %
      Precision & Recall & \F{} & & \\\midrule

       &  &  &  & %
       &  &  & %
       &  &  & %
       & \\\bottomrule
    \end{tabular}
    \egroup
    \caption[Evaluation of ML-based coarse-grained SA methods.]{
      Evaluation of ML-based coarse-grained SA methods.\\
      {\small }}
    \label{snt-cgsa:tbl:ml-res}
  \end{center}
\end{table}

\section{Deep-Learning Methods}\label{sec:cgsa:dl-based}

\todo[inline]{Lin, 1998}

Since there was not a complete set of such expressions, it provided
some seeds and then used distributional similarity (Lin, 1998) to find
similar words, which were also likely to be subjectivity
indicators. However, words found this way had low precision and high
recall.

\todo[inline]{\citet{Bespalov:11}}

In (Bespalov et al., 2011), sentiment classification was performed
based on supervised latent n-gram analysis.

\todo[inline]{\citet{Zhou:10}}

\citet{Yessenalina:11}

A real breakthrough in the use of deep neural networks for the
sentence-level sentiment analysis happened with the pioneering work
of~\citet{Socher:11}, who first introduced a recursive autoencoder
(RAE).  In this system, the authors obtained a fixed-width vector
representation for complex phrases $\vec{v}$ by recursively merging
the vectors of adjacent tokens (say $\vec{w}_1$ and $\vec{w}_2$),
first multiplying these vectors with a compositional matrix $W$ and
then applying a non-linear function ($softmax$) to the resulting
product:
\begin{align*}
  \vec{c} &= softmax\left(W\cdot\begin{bmatrix}
  \vec{w}_1\\
  \vec{w}_2
  \end{bmatrix}\right)
\end{align*}
Using a max-margin classifier on top of the resulting phrase
representation, \citet{Socher:11} could improve the state-of-the-art
results on predicting the sentence-level polarity of user's blog
posts~\cite{Potts:10} and also outperformed the system
of~\citet{Nasukawa:03} on the MPQA data set~\cite{Wiebe:05}.

Later on, \citet{Socher:12} further improved these scores with the
help of a recursive matrix-vectors space model (RMVSM), in which each
word was associated with a 2-tuple of a vector and matrix---e.g.,
$(\vec{w}_1, W_1)$ and $(\vec{w}_2, W_2)$---and the compositionality
function was redefined as follows:
\begin{align*}
  \vec{c} &= softmax\left(W\cdot\begin{bmatrix}
  W_2\cdot\vec{w}_1\\
  W_1\cdot\vec{w}_2
  \end{bmatrix}\right)
\end{align*}


\done[inline]{\citet{Tang:14b}}

A hybrid approach to coarse-grained sentiment analysis was proposed by
\citet{Tang:14b}, who trained a linear SVM classifier on top of
sentiment-specific word embeddings and hand-crafted features.  To
obtain the former representations, \citeauthor{Tang:14b} devised a
simple feed-forward neural network similar to the one used
by~\citet{Collobert:11}, which, for each token $t$, had to predict the
probability that this token appeared in the surrounding context and
the likelihood that $t$ occurred in a positive or negative microblog.
Since this training required a substantial amount of data, the authors
leveraged a big collection of automatically downloaded tweets,
obtaining noisy sentiment labels for these microblogs with the distant
supervision method of~\citet{Go:09}.  The second part of this
system---manually designed features---were mostly inspired by the work
of~\citet{Mohammad:13} and included $n$-grams, word clusters,
information about emoticons, negtaion, elongated characters and
punctuation marks.  Combining these different traits into a single
feature vector resulted significantly improved classification
accuracy, yielding 0.701~\F{} on the SemEval-2014 test set (second
place among all competing systems).

\done[inline]{\citet{Severyn:15}}

An important breakthrough in the usage of deep learning methods for
sentiment analysis on Twitter happened with the
work~\citet{Severyn:15}, whose proposed feed-forward DL system ranked
first in Subtask~10~A (phrase-level polarity prediction) at
SemEval~2015 \cite{Rosenthal:15} and achieved second place in
Subtask~10~B (message-level classification).  Drawing on the ideas
of~\citet{Kalchbrenner:14}, the authors devised a simple convolutional
network which, taking sentiment-flavored pretrained word2vec vectors
as input, multiplied these embeddings with 300 distinct convolutional
kernels each of width five, subsequently passing the results of this
multiplication to a piecewise linear ReLU filter and densely connected
softmax layer.  An important aspect of this method which accounted for
a huge part of its success was a special initialization scheme
introduced by the authors.  In this inital process,
\citeauthor{Severyn:15} first trained Twitter-specific word2vec
vectors on a large collection of downloaded tweets, then pretrained
the complete system, incuding matrix weights and emeddings, on noisily
labeled microblogs of this corpus, leveraging the approach
of~\citeauthor{Go:09}, and, finally, fine-tuned the parameters of
their network on the officially released SemEval data.  Due to these
improvements, the final system attained a competitive result of
0.6459~two-class~\F{} on the message-level polarity subtask.

\done[inline]{SemEval 2016}

\done[inline]{\citet{Deriu:16}}

\citet{Deriu:16} extended the system of~\citet{Severyn:15} by
increasing the number of convolutional layers (using two layers
instead of just one).  Furthermore, to improve the generalizability of
their system, the authors trained two such networks with different
types of input embeddings, taking pretrained word2vec
vectors~\cite{Mikolov:13} for one classifier and using GloVe
embeddings~\cite{Pennington:14} for another one.  Similarly to
\citet{Severyn:15}, \citeauthor{Deriu:16} first fine-tuned these word
representations on a big collection of tweets, maximizing the context
prediction objective.  Afterwards, they pretrained the parameters of
the networks including embeddings and convolutional filters on a big
set of noisily labeled tweets, and, finally, put the finishing touches
on the weights of these systems by training them on the officially
released SemEval data.  The authors united the predictions of both
networks by training a random forest classifier on top of their output
vectors, establishing a new state of the art (0.633~\F{}) on the
SemEval-2016 data.

\done[inline]{\citet{Rouvier:16}}

Another approach building on the work of~\citet{Severyn:15} was
proposed by~\citet{Rouvier:16}.  In contrast to the former system
which utilized only pre-trained sentiment-flavored word vectors with a
single convolutional layer, the authors simultaneously harnessed three
different types of embeddings (word2vec, word2vec specific to
particular parts of speech, and sentiment-tailored emeddings) each of
which was trained with a separate set of convolutional filters.
Besides training deep representations, the authors also used
hand-crafted features such as sentiment lexicons, emoticons,
information about elongated words, punctuation marks, and capitalized
tokens, training a separate multi-layer perceptron on these
attributes.  In the final step, \citeauthor{Rouvier:16} joined the
outputs of the two downstream classifiers (deep convolutions and
perceptron) into a single vector, subsequently passing this vector to
two fully connected neural network layers with softmax non-linearity
at the end.  This way, the authors achieved 0.63~\F{} on the
SemEval-2016 test set, getting second rank in this shared task.

\done[inline]{\citet{Xu:16}}

\citet{Xu:16} also chose an ensemble approach to coarse-grained
opinion mining of tweets.  In particular, the authors combined a
convolutional system with 300 filters of widths three, four, and five
(using 100 filters for each given width); an LSTM
classifier~\cite{Hochreiter:97}, taking its output vector from the
last time step $t$ as the final vote; and a special Bayesian wordvec
system, which was trained to maximize the probability of a token given
its surrounding context and the label of the tweet, maximizing this
probability with the prior likelihood of the respective polarity.
\citeauthor{Xu:16} united the decisions of these subsystems using soft
weighting scheme:
\begin{equation*}
  y^* = \sum_i w_i y_i,\textrm{, s.t.} \sum_i w_i = 1, \forall i: w_i \geq 0,
\end{equation*}
where $y_i$ is the score of the label $y$ returned by the $i$-th
classifier, and $w_i$ denotes an automatically learned weight for this
prediction.  This submission achieved 0.617~\F{} on the two polarity
classes (positive and negative), getting third place among all
participating submissions.

\todo[inline]{\citet{Wang:15}}

\todo[inline]{\citet{Baziotis:17}}
\todo[inline]{\citet{Cliche:17}}
\todo[inline]{\citet{Rouvier:17}}

\begin{table}[h]
  \begin{center}
    \bgroup \setlength\tabcolsep{0.1\tabcolsep}\scriptsize
    \begin{tabular}{p{0.162\columnwidth} % first columm
        *{9}{>{\centering\arraybackslash}p{0.074\columnwidth}} % next nine columns
        *{2}{>{\centering\arraybackslash}p{0.068\columnwidth}}} % last two columns
      \toprule
      \multirow{2}*{\bfseries Method} & %
      \multicolumn{3}{c}{\bfseries Positive} & %
      \multicolumn{3}{c}{\bfseries Negative} & %
      \multicolumn{3}{c}{\bfseries Neutral} & %
      \multirow{2}{0.068\columnwidth}{\bfseries\centering Macro\newline \F{}} & %
      \multirow{2}{0.068\columnwidth}{\bfseries\centering Micro\newline \F{}}\\
      \cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}

      & Precision & Recall & \F{} & %
      Precision & Recall & \F{} & %
      Precision & Recall & \F{} & & \\\midrule

       &  &  &  & %
       &  &  & %
       &  &  & %
       & \\\bottomrule
    \end{tabular}
    \egroup
    \caption[Evaluation of DL-based coarse-grained SA methods.]{
      Evaluation of DL-based coarse-grained SA methods.\\
      {\small }}
    \label{snt-cgsa:tbl:ml-res}
  \end{center}
\end{table}

% \section{Coarse-Grained Sentiment Analysis Using Language and Domain
%   Adaptation}\label{sec:cgsa:domain-adaptation}

% One of the first works which pointed out the importance of domain
% adaptation for sentiment analysis was introduced by~\citet{Aue:05}.
% In their experiments, the authors trained separate SVM classifiers on
% four different document sets: movie reviews, book reviews, customer
% feedback from a product support service, and a feedback survey from a
% customer knowledge base; finding that each classifier performed best
% when applied to the same domain as it was trained on.  In order to
% find an optimal way of overcoming this domain specificity,
% \citet{Aue:05} tried out four different options:
% \begin{inparaenum}[(i)]
% \item\label{sent-cgsa:lst:rel-wrk1} training one classifier on all but
%   the target domain and applying it to the latter;
% \item using the same procedure as above, but limiting the features to
%   only those which also appeared in the target texts;
% \item taking an ensemble of individual classifiers each of which was
%   trained on a different data collection; and, finally,
% \item using a minimal subset of labeled in-domain data to train a
%   Na{\"i}ve Bayes system with the expectation-maximization algorithm
%   \cite[EM;][]{Dempster:77}.
% \end{inparaenum}
% The authors found that the ensemble and EM options worked best for
% their cross-domain task, achieving an accuracy of up to 82.39\% for
% the two-class prediction (positive vs negative) on new unseen text
% genres.

% Another notable milestone in the domain adaptation research was set
% by~\citet{Blitzer:07}.  Relying on their previous work on structural
% correspondence learning~\cite{Blitzer:07}, in which they used a set of
% \emph{pivot features} (features which frequently appeared in both
% target and source domains) to find an optimal correspondence of the
% remaining attributes,\footnote{In particular, the authors trained $m$
%   binary predictors for each of their $m$ pivot features in order to
%   find other attributes which frequently co-occurred with the pivots.
%   Afterwards, they composed these $m$ resulting weight vectors into a
%   single matrix $W := [\vec{w}_{1},\ldots,\vec{w}_{m}]$, took an SVD
%   decomposition of this matrix, and used the top $h$ left singular
%   vectors to translate source features to the new domain.} the authors
% refined their method by pre-selecting the pivots using their PMI
% scores and improving misaligned feature projections using a small set
% of labeled target examples.  With these modifications,
% \citeauthor{Blitzer:07} were able to reduce the average adaptation
% loss (the accuracy drop when transferring a classifier to a different
% domain) from 9.1 to 4.9~percent when testing a sentiment predictor on
% the domains of book, dvd, electical appliances, and kitchen reviews.

% Other important works on domain adaptation for opinion mining include
% those of~\citet{Read:05}, who pointed out that sentiment
% classification might not only depend on the domain but also on topic,
% time, and language style in which the text was written;
% \citet{Tan:07}, who proposed using the classifier trained on the
% source domain to classify unlabeled instances from the target genre,
% and then iteratively retrain the system on the enriched data set.
% Finally, \citet{Andreevskaia:08} proposed a combination of a lexicon-
% and ML-based systems, claiming that this ensemble would be more
% resistible to the domain shift than each of these classifiers on their
% own.

% Another line of research was introduced by~\citet{Glorot:11} who
% proposed stacked denoising autoencoders (SDA)---a neural network
% architecture in which an input vector $\vec{x}$ was first mapped to a
% smaller representation $\vec{x}'$ via some function
% $h: \vec{x}\mapsto\vec{x}'$, and then restored to its approximate
% original state via an inverse transformation
% $g: \vec{x}'\mapsto\vec{x}''\approx\vec{x}$.  In their experiments,
% the authors optimized the parameters of the functions $h$ and $g$ on
% both target and source data, getting approximate representations of
% instances from both data sets; and then trained a linear SVM
% classifier on the restored representations of the source instances,
% subsequently applying this classifier to the target domain.  This
% approach was further refined by~\citet{Chen:12} who analytically
% computed the reconstruction function~$g$, and used both original and
% restored features to predict the polarity labels of the target
% data.\footnote{Both approaches were trained tested on the Amazon
%   Review Corpus of~\citet{Blitzer:07}.}


% Further notable contributions to domain adaptation in general were
% made by~\citet{Daume:07} who proposed to replicate each extracted
% feature three times and train the first replication on both domains,
% the second repetion only on source, and the third copy only on target
% domain, for which he assumed a small subset of labeled examples was
% available; \citet{Yang:15} who trained neural embeddings of features,
% trying to predict which instance attributes frequently co-occured with
% each other;

\section{Evaluation}
\subsection{Effect of Lexicons}\label{cgsa:subsec:eval:lexicons}

\todo[inline]{describe lexicon normalization steps}

\subsection{Effect of Distant Supervision}
\todo[inline]{}

To the best of our knowledge, the idea of utilizing web texts
containing emoticons as noisily labeled training data was first
proposed by~\citet{Read:05}, who collected a set of 26,000 Usenet
posts featuring smileys or frownies and used these documents to train
a Na{\"i}ve Bayes and SVM classifier.  The author demonstrated that,
despite some encouraging results obtained on the instances from the
same domain (up to 70\% accuracy), the trained systems did not
generalize well to other text genres, barely outperforming the chance
baseline and reaching a maximum accuracy of~54.4\% on news data and
56.8\% on movie reviews.

The presumably first known attempt to adopt distant supervision for
the sentiment analysis of Twitter data was made by~\citet{Go:09} who
collected a set of 800,000 positive and 800,000 negative microblogs
relying on emoticons as their noisy labels.  After stripping off these
smileys from text, the authors trained three independent
ML-classifiers (Na{\"i}ve Bayes, Maximum Entropy, and Support Vector
Machines) on this collection, achieving their best results (82.7\%
accuracy) with the NB and MaxEnt systems thaat utilized unigrams and
bigrams as features.

Another distantly supervised approach was presented
by~\citet{Barbosa:10}, who gathered a collection of automatically
labeled tweets from three popular sentiment web sites (Twendz, Twitter
Sentiment, and TweetFeel), and trained two binary SVM systems on this
corpus.  The first of these classifiers had to distinguish between
subjective and objective microblogs, attaining an error rate of~18.1\%
on a subset of 1,000 manually annotated messages.  In the next step,
the second system had to determine the semantic orientation of
opinionated posts (positive or negative), reaching an error rate
of~18.7\% on this prediction.

In a similar way, \citet{Pak:10} gathered a collection of 300,000
noisily labeled tweets, ensuring an even distribution of positive,
negative, and neutral messages.  After a brief exploration of PoS tag
statistics in these different classes, they presented a Na{\"i}ve
Bayes system which utilized highly relevant binary part-of-speech and
$n$-gram features.\footnote{\citet{Pak:10} determined the relevance of
  a feature $f$ using a special \emph{salience} metric, which was
  defined as a negative ratio between the minimum and maximum
  conditional probabilities of this feature belonging to different
  target classes:
  \begin{equation*}
    salience(f) = \frac{1}{N}\sum_{i=1}^{N-1}\sum_{j=i+1}^N 1 - \frac{\min(P(f, s_i), P(f, s_j))}{\max(P(f, s_i), P(f, s_j))},
  \end{equation*}
  where the $N$~term denotes the number of training examples, and
  $s_i$ means the sentiment class of the $i$-th training instance.}
With this approach, the authors attained an accuracy slighlty above
0.6 on the manually labeled test set of~\citet{Go:09}, also
demonstrating a particular utility of bigrams, negation rules, and
feature pruning heuristics.

A slightly different task was addressed by~\citet{Davidov:10}, who
sought to predict hashtags and emoticons occurring in tweets using a
$k$-NN classifier trained on a large collection of messages.  The
authors achieved an \F-measure of~0.31 on the former task, and reached
an \F-score of~0.64 on predicting smileys.

\citet{Kouloumpis:11} trained an AdaBoost
classifier~\cite{Schapire:00} on two large collections of noisily
labeled tweets---the emoticon tweebank of~\citet{Go:09} and the
Edinburgh hashtag corpus.\footnote{\url{http://demeter.inf.ed.ac.uk}}
Using $n$-gram (up to length two), lexicon, part-of-speech, and
micro-blogging features (such as emoticons, abbreviations, and slang
expressions), the authors achieved a macro-averaged \F-measure of~0.68
on the three-class prediction task.

\subsection{Effect of Word Embeddings}
\subsection{Effect of Text Normalization}
\begin{table}[h]
  \begin{center}
    \bgroup \setlength\tabcolsep{0.1\tabcolsep}\scriptsize
    \begin{tabular}{p{0.162\columnwidth} % first columm
        *{9}{>{\centering\arraybackslash}p{0.074\columnwidth}} % next nine columns
        *{2}{>{\centering\arraybackslash}p{0.068\columnwidth}}} % last two columns
      \toprule
      \multirow{2}*{\bfseries Method} & %
      \multicolumn{3}{c}{\bfseries Positive} & %
      \multicolumn{3}{c}{\bfseries Negative} & %
      \multicolumn{3}{c}{\bfseries Neutral} & %
      \multirow{2}{0.068\columnwidth}{\bfseries\centering Macro\newline \F{}$^{+/-}$} & %
      \multirow{2}{0.068\columnwidth}{\bfseries\centering Micro\newline \F{}}\\
      \cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}

      & Precision & Recall & \F{} & %
      Precision & Recall & \F{} & %
      Precision & Recall & \F{} & & \\\midrule

      \multicolumn{12}{c}{\cellcolor{cellcolor}PotTS}\\

      % Training hu-liu
      % Testing hu-liu
      % Evaluating hu-liu
      % General Statistics:
      % precision    recall  f1-score   support
      % positive       0.44      0.21      0.28       691
      % negative       0.15      0.10      0.12       296
      % neutral       0.35      0.66      0.46       542
      % avg / total       0.35      0.35      0.31      1529
      % Macro-Averaged F1-Score (Positive and Negative Classes): 19.95%
      % Micro-Averaged F1-Score (All Classes): 34.5978%

      HL & 0.44 & 0.21 & 0.28 & %
        0.15 & 0.1 & 0.12 & %
        0.35 & 0.66 & 0.46 & %
        0.2 & 0.346\\

        % Training taboada
        % Testing taboada
        % Evaluating taboada
        % General Statistics:
        % precision    recall  f1-score   support
        % positive       0.46      0.17      0.25       691
        % negative       0.15      0.09      0.11       296
        % neutral       0.35      0.72      0.48       542
        % avg / total       0.36      0.35      0.30      1529
        % Macro-Averaged F1-Score (Positive and Negative Classes): 17.95%
        % Micro-Averaged F1-Score (All Classes): 34.9248%
      TBD & 0.46 & 0.17 & 0.25 & %
        0.15 & 0.09 & 0.11 & %
        0.35 & 0.72 & 0.48 & %
        0.18 & 0.349\\

        % Training musto
        % Testing musto
        % Evaluating musto
        % General Statistics:
        % precision    recall  f1-score   support
        % positive       0.44      0.20      0.27       691
        % negative       0.16      0.12      0.14       296
        % neutral       0.35      0.65      0.46       542
        % avg / total       0.36      0.34      0.31      1529
        % Macro-Averaged F1-Score (Positive and Negative Classes): 20.55%
        % Micro-Averaged F1-Score (All Classes): 34.4670%
      MST & 0.44 & 0.2 & 0.27 & %
        0.16 & 0.12 & 0.14 & %
        0.35 & 0.65 & 0.46 & %
        0.206 & 0.345\\

        % Training jurek
        % Testing jurek
        % Evaluating jurek
        % General Statistics:
        % precision    recall  f1-score   support
        % positive       0.44      0.24      0.31       691
        % negative       0.13      0.06      0.08       296
        % neutral       0.36      0.68      0.47       542
        % avg / total       0.35      0.36      0.32      1529
        % Macro-Averaged F1-Score (Positive and Negative Classes): 19.35%
        % Micro-Averaged F1-Score (All Classes): 35.9712%
      JRK & 0.44 & 0.24 & 0.31 & %
        0.13 & 0.06 & 0.08 & %
        0.36 & 0.68 & 0.47 & %
        0.194 & 0.36\\

        % Training kolchyna
        % Testing kolchyna
        % Evaluating kolchyna
        % General Statistics:
        % precision    recall  f1-score   support
        % positive       0.46      0.18      0.26       691
        % negative       0.16      0.09      0.12       296
        % neutral       0.36      0.72      0.48       542
        % avg / total       0.37      0.36      0.31      1529
        % Macro-Averaged F1-Score (Positive and Negative Classes): 18.95%
        % Micro-Averaged F1-Score (All Classes): 35.6442%
      KLCH & 0.46 & 0.18 & 0.26 & %
        0.16 & 0.09 & 0.12 & %
        0.36 & 0.72 & 0.48 & %
        0.19 & 0.356 \\\bottomrule

      \multicolumn{12}{c}{\cellcolor{cellcolor}SB10k}\\

      % Training hu-liu
      % Testing hu-liu
      % Evaluating hu-liu
      % General Statistics:
      % precision    recall  f1-score   support
      % positive       0.41      0.43      0.42       354
      % negative       0.24      0.27      0.25       212
      % neutral       0.66      0.63      0.65       930
      % avg / total       0.54      0.53      0.54      1496
      % Macro-Averaged F1-Score (Positive and Negative Classes): 33.67%
      % Micro-Averaged F1-Score (All Classes): 53.2086%
      HL & 0.41 & 0.43 & 0.42 & %
        0.24 & 0.27 & 0.25 & %
        0.66 & 0.63 & 0.65 & %
        0.337 & 0.532\\

        % Training taboada
        % Testing taboada
        % Evaluating taboada
        % General Statistics:
        % precision    recall  f1-score   support
        % positive       0.41      0.38      0.39       354
        % negative       0.21      0.23      0.22       212
        % neutral       0.66      0.66      0.66       930
        % avg / total       0.53      0.53      0.53      1496
        % Macro-Averaged F1-Score (Positive and Negative Classes): 30.66%
        % Micro-Averaged F1-Score (All Classes): 53.3422%
      TBD & 0.41 & 0.38 & 0.39 & %
        0.21 & 0.23 & 0.22 & %
        0.66 & 0.66 & 0.66 & %
        0.307 & 0.533\\

        % Training musto
        % Testing musto
        % Evaluating musto
        % General Statistics:
        % precision    recall  f1-score   support
        % positive       0.40      0.32      0.36       354
        % negative       0.26      0.30      0.28       212
        % neutral       0.65      0.68      0.67       930
        % avg / total       0.54      0.54      0.54      1496
        % Macro-Averaged F1-Score (Positive and Negative Classes): 31.77%
        % Micro-Averaged F1-Score (All Classes): 54.2112%
      MST & 0.4 & 0.32 & 0.36 & %
        0.26 & 0.3 & 0.28 & %
        0.65 & 0.68 & 0.67 & %
        0.318 & 0.542\\

        % Training jurek
        % Testing jurek
        % Evaluating jurek
        % General Statistics:
        % precision    recall  f1-score   support
        % positive       0.40      0.41      0.40       354
        % negative       0.36      0.25      0.29       212
        % neutral       0.69      0.72      0.71       930
        % avg / total       0.57      0.58      0.58      1496
        % Macro-Averaged F1-Score (Positive and Negative Classes): 34.94%
        % Micro-Averaged F1-Score (All Classes): 58.3556%
      JRK & 0.4 & 0.41 & 0.4 & %
        0.36 & 0.25 & 0.29 & %
        0.69 & 0.72 & 0.71 & %
        0.349 & 0.584\\

        % Training kolchyna
        % Testing kolchyna
        % Evaluating kolchyna
        % General Statistics:
        % precision    recall  f1-score   support
        % positive       0.42      0.18      0.26       354
        % negative       0.19      0.14      0.16       212
        % neutral       0.65      0.84      0.73       930
        % avg / total       0.53      0.58      0.54      1496
        % Macro-Averaged F1-Score (Positive and Negative Classes): 20.83%
        % Micro-Averaged F1-Score (All Classes): 58.4225%
      KLCH & 0.42 & 0.18 & 0.26 & %
       0.19 & 0.14 & 0.16 & %
       0.65 & 0.84 & 0.73 & %
       0.208 & 0.584\\\bottomrule
\end{tabular}
    \egroup
    \caption[Results of CGSA Methods without Text Normalization.]{
      Results of CGSA methods without text normalization.\\
      {\small HL~--~\citet{Hu:04}, TBD~--~\citet{Taboada:11}, MST~-- \citet{Musto:14}, JRK
        -- \citet{Jurek:15}, KLCH -- \citet{Kolchyna:15}}}
    \label{snt-cgsa:tbl:res-without-normalization}
  \end{center}
\end{table}

\section{Summary and Conclusions}\label{slsa:subsec:conclusions}
